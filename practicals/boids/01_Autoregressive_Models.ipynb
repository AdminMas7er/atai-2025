{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2UctuhrmJ-"
      },
      "source": [
        "# Autoregressive Models\n",
        "\n",
        "In this practical, we'll go over the following topics:\n",
        "- Autoregressive models and when to use them\n",
        "- Implementing equivariances in Autoregressive GNNs\n",
        "- Evaluating scientific AI models\n",
        "\n",
        "But first, a short introduction on the dataset used for this practical.\n",
        "\n",
        "![Boids gif](figures/boids.gif)\n",
        "\n",
        "## Boids (by Craig Reynolds)\n",
        "\n",
        "The Boids algorithm, developed by Craig Reynolds [2], aims to replicate the behavior of flocking birds.\n",
        "\n",
        "The simplest setting, used in this practical, follows three simple rules:\n",
        "\n",
        "1. Separation: Each boid should steer away from crowding local flockmates (avoiding collisions)\n",
        "2. Alignment: Each boid should steer towards the average heading of local flockmates\n",
        "3. Cohesion: Each boid should steer towards the average position of local flockmates\n",
        "\n",
        "With some parameter tuning, these rules allow for some surprisingly realistic behavior. A gif of one of the simulations is shown above.\n",
        "\n",
        "### Implementation details\n",
        "\n",
        "Our dataset consists of 1000 samples of Boids simulations. Each simulation has 25 Boids and continues for 1000 timesteps. The Boids fly around in a 2D grid of 1000 x 1000 units.\n",
        "\n",
        "In our simulations, Boids steer away from eachother (Separation) if they are within 16 units of eachother. Boids steer towards the average heading/position of all (local) flockmates within 40 units.*\n",
        "Finally, we use periodic boundary conditions; Boids cannot leave the screen, they re-enter on the other side (pacman style).\n",
        "\n",
        "* We use Euclidean distance (with PBC) here to compute the distance between boids. For a more detailed explanation, visit [The minimum image convention](https://en.wikibooks.org/wiki/Molecular_Simulation/Periodic_Boundary_Conditions) section of the wikibooks page on PBC.\n",
        "\n",
        "## Problem setting\n",
        "\n",
        "Boids simulations feature complex interactions between multiple actors (nodes). The simulation can be chaotic and very sensitive to initial conditions.\n",
        "\n",
        "\n",
        "This makes it an interesting playground for the models/frameworks discussed in the course. In this practical, we will implement an AR model from scratch, then gradually introduce equivariances and training/evaluation methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f1Io-bCIrmKC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
            "  warnings.warn(\n",
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from typing import Tuple\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPQ9aywvrmKE"
      },
      "source": [
        "## Data exploration\n",
        "\n",
        "First let's look at the data structure, and some statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPRT1xTtrmKE",
        "outputId": "24e67948-d876-47f9-f7b2-cd4389d7951e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26\n"
          ]
        }
      ],
      "source": [
        "base = \"../../data/boids/raw\"\n",
        "files = [f for f in os.listdir(base) if f.endswith(\".npy\")]\n",
        "trajectories = [np.load(os.path.join(base, f)) for f in files]\n",
        "\n",
        "print(len(trajectories))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOnrEMv2rmKF",
        "outputId": "c9183283-aba4-4572-80e1-fe73fb5bc9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single trajectory shape:\n",
            "(1000, 25, 4)\n",
            "The axes and their cardinalities; (Timesteps:1000, Boids:25, (Position X, Position Y, Velocity x, Velocity y):4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Single trajectory shape:\")\n",
        "print(trajectories[0].shape)\n",
        "print(\"The axes and their cardinalities; (Timesteps:1000, Boids:25, (Position X, Position Y, Velocity x, Velocity y):4)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn46INH3rmKF",
        "outputId": "321f48d7-ddb2-4363-da3a-e530b16957fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Position mean, std, min, max:\n",
            "500.32 290.61 0.0 1000.0\n",
            "\n",
            "Velocity mean, std, min, max:\n",
            "-0.35 2.96 -6.0 6.0\n"
          ]
        }
      ],
      "source": [
        "# Print the mean, std, min and max of the boid positions, velocities\n",
        "positions = np.array([t[:, :, :2] for t in trajectories])\n",
        "velocities = np.array([t[:, :, 2:] for t in trajectories])\n",
        "\n",
        "print(\"Position mean, std, min, max:\")\n",
        "# Round to 2 decimal places\n",
        "print(round(np.mean(positions),2), round(np.std(positions),2), round(np.min(positions), 2), round(np.max(positions), 2))\n",
        "print()\n",
        "print(\"Velocity mean, std, min, max:\")\n",
        "# Round to 2 decimal places\n",
        "print(round(np.mean(velocities),2), round(np.std(velocities),2), round(np.min(velocities), 2), round(np.max(velocities), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xGnPrEXErmKG"
      },
      "outputs": [],
      "source": [
        "def plot_state(trajectory, timestep):\n",
        "    fig, ax = plt.subplots()\n",
        "    # Plot dots for the boids\n",
        "    ax.scatter(trajectory[timestep, :, 0], trajectory[timestep, :, 1])\n",
        "    # plot the boid velocities as arrows\n",
        "    for i in range(trajectory.shape[1]):\n",
        "        # NOTE: The arrows are made larger for effect\n",
        "        ax.arrow(trajectory[timestep, i, 0], trajectory[timestep, i, 1], trajectory[timestep, i, 2]*5, trajectory[timestep, i, 3]*5)\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "OKk3eGrRrmKG",
        "outputId": "ae68d65c-438d-4981-a821-c7330fe0c7dd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot timesteps 0, 250, 500, 750, 999 for the first trajectory\n",
        "trajectory = trajectories[0]\n",
        "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
        "for i, t in enumerate([0, 250, 500, 750, 999]):\n",
        "    axs[i].set_title(f\"Timestep {t}\")\n",
        "    # Plot dots for the boids\n",
        "    axs[i].scatter(trajectory[t, :, 0], trajectory[t, :, 1])\n",
        "    # plot the boid velocities as arrows\n",
        "    for j in range(trajectory.shape[1]):\n",
        "        # NOTE: The arrows are made larger for effect\n",
        "        axs[i].arrow(trajectory[t, j, 0], trajectory[t, j, 1], trajectory[t, j, 2]*5, trajectory[t, j, 3]*5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSuLp6fsrmKH"
      },
      "source": [
        "In the plot above, you can see that after some warmup time, the boids start to form flocks. Flocking behavior is a form of inter-node communication, which we will come back to again later.\n",
        "\n",
        "Thinking back to the Geometric Deep Learning framework, we can identify the following symmetries in the data:\n",
        "\n",
        "- The boids are equivariant to permutations, ie it does not matter in which order we compute the update rules for the boids.\n",
        "- Local flocks of boids are equivariant to translation, rotation and reflection.\n",
        "\n",
        "Following these symmetries, it makes sense to model the boids using a Graph Neural Network (GNN). Specifically, since we are dealing with inter-node communication, we will be implementing a Message Passing GNN here.\n",
        "\n",
        "But first, we create a `torch_geometric` InMemoryDataset object, to model the data as a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F3pCfIFXrmKH"
      },
      "outputs": [],
      "source": [
        "class AR_Boids_Dataset(InMemoryDataset):\n",
        "    def __init__(self, raw_data_path, processed_data_path, root=None, transform=None, pre_transform=None, post_transform=None, solution_idx_range=(0, 25), timesteps=1000, processed_file_name=\"AR1_Boids.pt\"):\n",
        "        self.raw_data_path = raw_data_path\n",
        "        self.processed_data_path = processed_data_path\n",
        "        self.solution_idx_range = solution_idx_range\n",
        "        self.timesteps = timesteps\n",
        "        self.processed_file_name = processed_file_name\n",
        "        self.pre_transform = pre_transform\n",
        "        self.transform = transform\n",
        "        self.post_transform = post_transform\n",
        "        super(AR_Boids_Dataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.processed_file_name]\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [pfn for pfn in os.listdir(self.raw_data_path) if (self.solution_idx_range[0] <= int(pfn.split(\"_\")[-1][:-4]) < self.solution_idx_range[1])]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.timesteps - 1) * (self.solution_idx_range[1] - self.solution_idx_range[0])\n",
        "\n",
        "    def process(self):\n",
        "        data_list = []\n",
        "        for idx, raw_path in enumerate(self.raw_file_names):\n",
        "            trajectory = np.load(self.raw_data_path + raw_path)\n",
        "\n",
        "            if self.transform is not None:\n",
        "                trajectory = self.transform(trajectory)\n",
        "\n",
        "            for t in range(trajectory.shape[0] - 1):\n",
        "                x = torch.tensor(trajectory[t], dtype=torch.float)\n",
        "                y_temp = torch.tensor(trajectory[t+1], dtype=torch.float)\n",
        "                # y_temp is (position x, position y, velocity x, velocity y) for the next timestep\n",
        "                # However, we want delta position and delta velocity\n",
        "                # Luckily, the delta poisition is just the velocity from the next timestep, and the delta velocity is the acceleration\n",
        "                # So we can just take the last two elements of y to get the delta velocity\n",
        "                # First we copy the last two columns of y to the first two columns of y\n",
        "                y = y_temp.clone()\n",
        "                y[:, :2] = y_temp[:, 2:]\n",
        "                # Then we calculate the acceleration\n",
        "                y[:, 2:] = y_temp[:, 2:] - x[:, 2:]    # (V_x ^ (t+1), V_y ^ (t+1), a_x, a_y)\n",
        "\n",
        "                # fully connected graph\n",
        "                edge_index = torch.tensor([[i, j] for i in range(trajectory.shape[1]) for j in range(trajectory.shape[1]) if i != j], dtype=torch.long).t().contiguous()\n",
        "\n",
        "                if self.post_transform is not None:\n",
        "                    data = self.post_transform(data)\n",
        "\n",
        "                data = Data(x=x, y=y, edge_index=edge_index)\n",
        "                data_list.append(data)\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_data_path+self.processed_file_name)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.get(idx)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}({len(self)})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0sT0htrmKH",
        "outputId": "3d8245f2-5fd2-4e5d-9fe3-6192ee8c469e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AR_Boids_Dataset(14985)\n",
            "AR_Boids_Dataset(8991)\n",
            "Data(x=[25, 4], edge_index=[2, 600], y=[25, 4])\n",
            "<bound method BaseData.keys of Data(x=[25, 4], edge_index=[2, 600], y=[25, 4])>\n",
            "Pos x, Pos y, Vel x, Vel y\n",
            "tensor([719., 745.,   5.,  -3.])\n"
          ]
        }
      ],
      "source": [
        "train_dataset = AR_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(0, 15),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"AR1_Boids.pt\"\n",
        ")\n",
        "\n",
        "validation_dataset = AR_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(16, 25),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"AR1_VAL_Boids.pt\"\n",
        ")\n",
        "\n",
        "\n",
        "print(train_dataset)\n",
        "print(validation_dataset)\n",
        "\n",
        "\n",
        "data_0 = train_dataset[0]\n",
        "print(data_0)\n",
        "print(data_0.keys)\n",
        "print(\"Pos x, Pos y, Vel x, Vel y\")\n",
        "print(data_0.x[0,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwSZ7OvDrmKI"
      },
      "source": [
        "## Autoregressive Models\n",
        "In general, when dealing with simulations spanning multiple timesteps, we can define the learning problem as follows.\n",
        "\n",
        "Let $X^{0:T-1}$ denote the states spanning across timesteps $t=0$ through $t=T-1$. Given the initial state $X^0$, our goal is to accurately predict the future states $X^{1:T-1}$. In the probabilistic case, we want to learn a model with parameters $\\theta$ for the probability distribution $P_\\theta(X^{1:T-1}|X^0)$.*\n",
        "\n",
        "In some systems, such as in the Boids setting, the next state X^{t+1} is only dependent on the current state X^t. Such systems are memoryless, and are often said to be _Markovian_. The Markov property allows us to rewrite the learning task to $P_\\theta(X^{1:T-1}|X^0) = \\prod_{t=0}^{T-2} P_\\theta(X^{t+1} | X^t)$\n",
        "\n",
        "Here, $P_\\theta(X^{t+1} | X^t)$ is the _Autoregressive model_ - literally meaning it is used to autoregressively construct the full trajectory of the system. Note that this model is autoregressive in time; not space.\n",
        "\n",
        "*: In this practical, we will not be building a probabilistic model. So instead of parameterizing a distribution, we learn a function $f_\\theta: X^t \\rarr X^{t+1}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXJiDfrarmKI"
      },
      "source": [
        "### Autoregressive set model\n",
        "\n",
        "Below, we create the simplest AR model for the Boids system; a fully connected GNN (essentially a set model).\n",
        "\n",
        "Given a fully connected graph $X^t$, representing the Boids system at time $t$; it learns to predict the next state of the system $X^{t+1}$.\n",
        "\n",
        "Note here that we use all features from the dataset as node features. This causes the model to not be equivariant to some group actions, that are relevant in the Boids setting.\n",
        "\n",
        "---\n",
        "\n",
        "Tick the equivariance(s) of this model:\n",
        "\n",
        "- <input\n",
        "      type=\"checkbox\"\n",
        "      id=\"eq0\"\n",
        "      name=\"perm\"\n",
        "      value=\"perm\" />\n",
        "    <label for=\"eq1\">Permutational Equivariance</label>\n",
        "\n",
        "- <input\n",
        "      type=\"checkbox\"\n",
        "      id=\"eq1\"\n",
        "      name=\"space\"\n",
        "      value=\"space\" />\n",
        "    <label for=\"eq1\">Space Translation Equivariance</label>\n",
        "\n",
        "- <input\n",
        "      type=\"checkbox\"\n",
        "      id=\"eq2\"\n",
        "      name=\"time\"\n",
        "      value=\"time\" />\n",
        "    <label for=\"eq2\">Time Translation Equivariance</label>\n",
        "\n",
        "- <input\n",
        "      type=\"checkbox\"\n",
        "      id=\"eq3\"\n",
        "      name=\"rot\"\n",
        "      value=\"rot\" />\n",
        "    <label for=\"eq3\">Rotation/Reflection Equivariance</label>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Cru8x0H6rmKI"
      },
      "outputs": [],
      "source": [
        "class AR_Set_Model(torch.nn.Module):\n",
        "    def __init__(self, node_dim=4, emb_dim=16, out_dim=4):\n",
        "        super(AR_Set_Model, self).__init__()\n",
        "        self.node_embedding = torch.nn.Linear(node_dim, emb_dim)\n",
        "        self.conv1 = torch_geometric.nn.GCNConv(emb_dim, emb_dim)\n",
        "        self.conv2 = torch_geometric.nn.GCNConv(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.node_embedding(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cNsXs-DPrmKI"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_dataset, validation_dataset, batch_size=1, lr=0.0001, epochs=100, loss_fn=torch.nn.MSELoss(), model_name= \"01-AR-Set-Model.pt\"):\n",
        "        \"\"\"\n",
        "        Simple Trainer class to train a PyTorch (geometric) model on a dataset.\n",
        "\n",
        "        Args:\n",
        "            model: PyTorch model to train\n",
        "            train_dataset: PyTorch dataset to train on\n",
        "            validation_dataset: PyTorch dataset to validate on\n",
        "            batch_size: Batch size for training\n",
        "            lr: Learning rate\n",
        "            epochs: Number of epochs to train for\n",
        "            loss_fn: Loss function to use\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.validation_dataset = validation_dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"Using device:\", self.device)\n",
        "        self.model.to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "\n",
        "        self.train_loader = self.make_data_loader(self.train_dataset)\n",
        "        self.validation_loader = self.make_data_loader(self.validation_dataset, shuffle=False)\n",
        "\n",
        "    def make_data_loader(self, dataset, shuffle=True):\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
        "\n",
        "    def train_loop(self):\n",
        "        \"\"\"\n",
        "        Train loop for the model\n",
        "        \"\"\"\n",
        "        best_model_loss = np.inf\n",
        "        for epoch in range(self.epochs):\n",
        "            # Train the model\n",
        "            self.model.train()\n",
        "            mean_train_loss = 0\n",
        "            for i, data in enumerate(self.train_loader):\n",
        "                data = self.train_dataset[i].to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                out = self.model(data)\n",
        "                loss = self.loss_fn(out, data.y)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                mean_train_loss += loss.item()\n",
        "            mean_train_loss /= i\n",
        "\n",
        "            # Validate the model\n",
        "            self.model.eval()\n",
        "            mean_val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(self.validation_loader):\n",
        "                    data = self.validation_dataset[i].to(self.device)\n",
        "                    out = self.model(data)\n",
        "                    loss = self.loss_fn(out, data.y)\n",
        "                    mean_val_loss += loss.item()\n",
        "                mean_val_loss /= i\n",
        "\n",
        "            if mean_val_loss < best_model_loss:\n",
        "                best_model_loss = mean_val_loss\n",
        "                torch.save(self.model.state_dict(), f\"../../models/{self.model_name}\")\n",
        "\n",
        "            print(f\"Epoch {epoch}, Mean Train Loss: {mean_train_loss}, Mean Validation Loss: {mean_val_loss}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpg3JEUGrmKJ",
        "outputId": "ea78b0bd-8e68-42b8-ed5e-d654d7cb9d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Mean Train Loss: 116.65049430926852, Mean Validation Loss: 28.963502348265475\n",
            "Epoch 1, Mean Train Loss: 3.999818750549241, Mean Validation Loss: 23.93505015802086\n",
            "Epoch 2, Mean Train Loss: 3.606612415028586, Mean Validation Loss: 23.143549235506136\n",
            "Epoch 3, Mean Train Loss: 3.5958673077283922, Mean Validation Loss: 22.972979925194704\n",
            "Epoch 4, Mean Train Loss: 3.8856800639304767, Mean Validation Loss: 26.705327995526186\n",
            "Epoch 5, Mean Train Loss: 3.641617322566353, Mean Validation Loss: 23.2448399735686\n",
            "Epoch 6, Mean Train Loss: 3.96966714780724, Mean Validation Loss: 29.44930533819292\n",
            "Epoch 7, Mean Train Loss: 4.341298597513261, Mean Validation Loss: 28.406608962205937\n",
            "Epoch 8, Mean Train Loss: 4.264698102012141, Mean Validation Loss: 26.440589967415146\n",
            "Epoch 9, Mean Train Loss: 4.048862428761903, Mean Validation Loss: 25.958907586808515\n",
            "Epoch 10, Mean Train Loss: 4.140312838478007, Mean Validation Loss: 28.819224270135297\n",
            "Epoch 11, Mean Train Loss: 4.337253311962224, Mean Validation Loss: 25.429310548125052\n",
            "Epoch 12, Mean Train Loss: 4.221681306976974, Mean Validation Loss: 27.96522145301024\n",
            "Epoch 13, Mean Train Loss: 4.291111618710023, Mean Validation Loss: 27.987005381316663\n",
            "Epoch 14, Mean Train Loss: 4.302538974394597, Mean Validation Loss: 27.885380382317045\n",
            "Epoch 15, Mean Train Loss: 4.333533732603402, Mean Validation Loss: 27.272069135310918\n",
            "Epoch 16, Mean Train Loss: 4.297208934783681, Mean Validation Loss: 26.856314307541478\n",
            "Epoch 17, Mean Train Loss: 4.283017982949055, Mean Validation Loss: 26.37349987688175\n",
            "Epoch 18, Mean Train Loss: 4.217839708954526, Mean Validation Loss: 26.120514767783515\n",
            "Epoch 19, Mean Train Loss: 4.17436852849109, Mean Validation Loss: 26.2072160367125\n",
            "Epoch 20, Mean Train Loss: 4.178731857457393, Mean Validation Loss: 26.237304960312\n",
            "Epoch 21, Mean Train Loss: 4.169882026765032, Mean Validation Loss: 26.251990366491587\n",
            "Epoch 22, Mean Train Loss: 4.158838619921084, Mean Validation Loss: 26.22836353984775\n",
            "Epoch 23, Mean Train Loss: 4.138181858118752, Mean Validation Loss: 26.187612064587466\n",
            "Epoch 24, Mean Train Loss: 4.1224995256743195, Mean Validation Loss: 25.99364474174282\n",
            "Epoch 25, Mean Train Loss: 4.095797342313399, Mean Validation Loss: 25.702080734478823\n",
            "Epoch 26, Mean Train Loss: 4.06190244873386, Mean Validation Loss: 25.484739754312503\n",
            "Epoch 27, Mean Train Loss: 4.033481781074088, Mean Validation Loss: 25.192365457623108\n",
            "Epoch 28, Mean Train Loss: 4.002950645358691, Mean Validation Loss: 25.028489126441528\n",
            "Epoch 29, Mean Train Loss: 3.974400211131579, Mean Validation Loss: 24.688266429111348\n",
            "Epoch 30, Mean Train Loss: 3.9165054483968693, Mean Validation Loss: 24.20933911191069\n",
            "Epoch 31, Mean Train Loss: 3.868539692976229, Mean Validation Loss: 23.9217960785673\n",
            "Epoch 32, Mean Train Loss: 3.8414827522528854, Mean Validation Loss: 23.87360739623025\n",
            "Epoch 33, Mean Train Loss: 3.831359902009949, Mean Validation Loss: 23.55695438321318\n",
            "Epoch 34, Mean Train Loss: 3.791062020803605, Mean Validation Loss: 23.497475119223047\n",
            "Epoch 35, Mean Train Loss: 3.765966570288245, Mean Validation Loss: 23.373366338274675\n",
            "Epoch 36, Mean Train Loss: 3.7475840646954572, Mean Validation Loss: 23.351574477189796\n",
            "Epoch 37, Mean Train Loss: 3.7336117956833093, Mean Validation Loss: 23.361948881421043\n",
            "Epoch 38, Mean Train Loss: 3.7328608429692864, Mean Validation Loss: 23.138738704173562\n",
            "Epoch 39, Mean Train Loss: 3.7138002702913626, Mean Validation Loss: 22.540530817909953\n",
            "Epoch 40, Mean Train Loss: 3.64331569852386, Mean Validation Loss: 22.751004119908714\n",
            "Epoch 41, Mean Train Loss: 3.6951609890663364, Mean Validation Loss: 23.014392703320443\n",
            "Epoch 42, Mean Train Loss: 3.7250406918077625, Mean Validation Loss: 23.188912803109798\n",
            "Epoch 43, Mean Train Loss: 3.6695212030308935, Mean Validation Loss: 22.0580054556591\n",
            "Epoch 44, Mean Train Loss: 3.6103010440789247, Mean Validation Loss: 22.642030226579227\n",
            "Epoch 45, Mean Train Loss: 3.5913765456863604, Mean Validation Loss: 22.17845629435613\n",
            "Epoch 46, Mean Train Loss: 3.5475802996931263, Mean Validation Loss: 20.470840353256662\n",
            "Epoch 47, Mean Train Loss: 3.515361147835747, Mean Validation Loss: 19.866194650729852\n",
            "Epoch 48, Mean Train Loss: 3.539165712141189, Mean Validation Loss: 19.622806480073123\n",
            "Epoch 49, Mean Train Loss: 3.596768627686101, Mean Validation Loss: 18.01200665752482\n",
            "Epoch 50, Mean Train Loss: 3.673161851169588, Mean Validation Loss: 16.91518217903742\n",
            "Epoch 51, Mean Train Loss: 3.8340698465012766, Mean Validation Loss: 16.650430968056167\n",
            "Epoch 52, Mean Train Loss: 4.048677157827449, Mean Validation Loss: 16.906318442267388\n",
            "Epoch 53, Mean Train Loss: 4.28256395715351, Mean Validation Loss: 17.438662611153756\n",
            "Epoch 54, Mean Train Loss: 4.573076854112373, Mean Validation Loss: 18.95151221210789\n",
            "Epoch 55, Mean Train Loss: 4.898711173564943, Mean Validation Loss: 20.85671665598427\n",
            "Epoch 56, Mean Train Loss: 5.191992271729351, Mean Validation Loss: 20.790851382623266\n",
            "Epoch 57, Mean Train Loss: 5.4192181701846005, Mean Validation Loss: 21.09099023913233\n",
            "Epoch 58, Mean Train Loss: 5.371638383925184, Mean Validation Loss: 21.256126888288733\n",
            "Epoch 59, Mean Train Loss: 5.236780999277087, Mean Validation Loss: 20.63421517085095\n",
            "Epoch 60, Mean Train Loss: 5.113670866787275, Mean Validation Loss: 19.212743717118872\n",
            "Epoch 61, Mean Train Loss: 5.10503948788177, Mean Validation Loss: 19.873772279555947\n",
            "Epoch 62, Mean Train Loss: 5.24257202248362, Mean Validation Loss: 18.74100460182421\n",
            "Epoch 63, Mean Train Loss: 5.046564856316403, Mean Validation Loss: 17.554563469687213\n",
            "Epoch 64, Mean Train Loss: 4.834029437575312, Mean Validation Loss: 17.396328554340272\n",
            "Epoch 65, Mean Train Loss: 4.639944642066192, Mean Validation Loss: 15.917367650479582\n",
            "Epoch 66, Mean Train Loss: 4.473270005073639, Mean Validation Loss: 16.213955743123883\n",
            "Epoch 67, Mean Train Loss: 4.389845596903858, Mean Validation Loss: 16.004600804508105\n",
            "Epoch 68, Mean Train Loss: 4.323767520340127, Mean Validation Loss: 15.644881306221096\n",
            "Epoch 69, Mean Train Loss: 4.284544916440635, Mean Validation Loss: 15.387193170065128\n",
            "Epoch 70, Mean Train Loss: 4.157935949455145, Mean Validation Loss: 15.937447848536559\n",
            "Epoch 71, Mean Train Loss: 4.132752708776457, Mean Validation Loss: 15.158678285797473\n",
            "Epoch 72, Mean Train Loss: 4.065920349435252, Mean Validation Loss: 14.635397423831671\n",
            "Epoch 73, Mean Train Loss: 4.023540227634666, Mean Validation Loss: 14.198083752940407\n",
            "Epoch 74, Mean Train Loss: 3.9766557251331456, Mean Validation Loss: 13.872688029137235\n",
            "Epoch 75, Mean Train Loss: 3.936166522373061, Mean Validation Loss: 13.56136761853871\n",
            "Epoch 76, Mean Train Loss: 3.9367457236826136, Mean Validation Loss: 13.179030292923708\n",
            "Epoch 77, Mean Train Loss: 3.874408035117932, Mean Validation Loss: 12.851741419025329\n",
            "Epoch 78, Mean Train Loss: 3.865745695975141, Mean Validation Loss: 12.880500927209217\n",
            "Epoch 79, Mean Train Loss: 3.7986720560771925, Mean Validation Loss: 12.643869357775708\n",
            "Epoch 80, Mean Train Loss: 3.818929586318872, Mean Validation Loss: 12.743642227626335\n",
            "Epoch 81, Mean Train Loss: 3.7886067198612317, Mean Validation Loss: 12.418098597683656\n",
            "Epoch 82, Mean Train Loss: 3.765461130506268, Mean Validation Loss: 12.454288865239729\n",
            "Epoch 83, Mean Train Loss: 3.7067840637781373, Mean Validation Loss: 12.24464417119591\n",
            "Epoch 84, Mean Train Loss: 3.685148113211781, Mean Validation Loss: 12.491571072691377\n",
            "Epoch 85, Mean Train Loss: 3.673548760575785, Mean Validation Loss: 12.287273305500605\n",
            "Epoch 86, Mean Train Loss: 3.68526944494222, Mean Validation Loss: 11.4850675308163\n",
            "Epoch 87, Mean Train Loss: 3.5995567309557277, Mean Validation Loss: 11.891948580848036\n",
            "Epoch 88, Mean Train Loss: 3.4837988502382276, Mean Validation Loss: 12.014864760854897\n",
            "Epoch 89, Mean Train Loss: 3.44081392013893, Mean Validation Loss: 11.848976239707994\n",
            "Epoch 90, Mean Train Loss: 3.4251777312046565, Mean Validation Loss: 11.725107693396184\n",
            "Epoch 91, Mean Train Loss: 3.4034420053270242, Mean Validation Loss: 11.601105200214676\n",
            "Epoch 92, Mean Train Loss: 3.380735242360426, Mean Validation Loss: 11.551260911664682\n",
            "Epoch 93, Mean Train Loss: 3.3606564877698974, Mean Validation Loss: 11.428455484836949\n",
            "Epoch 94, Mean Train Loss: 3.3310067221816695, Mean Validation Loss: 11.375095551500126\n",
            "Epoch 95, Mean Train Loss: 3.3107149845065753, Mean Validation Loss: 11.334750058495988\n",
            "Epoch 96, Mean Train Loss: 3.287323355833859, Mean Validation Loss: 11.298907719652036\n",
            "Epoch 97, Mean Train Loss: 3.2686645105059493, Mean Validation Loss: 11.30144101705067\n",
            "Epoch 98, Mean Train Loss: 3.2466568039243895, Mean Validation Loss: 11.231516376310232\n",
            "Epoch 99, Mean Train Loss: 3.281781305461024, Mean Validation Loss: 11.618964323059108\n"
          ]
        }
      ],
      "source": [
        "model = AR_Set_Model(emb_dim=64)\n",
        "trainer = Trainer(model, train_dataset, validation_dataset, batch_size=8, loss_fn=torch.nn.MSELoss(), epochs=100, model_name=\"01-AR-Set-Model.pt\")\n",
        "trainer.train_loop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuWZhjDjrmKJ"
      },
      "source": [
        "### Q1: Implementing rollout code\n",
        "\n",
        "We have a working model now to predict $\\hat{X}^{t+1}$ given $X^t$. However, we of course want to be able to generate trajectories longer than one step (ie for i steps: $\\hat{X}^{t+1:t+i}$), given $X^t$.\n",
        "\n",
        "We sometimes call this a `rollout` - essentially a multi-step prediction.\n",
        "\n",
        "Q1: Complete the method below, which generates a rollout of `timesteps` steps, for a given model `model`, and dataset `dataset` *.\n",
        "\n",
        "HINT: What should happen if the position $x_i, y_i$ of boid $i$ are predicted to move $dx_i, dy_i$, such that $x_i + dx_i > \\text{width}$ or $y_i + dy_i > \\text{height}$?\n",
        "\n",
        "*: If you check the cell below the next cell, we already made a dataset for you that only contains initial positions :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d1cWzXEsrmKJ"
      },
      "outputs": [],
      "source": [
        "def compute_ar_set_model_rollouts(model, dataset, timesteps=1000, device='cuda', mode=\"residual\", width = 1000, height = 1000):\n",
        "    \"\"\"\n",
        "    Predict the rollouts of the model on the dataset starting from the idx\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        dataset: PyTorch dataset\n",
        "        timesteps: Number of timesteps to predict\n",
        "        device: Device to run the model on\n",
        "        mode: \"residual\" or \"direct\"\n",
        "        - In the solution above, we used the \"residual\" mode, where the model predicts the change in position and change in velocity\n",
        "        - In the \"direct\" mode, the model predicts the position and velocity directly (if you do not intend to use this mode, you can ignore this argument)\n",
        "        width: Width of the PBC box\n",
        "        height: Height of the PBC box\n",
        "    Returns:\n",
        "        rollouts: Rollouts of the model on the dataset\n",
        "        - Should be a torch tensor of shape (Batch, Timesteps, Boids, Node_dim)\n",
        "    \"\"\"\n",
        "    rollouts = torch.empty((len(dataset), timesteps, dataset[0].x.shape[0], dataset[0].x.shape[1]), device=device)\n",
        "    print(rollouts.shape)\n",
        "\n",
        "    # new code below\n",
        "    model.eval()\n",
        "    dtype = dataset[0].x.dtype\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b in range(len(dataset)):\n",
        "            data = dataset[b]\n",
        "            # current state (N, F) and graph\n",
        "            x_t = data.x.to(device=device, dtype=dtype)           # [x, y, vx, vy]\n",
        "            edge_index = data.edge_index.to(device)\n",
        "\n",
        "            for t in range(timesteps):\n",
        "                # one-step prediction\n",
        "                if mode == \"residual\":\n",
        "                    delta = model(Data(x=x_t, edge_index=edge_index))   # predicts Δ[x, y, vx, vy]\n",
        "                    x_next = x_t + delta\n",
        "                else:  # \"direct\"\n",
        "                    x_next = model(Data(x=x_t, edge_index=edge_index))  # predicts next [x, y, vx, vy]\n",
        "\n",
        "                # Periodic Boundary Conditions (wrap positions only)\n",
        "                x_next[:, 0] = (x_next[:, 0] + width) % width    # x\n",
        "                x_next[:, 1] = (x_next[:, 1] + height) % height  # y\n",
        "\n",
        "                # store & advance\n",
        "                rollouts[b, t] = x_next\n",
        "                x_t = x_next.detach()\n",
        "\n",
        "\n",
        "    return rollouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd3gozl3rmKK",
        "outputId": "3750cd5b-bfef-4639-f857-d9bf6d036a33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_14484\\412190819.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ar_set_model.load_state_dict(torch.load(\"../../models/01-AR-Set-Model.pt\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9, 1000, 25, 4])\n"
          ]
        }
      ],
      "source": [
        "def keep_01(data):\n",
        "    return data[0:2, :, :]\n",
        "\n",
        "initial_states_validation_dataset = AR_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(16, 25),\n",
        "    timesteps=2,\n",
        "    processed_file_name=\"AR1_VAL_init.pt\",\n",
        "    transform=keep_01\n",
        "    )\n",
        "\n",
        "ar_set_model = AR_Set_Model(emb_dim=64)\n",
        "ar_set_model.load_state_dict(torch.load(\"../../models/01-AR-Set-Model.pt\"))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "ar_set_model.to(device)\n",
        "ar_set_model.eval()\n",
        "\n",
        "ar_set_model_rollout = compute_ar_set_model_rollouts(ar_set_model, initial_states_validation_dataset, timesteps=1000, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbS5GCwdrmKK"
      },
      "source": [
        "We'll evaluate these rollouts later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLUTonFXrmKK"
      },
      "source": [
        "### Quick recap on equivariances\n",
        "\n",
        "<img src=\"figures/boids-translational-equivariance.png\" alt=\"drawing\" width=\"250\" style=\"background-color: white; padding: 50px;\"/>\n",
        "<img src=\"figures/boids-rotational-equivariance.png\" alt=\"drawing\" width=\"250\" style=\"background-color: white; padding: 50px;\"/>\n",
        "\n",
        "The figures above show the equivariances of the Boids system. The system is equivariant to all E(n) transformations; translation,\n",
        "rotation and reflection.*\n",
        "\n",
        "Formally, we say a function $f: X \\rarr Y$ is _equivariant_ to a group action or transformation $T: X \\rarr X$ if there is an equivalent transformation $S: Y \\rarr Y$ on the output space of the function such that\n",
        "\n",
        "$f(T(x)) = S(f(x))$ for each $x \\in X$\n",
        "\n",
        "We won't go into the formal definitions of each equivariance, but if you're interested you can check out the [E(n) Equivariant Graph Neural Networks](https://arxiv.org/pdf/2102.09844) paper [3], the equivariant model is based on.\n",
        "\n",
        "*: Excluding time translation equivariance, which states that there is no dependence on the time of the system, only the state.\n",
        "\n",
        "*: Also excluding permutational equivariance; the order of the nodes does not matter.\n",
        "\n",
        "## Towards Equivariant AR-GNNs\n",
        "The above model is **not** equivariant to translations in space! This is because we use absolute coordinates as _node features_, which creates a dependence on the absolute coordinate system. Instead, if we do not use the absolute positions as node features - and include the PBC distance as _edge features_ - the predictions will be space translation equivariant.\n",
        "\n",
        "Let's implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLQCTgi-rmKK"
      },
      "source": [
        "Before, we were not using the fact that boids only affect eachother within a certain radius, since we used a fully connected graph without edge weights.\n",
        "\n",
        "Before blindly jumping into the new dataset code, let's investigate this behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "cgKvSXIermKK",
        "outputId": "5b545635-25b4-4405-e045-d87710e2b9b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot timesteps 0, 250, 500, 750, 999 for the first trajectory\n",
        "trajectory = trajectories[0]\n",
        "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
        "fig.suptitle(\"Boids with radius of effect\")\n",
        "radius = 40\n",
        "\n",
        "for i, t in enumerate([0, 250, 500, 750, 999]):\n",
        "    axs[i].set_title(f\"Timestep {t}\")\n",
        "    # Plot dots for the boids\n",
        "    axs[i].scatter(trajectory[t, :, 0], trajectory[t, :, 1])\n",
        "    # Draw a red circle around each boid to indicate the radius\n",
        "    for j in range(trajectory.shape[1]):\n",
        "        circle = plt.Circle((trajectory[t, j, 0], trajectory[t, j, 1]), radius, color='r', fill=False)\n",
        "        axs[i].add_artist(circle)\n",
        "    # plot the boid velocities as arrows\n",
        "    for j in range(trajectory.shape[1]):\n",
        "        # NOTE: The arrows are made larger for effect\n",
        "        axs[i].arrow(trajectory[t, j, 0], trajectory[t, j, 1], trajectory[t, j, 2]*5, trajectory[t, j, 3]*5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOfB5OZMrmKK"
      },
      "source": [
        "Above, we show the boids with their radius of effect. As expected, boids who are farther than `radius=40` units away from eachother, are shown to not affect eachother.\n",
        "\n",
        "## Q2: Implement your own model\n",
        "\n",
        "As discussed above, the Boids system is equivariant to\n",
        "- Permutation\n",
        "- Translation\n",
        "- Rotation/Reflection\n",
        "\n",
        "Your next task is to build a model that is equivariant to permutation and translation. Make sure your model adheres to the PBC, either via the loss function or position updates.\n",
        "\n",
        "For this you will have to code up:\n",
        "\n",
        "1. The `InMemoryDataset` used when training your model.\n",
        "2. The Permutation/Translation Equivariant model `TranslationalEquivariantModel`\n",
        "3. Possibly a new rollout method `model2_rollouts`\n",
        "    - HINT: Depending on your design choices, you may need to store the initial coordinates of your nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "utFRwDyRrmKK"
      },
      "outputs": [],
      "source": [
        "from tqdm import trange\n",
        "\n",
        "class Equivariant_Boids_Dataset(InMemoryDataset):\n",
        "    def __init__(self, raw_data_path, processed_data_path, root=None, transform=None, pre_transform=None, post_transform=None, solution_idx_range=(0, 25), timesteps=1000, processed_file_name=\"AR1_Boids.pt\", L = 1000):\n",
        "        self.raw_data_path = raw_data_path\n",
        "        self.processed_data_path = processed_data_path\n",
        "        self.solution_idx_range = solution_idx_range\n",
        "        self.timesteps = timesteps\n",
        "        self.processed_file_name = processed_file_name\n",
        "        self.pre_transform = pre_transform\n",
        "        self.transform = transform\n",
        "        self.post_transform = post_transform\n",
        "        self.L = L\n",
        "        super(Equivariant_Boids_Dataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.processed_file_name]\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [pfn for pfn in os.listdir(self.raw_data_path) if (self.solution_idx_range[0] <= int(pfn.split(\"_\")[-1][:-4]) < self.solution_idx_range[1])]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.timesteps - 1) * (self.solution_idx_range[1] - self.solution_idx_range[0])\n",
        "\n",
        "    def process(self):\n",
        "        # TODO: TODO: TODO: TODO: TODO:\n",
        "        \"\"\"\n",
        "        Your code goes here.\n",
        "\n",
        "        Process the raw data and save the processed data to disk, see the AR_Boids_Dataset for an example.\n",
        "\n",
        "        HINT: Make sure your learning task adheres to the PBC constraints - depending on your approach,\n",
        "        you may need to include the PBC constraints in the data processing step.\n",
        "        \"\"\"\n",
        "        data_list = []\n",
        "\n",
        "        # gather raw files in selected range and sort by numeric id\n",
        "        raw_files = self.raw_file_names\n",
        "        raw_files = sorted(raw_files, key=lambda p: int(p.split(\"_\")[-1][:-4]))\n",
        "\n",
        "        init_positions_list = []\n",
        "\n",
        "        for pfn in raw_files:\n",
        "            traj = np.load(os.path.join(self.raw_data_path, pfn))  # (T, N, 4) with [x,y,vx,vy]\n",
        "            T, N, F = traj.shape\n",
        "            T = min(T, self.timesteps)\n",
        "\n",
        "            # store initial positions for this trajectory (for equivariant rollouts)\n",
        "            pos0 = torch.from_numpy(traj[0, :, :2]).float()  # (N,2)\n",
        "            init_positions_list.append(pos0)\n",
        "\n",
        "            # prebuild complete directed graph (no self-loops)\n",
        "            recv, send = [], []\n",
        "            for i in range(N):\n",
        "                for j in range(N):\n",
        "                    if i != j:\n",
        "                        recv.append(i); send.append(j)\n",
        "            edge_index = torch.tensor([recv, send], dtype=torch.long)\n",
        "\n",
        "            # build AR pairs (t -> t+1)\n",
        "            pos = traj[:T, :, :2]  # (T,N,2)\n",
        "            vel = traj[:T, :, 2:]  # (T,N,2)\n",
        "\n",
        "            for t in range(T - 1):\n",
        "                x_t = np.concatenate([pos[t], vel[t]], axis=-1)  # (N,4)\n",
        "\n",
        "                # residual targets with PBC (minimum image convention)\n",
        "                dpos = pos[t + 1] - pos[t]                        # (N,2)\n",
        "                dpos = (dpos + self.L / 2.0) % self.L - self.L / 2.0\n",
        "                dvel = vel[t + 1] - vel[t]                        # (N,2)\n",
        "\n",
        "                y_res = np.concatenate([dpos, dvel], axis=-1)     # (N,4)\n",
        "\n",
        "                data_list.append(\n",
        "                    Data(\n",
        "                        x=torch.from_numpy(x_t).float(),\n",
        "                        y=torch.from_numpy(y_res).float(),\n",
        "                        edge_index=edge_index.clone(),\n",
        "                        pos0=pos0.clone(),  # keep initial positions if needed by rollout\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # collate & save dataset\n",
        "        data, slices = self.collate(data_list)\n",
        "        os.makedirs(self.processed_data_path, exist_ok=True)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "        # also save stack of initial positions expected by the notebook\n",
        "        init_positions = torch.stack(init_positions_list, dim=0)  # (num_traj, N, 2)\n",
        "        positions_fname = f\"positions_{self.processed_file_name[:-3]}.pt\"\n",
        "        torch.save(init_positions, os.path.join(self.processed_data_path, positions_fname))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.get(idx)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}({len(self)})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5NGNzO-ormKL"
      },
      "outputs": [],
      "source": [
        "equivariant_train_dataset = Equivariant_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(0, 15),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"AR1_Boids_Equivariant.pt\"\n",
        "    )\n",
        "\n",
        "equivariant_validation_dataset = Equivariant_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(16, 25),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"AR1_VAL_Boids_Equivariant.pt\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DR_AepNrmKL",
        "outputId": "5ba93f89-2a66-4b12-9bed-fd9de50bd416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([15, 25, 2])\n",
            "torch.Size([9, 25, 2])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_14484\\3519763002.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  init_positions = torch.load(\"../../data/boids/processed/positions_AR1_Boids_Equivariant.pt\")\n",
            "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_14484\\3519763002.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  init_val_positions = torch.load(\"../../data/boids/processed/positions_AR1_VAL_Boids_Equivariant.pt\")\n"
          ]
        }
      ],
      "source": [
        "init_positions = torch.load(\"../../data/boids/processed/positions_AR1_Boids_Equivariant.pt\")\n",
        "print(init_positions.shape)\n",
        "init_val_positions = torch.load(\"../../data/boids/processed/positions_AR1_VAL_Boids_Equivariant.pt\")\n",
        "print(init_val_positions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiYTCJoCrmKL"
      },
      "outputs": [],
      "source": [
        "class TranslationalEquivariantModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TranslationalEquivariantModel, self).__init__()\n",
        "        # TODO: TODO: TODO: TODO: TODO:\n",
        "        self.L = 1000.0  # box size for PBC (wrap relative vectors via minimum-image)\n",
        "        hidden = 128\n",
        "        nn = torch.nn\n",
        "\n",
        "        # Edge MLP: [v_i(2), v_j(2), ||r_ij||^2(1)] -> H\n",
        "        self.phi_e = nn.Sequential(\n",
        "            nn.Linear(2 + 2 + 1, hidden), nn.SiLU(),\n",
        "            nn.Linear(hidden, hidden),   nn.SiLU(),\n",
        "        )\n",
        "\n",
        "        # Node MLP: [v_i(2), agg_msg(H)] -> Δv(2)\n",
        "        self.phi_h = nn.Sequential(\n",
        "            nn.Linear(2 + hidden, hidden), nn.SiLU(),\n",
        "            nn.Linear(hidden, 2),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        # TODO: TODO: TODO: TODO: TODO:\n",
        "        \n",
        "        \"\"\"\n",
        "        Your code goes here\n",
        "        \"\"\"\n",
        "        \n",
        "        # NOTE: You may use different data attributes instead of x, edge_index, edge_attr\n",
        "        # But you should pass a Data object to the model\n",
        "        # (see the AR_Set_Model for an example and the Trainer class for how this is used)\n",
        "\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "\n",
        "        pos, vel = x[:, :2], x[:, 2:]               \n",
        "        N = pos.size(0)      \n",
        "        i = edge_index[0]\n",
        "        j = edge_index[1]\n",
        "\n",
        "        # minimum-image relative vector \n",
        "\n",
        "        rij = pos[i] - pos[j]\n",
        "        L = torch.tensor(self.L, device=pos.device, dtype=pos.dtype)\n",
        "        rij = (rij + L / 2) % L - L / 2\n",
        "        dij2 = (rij * rij).sum(-1, keepdim=True)    \n",
        "\n",
        "        # edge messages \n",
        "        m_ij = self.phi_e(torch.cat([vel[i], vel[j], dij2], dim=-1))  \n",
        "\n",
        "        # symmetric aggregation (mean) -> permutation equivariant\n",
        "        m_i = torch.zeros(N, m_ij.size(-1), device=x.device, dtype=x.dtype)\n",
        "        m_i.index_add_(0, i, m_ij)                  # sum into receiver i\n",
        "        deg = torch.bincount(i, minlength=N).clamp_min(1).to(x.device)\n",
        "        m_i = m_i / deg.view(N, 1)\n",
        "\n",
        "        # velocity update and integrate to get Δx (Δt=1)\n",
        "        dv = self.phi_h(torch.cat([vel, m_i], dim=-1))   \n",
        "        v_next = vel + dv\n",
        "        dx = v_next                                      \n",
        "\n",
        "        y = torch.cat([dx, dv], dim=-1)                  \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPyezwzJrmKL",
        "outputId": "83aa6c4a-332d-448e-e799-485bca8e6c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Mean Train Loss: 10424.436787567462, Mean Validation Loss: 0.014236949652081766\n",
            "Epoch 1, Mean Train Loss: 7.726957827430936, Mean Validation Loss: 330.0375371238321\n",
            "Epoch 2, Mean Train Loss: 59.08364051277476, Mean Validation Loss: 7.041840577911078\n",
            "Epoch 3, Mean Train Loss: 103.59289891357102, Mean Validation Loss: 724.794149234055\n",
            "Epoch 4, Mean Train Loss: 91.07769559357814, Mean Validation Loss: 0.226452411256087\n",
            "Epoch 5, Mean Train Loss: 110.34524526505894, Mean Validation Loss: 4191.523440761006\n",
            "Epoch 6, Mean Train Loss: 85.4128036220969, Mean Validation Loss: 54.32888932538054\n",
            "Epoch 7, Mean Train Loss: 116.43239782244416, Mean Validation Loss: 0.012441345923003853\n",
            "Epoch 8, Mean Train Loss: 58.19735709681084, Mean Validation Loss: 99.84855134850194\n",
            "Epoch 9, Mean Train Loss: 89.08308764973579, Mean Validation Loss: 0.010728786767918396\n",
            "Epoch 10, Mean Train Loss: 46.57921238409185, Mean Validation Loss: 4345.946339499388\n",
            "Epoch 11, Mean Train Loss: 77.26396189324257, Mean Validation Loss: 0.012156168786242426\n",
            "Epoch 12, Mean Train Loss: 87.3314434534501, Mean Validation Loss: 0.010595415566453586\n",
            "Epoch 13, Mean Train Loss: 46.66859270130315, Mean Validation Loss: 0.010837552303147485\n",
            "Epoch 14, Mean Train Loss: 68.93311020300429, Mean Validation Loss: 0.012402225277579008\n",
            "Epoch 15, Mean Train Loss: 41.933673229211685, Mean Validation Loss: 0.012211604433309185\n",
            "Epoch 16, Mean Train Loss: 48.9353588241822, Mean Validation Loss: 0.03338976169066406\n",
            "Epoch 17, Mean Train Loss: 51.501522711753495, Mean Validation Loss: 0.011197610207319589\n",
            "Epoch 18, Mean Train Loss: 37.8414241502721, Mean Validation Loss: 16.30244698104111\n",
            "Epoch 19, Mean Train Loss: 36.73955324179669, Mean Validation Loss: 5.610017960345437\n",
            "Epoch 20, Mean Train Loss: 46.44721930725369, Mean Validation Loss: 0.015160877497050702\n",
            "Epoch 21, Mean Train Loss: 31.672727745504908, Mean Validation Loss: 745.6880373593855\n",
            "Epoch 22, Mean Train Loss: 37.69881887141828, Mean Validation Loss: 0.010733366985439396\n",
            "Epoch 23, Mean Train Loss: 26.30049845836016, Mean Validation Loss: 28.31161988513977\n",
            "Epoch 24, Mean Train Loss: 31.35332085704846, Mean Validation Loss: 570.0157189713136\n",
            "Epoch 25, Mean Train Loss: 27.12349996817768, Mean Validation Loss: 0.010387913614951234\n",
            "Epoch 26, Mean Train Loss: 34.180877704201706, Mean Validation Loss: 0.010693341771220308\n",
            "Epoch 27, Mean Train Loss: 20.586377835343825, Mean Validation Loss: 129.77149665132762\n",
            "Epoch 28, Mean Train Loss: 26.33792341947938, Mean Validation Loss: 0.011106574541859275\n",
            "Epoch 29, Mean Train Loss: 18.581110849877824, Mean Validation Loss: 127.50012877575543\n",
            "Epoch 30, Mean Train Loss: 25.217233546995683, Mean Validation Loss: 0.273270661039535\n",
            "Epoch 31, Mean Train Loss: 17.348139740452325, Mean Validation Loss: 69.27397466236634\n",
            "Epoch 32, Mean Train Loss: 23.868675812851713, Mean Validation Loss: 0.010886534166195573\n",
            "Epoch 33, Mean Train Loss: 23.449213954977203, Mean Validation Loss: 0.011208370221123176\n",
            "Epoch 34, Mean Train Loss: 20.982976953504846, Mean Validation Loss: 0.012882968817629377\n",
            "Epoch 35, Mean Train Loss: 30.555508014907176, Mean Validation Loss: 5.3637087965054056\n",
            "Epoch 36, Mean Train Loss: 13.72569723090807, Mean Validation Loss: 0.014327532585456517\n",
            "Epoch 37, Mean Train Loss: 14.733551474412415, Mean Validation Loss: 0.011911157115059055\n",
            "Epoch 38, Mean Train Loss: 16.251190844141885, Mean Validation Loss: 0.011519655702429975\n",
            "Epoch 39, Mean Train Loss: 14.442053391670077, Mean Validation Loss: 1.0474582929114413\n",
            "Epoch 40, Mean Train Loss: 12.598267832721065, Mean Validation Loss: 262.37730425378624\n",
            "Epoch 41, Mean Train Loss: 10.047478570380267, Mean Validation Loss: 0.18439253418974227\n",
            "Epoch 42, Mean Train Loss: 15.573310589280142, Mean Validation Loss: 1.8783268188644708\n",
            "Epoch 43, Mean Train Loss: 9.00634378479655, Mean Validation Loss: 0.070258203409579\n",
            "Epoch 44, Mean Train Loss: 12.731783141279896, Mean Validation Loss: 33.22232838135581\n",
            "Epoch 45, Mean Train Loss: 8.852523320530823, Mean Validation Loss: 53.17658152117436\n",
            "Epoch 46, Mean Train Loss: 8.677649000262992, Mean Validation Loss: 0.011877658676902597\n",
            "Epoch 47, Mean Train Loss: 7.620480282631345, Mean Validation Loss: 0.053216257947808064\n",
            "Epoch 48, Mean Train Loss: 6.4159280602834885, Mean Validation Loss: 0.4892596033196946\n",
            "Epoch 49, Mean Train Loss: 5.668754106347236, Mean Validation Loss: 0.017434263606875045\n",
            "Epoch 50, Mean Train Loss: 6.236438584062293, Mean Validation Loss: 0.029719876035888708\n",
            "Epoch 51, Mean Train Loss: 4.275031010430869, Mean Validation Loss: 23.74339459182318\n",
            "Epoch 52, Mean Train Loss: 10.872601368982766, Mean Validation Loss: 0.010163775837325776\n",
            "Epoch 53, Mean Train Loss: 1.5686960126603855, Mean Validation Loss: 187.77768311199077\n",
            "Epoch 54, Mean Train Loss: 8.13983733238291, Mean Validation Loss: 25.752402885620445\n",
            "Epoch 55, Mean Train Loss: 3.205949181000183, Mean Validation Loss: 0.056318369799377335\n",
            "Epoch 56, Mean Train Loss: 3.4538260533044967, Mean Validation Loss: 0.011705928602262515\n",
            "Epoch 57, Mean Train Loss: 3.3292872010744636, Mean Validation Loss: 0.011170227020665446\n",
            "Epoch 58, Mean Train Loss: 2.1689224797097904, Mean Validation Loss: 47.946953740378945\n",
            "Epoch 59, Mean Train Loss: 5.816672133247747, Mean Validation Loss: 0.2375155270550788\n",
            "Epoch 60, Mean Train Loss: 2.6048614295601094, Mean Validation Loss: 80.01715380362072\n",
            "Epoch 61, Mean Train Loss: 2.4972565134078177, Mean Validation Loss: 0.014627479554800017\n",
            "Epoch 62, Mean Train Loss: 2.0805449604735005, Mean Validation Loss: 0.010880618383743048\n",
            "Epoch 63, Mean Train Loss: 1.8963748991345841, Mean Validation Loss: 10.494938278877619\n",
            "Epoch 64, Mean Train Loss: 2.792064369211638, Mean Validation Loss: 0.010310685089702771\n",
            "Epoch 65, Mean Train Loss: 1.297199823645583, Mean Validation Loss: 3.1587415520675672\n",
            "Epoch 66, Mean Train Loss: 1.3981898219767235, Mean Validation Loss: 22.47671934078553\n",
            "Epoch 67, Mean Train Loss: 4.877012980359505, Mean Validation Loss: 0.011580899154716806\n",
            "Epoch 68, Mean Train Loss: 3.0812664427087295, Mean Validation Loss: 15.34333257343975\n",
            "Epoch 69, Mean Train Loss: 0.7981197757859643, Mean Validation Loss: 6.5845616061243755\n",
            "Epoch 70, Mean Train Loss: 1.5602978440419595, Mean Validation Loss: 0.011352472594223471\n",
            "Epoch 71, Mean Train Loss: 4.166719858787028, Mean Validation Loss: 0.010684529717114711\n",
            "Epoch 72, Mean Train Loss: 0.29476161665565154, Mean Validation Loss: 0.5009243311567808\n",
            "Epoch 73, Mean Train Loss: 0.481596790320062, Mean Validation Loss: 0.011053325524922702\n",
            "Epoch 74, Mean Train Loss: 0.6198690572727529, Mean Validation Loss: 2.3563971706298665\n",
            "Epoch 75, Mean Train Loss: 3.6381385959030674, Mean Validation Loss: 0.011278535940482025\n",
            "Epoch 76, Mean Train Loss: 0.17082902843515052, Mean Validation Loss: 1.4946600775153958\n",
            "Epoch 77, Mean Train Loss: 1.8863745342406077, Mean Validation Loss: 0.010548441990238543\n",
            "Epoch 78, Mean Train Loss: 0.7678739820342602, Mean Validation Loss: 0.010334318323387\n",
            "Epoch 79, Mean Train Loss: 0.6859775740126609, Mean Validation Loss: 0.012379168074176657\n",
            "Epoch 80, Mean Train Loss: 5.435381309857841, Mean Validation Loss: 0.011134767020255981\n",
            "Epoch 81, Mean Train Loss: 0.005137902479625314, Mean Validation Loss: 0.010429815714852304\n",
            "Epoch 82, Mean Train Loss: 0.9507518924241152, Mean Validation Loss: 0.011265737168834639\n",
            "Epoch 83, Mean Train Loss: 0.1953434900274923, Mean Validation Loss: 0.010425357579451407\n",
            "Epoch 84, Mean Train Loss: 0.9446562154756066, Mean Validation Loss: 0.01026728151081348\n",
            "Epoch 85, Mean Train Loss: 0.39520688351856154, Mean Validation Loss: 0.010187409481042287\n",
            "Epoch 86, Mean Train Loss: 0.2982837986324289, Mean Validation Loss: 0.010209100348976518\n",
            "Epoch 87, Mean Train Loss: 2.435473676831631, Mean Validation Loss: 0.010788120233334803\n",
            "Epoch 88, Mean Train Loss: 0.07229306395854217, Mean Validation Loss: 0.010042827754241913\n",
            "Epoch 89, Mean Train Loss: 0.420465962455402, Mean Validation Loss: 0.01111188460937979\n",
            "Epoch 90, Mean Train Loss: 0.7511421869337702, Mean Validation Loss: 0.010109569143194674\n",
            "Epoch 91, Mean Train Loss: 0.8649551722168898, Mean Validation Loss: 0.010159395379011721\n",
            "Epoch 92, Mean Train Loss: 0.9837535227470371, Mean Validation Loss: 0.010385798849745961\n",
            "Epoch 93, Mean Train Loss: 0.004570670247845542, Mean Validation Loss: 0.0099852880724038\n",
            "Epoch 94, Mean Train Loss: 0.6201842324799247, Mean Validation Loss: 0.009908403354894029\n",
            "Epoch 95, Mean Train Loss: 0.004448068876525589, Mean Validation Loss: 0.009903703054164353\n",
            "Epoch 96, Mean Train Loss: 0.8070563437193193, Mean Validation Loss: 0.01027508013932435\n",
            "Epoch 97, Mean Train Loss: 0.004534095278140506, Mean Validation Loss: 0.009951439325872188\n",
            "Epoch 98, Mean Train Loss: 0.8026871943645696, Mean Validation Loss: 0.009895593601169388\n",
            "Epoch 99, Mean Train Loss: 0.8021332609700266, Mean Validation Loss: 0.010101642280679987\n"
          ]
        }
      ],
      "source": [
        "translational_equivariant_model = TranslationalEquivariantModel()\n",
        "trainer = Trainer(translational_equivariant_model, equivariant_train_dataset, equivariant_validation_dataset, batch_size=8, loss_fn=torch.nn.MSELoss(), epochs=100, model_name=\"02-Translational-Equivariant-Model.pt\")\n",
        "trainer.train_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I1ach2OMrmKM"
      },
      "outputs": [],
      "source": [
        "def model2_rollouts(model, dataset, positions_dataset, timesteps=1000, device='cuda', mode=\"residual\", width = 1000, height = 1000):\n",
        "    \"\"\"\n",
        "    Predict the rollouts of the model on the dataset starting from the idx\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        dataset: PyTorch dataset\n",
        "        timesteps: Number of timesteps to predict\n",
        "        device: Device to run the model on\n",
        "        mode: \"residual\" or \"direct\"\n",
        "        - In the solution above, we used the \"residual\" mode, where the model predicts the change in position and velocity\n",
        "        - In the \"direct\" mode, the model predicts the position and velocity directly (if you do not intend to use this mode, you can ignore this argument)\n",
        "        width: Width of the PBC box\n",
        "        height: Height of the PBC box\n",
        "    Returns:\n",
        "        rollouts: Rollouts of the model on the dataset\n",
        "        - Should be a torch tensor of shape (Batch, Timesteps, Boids, Node_dim)\n",
        "    \"\"\"\n",
        "    rollouts = torch.empty((len(dataset), timesteps, dataset[0].x.shape[0], dataset[0].x.shape[1]), device=device)\n",
        "    print(rollouts.shape)\n",
        "\n",
        "    # code inserted below\n",
        "    model = model.to(device).eval()\n",
        "    init_pos = positions_dataset.to(device)\n",
        "    B, N, _ = init_pos.shape\n",
        "    Lx, Ly = float(width), float(height)\n",
        "    Traw = getattr(dataset, \"timesteps\", timesteps)\n",
        "\n",
        "    # use the first sample to infer feature size & edge_index template\n",
        "    d0 = dataset[0]\n",
        "    F = d0.x.shape[1]\n",
        "    # Prefer dataset-provided edge_index (keeps exact ordering); fallback to dense complete graph\n",
        "    if hasattr(d0, \"edge_index\") and d0.edge_index is not None:\n",
        "        edge_index_template = d0.edge_index.to(device)\n",
        "    else:\n",
        "        recv, send = [], []\n",
        "        for i in range(N):\n",
        "            for j in range(N):\n",
        "                if i != j:\n",
        "                    recv.append(i); send.append(j)\n",
        "        edge_index_template = torch.tensor([recv, send], dtype=torch.long, device=device)\n",
        "\n",
        "    rollouts = torch.empty((B, timesteps, N, F), device=device, dtype=d0.x.dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b in range(B):\n",
        "            # index of the first sample (t=0) for trajectory b\n",
        "            start_idx = b * (Traw - 1)\n",
        "            db0 = dataset[start_idx]\n",
        "\n",
        "            # initial absolute state: positions from positions_dataset, velocities from dataset sample\n",
        "            pos = init_pos[b].clone()                 # [N,2]\n",
        "            vel = db0.x[:, 2:4].to(device).clone()    # [N,2]\n",
        "\n",
        "            # fixed edge_index for this trajectory\n",
        "            edge_index = getattr(db0, \"edge_index\", edge_index_template).to(device)\n",
        "\n",
        "            # t = 0 frame\n",
        "            rollouts[b, 0] = torch.cat([pos, vel], dim=-1)\n",
        "\n",
        "            for t in range(1, timesteps):\n",
        "                x_in = torch.cat([pos, vel], dim=-1)          # [N,4]\n",
        "                data_in = Data(x=x_in, edge_index=edge_index) # pass a Data object as required\n",
        "                y_hat = model(data_in)                        # [N,4]\n",
        "\n",
        "                if mode == \"residual\":\n",
        "                    dpos = y_hat[:, :2]\n",
        "                    dvel = y_hat[:, 2:]\n",
        "                    vel = vel + dvel\n",
        "                    pos = pos + dpos\n",
        "                elif mode == \"direct\":\n",
        "                    pos = y_hat[:, :2]\n",
        "                    vel = y_hat[:, 2:]\n",
        "                else:\n",
        "                    raise ValueError(\"mode must be 'residual' or 'direct'\")\n",
        "\n",
        "                # Periodic Boundary Conditions on positions\n",
        "                pos[:, 0] = torch.remainder(pos[:, 0], Lx)\n",
        "                pos[:, 1] = torch.remainder(pos[:, 1], Ly)\n",
        "\n",
        "                rollouts[b, t] = torch.cat([pos, vel], dim=-1)\n",
        "\n",
        "    return rollouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ff6U98tormKM",
        "outputId": "8637a57f-ed70-4ada-98c5-03e615acb554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[25, 4], edge_index=[2, 600], y=[25, 4])\n",
            "torch.Size([9, 1000, 25, 4])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_14484\\2797361435.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  translational_equivariant_model.load_state_dict(torch.load(\"../../models/02-Translational-Equivariant-Model.pt\"))\n"
          ]
        }
      ],
      "source": [
        "initial_states_validation_dataset = AR_Boids_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(16, 25),\n",
        "    timesteps=2,\n",
        "    processed_file_name=\"AR1_VAL_Equivariant_init.pt\",\n",
        "    transform=keep_01\n",
        "    )\n",
        "\n",
        "print(initial_states_validation_dataset[1])\n",
        "\n",
        "translational_equivariant_model = TranslationalEquivariantModel()\n",
        "translational_equivariant_model.load_state_dict(torch.load(\"../../models/02-Translational-Equivariant-Model.pt\"))\n",
        "translational_equivariant_model_rollout = model2_rollouts(translational_equivariant_model, initial_states_validation_dataset, init_val_positions.to(device), timesteps=1000, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVl3Ym76rmKM"
      },
      "source": [
        "Above, we show the boids with their radius of effect. As expected, boids who are farther than `radius=40` units away from eachother, are shown to not affect eachother.\n",
        "\n",
        "So in our dataset, we form undirected edges between nodes with a max PBC distance of 40 units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZkQ_hS1rmKM"
      },
      "source": [
        "## Q3 E(n) Equivariant Graph Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibeSr0T9rmKM"
      },
      "source": [
        "In Satorras, Hoogeboom, Welling's paper [3] with the same name, they introduce a relatively simple model that is equivariant to E(n) transformations.\n",
        "You can check the official [implementation](https://github.com/vgsatorras/egnn)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UqdKUohUCJLY"
      },
      "outputs": [],
      "source": [
        "class EGNN_Dataset(InMemoryDataset):\n",
        "    def __init__(self, raw_data_path, processed_data_path, root=None,\n",
        "                 transform=None, pre_transform=None, post_transform=None,\n",
        "                 solution_idx_range=(0, 25), timesteps=1000,\n",
        "                 processed_file_name=\"AR1_Boids.pt\", L=1000):\n",
        "        self.raw_data_path = raw_data_path\n",
        "        self.processed_data_path = processed_data_path\n",
        "        self.solution_idx_range = solution_idx_range\n",
        "        self.timesteps = timesteps\n",
        "        self.processed_file_name = processed_file_name\n",
        "        self.pre_transform = pre_transform\n",
        "        self.transform = transform\n",
        "        self.post_transform = post_transform\n",
        "        self.L = L\n",
        "        super(EGNN_Dataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.processed_file_name]\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [pfn for pfn in os.listdir(self.raw_data_path)\n",
        "                if (self.solution_idx_range[0] <= int(pfn.split(\"_\")[-1][:-4]) < self.solution_idx_range[1])]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.timesteps - 1) * (self.solution_idx_range[1] - self.solution_idx_range[0])\n",
        "\n",
        "    def process(self):\n",
        "        data_list = []\n",
        "        pos_all = []\n",
        "        vel_all = []\n",
        "        raw_files = sorted(self.raw_file_names, key=lambda p: int(p.split(\"_\")[-1][:-4]))\n",
        "\n",
        "        # Collect all positions and velocities for normalization\n",
        "        for pfn in raw_files:\n",
        "            traj = np.load(os.path.join(self.raw_data_path, pfn))  # (T, N, 4)\n",
        "            pos_all.append(traj[:, :, :2])\n",
        "            vel_all.append(traj[:, :, 2:])\n",
        "        # Concatenate along time axis and then reshape\n",
        "        pos_all = np.concatenate(pos_all, axis=0)  # (total_timesteps, N, 2)\n",
        "        pos_all = pos_all.reshape(-1, pos_all.shape[-1])  # flatten to (samples, features)\n",
        "        vel_all = np.concatenate(vel_all, axis=0)\n",
        "        vel_all = vel_all.reshape(-1, vel_all.shape[-1])\n",
        "\n",
        "        # Calculate mean and std for normalization\n",
        "        pos_mean, pos_std = pos_all.mean(axis=0), pos_all.std(axis=0) + 1e-8\n",
        "        vel_mean, vel_std = vel_all.mean(axis=0), vel_all.std(axis=0) + 1e-8\n",
        "\n",
        "        for pfn in raw_files:\n",
        "            traj = np.load(os.path.join(self.raw_data_path, pfn))\n",
        "            T, N, F = traj.shape\n",
        "            T = min(T, self.timesteps)\n",
        "            # Save initial positions\n",
        "            pos0 = torch.from_numpy(traj[0, :, :2]).float()\n",
        "            # Build complete directed graph (no self loops)\n",
        "            recv, send = [], []\n",
        "            for i in range(N):\n",
        "                for j in range(N):\n",
        "                    if i != j:\n",
        "                        recv.append(i)\n",
        "                        send.append(j)\n",
        "            edge_index = torch.tensor([recv, send], dtype=torch.long)\n",
        "\n",
        "            for t in range(T - 1):\n",
        "                # Normalize input\n",
        "                pos_t = (traj[t, :, :2] - pos_mean) / pos_std\n",
        "                vel_t = (traj[t, :, 2:] - vel_mean) / vel_std\n",
        "                x_t = np.concatenate([pos_t, vel_t], axis=-1)\n",
        "\n",
        "                # Compute normalized residual targets with PBC for positions\n",
        "                dpos = traj[t + 1, :, :2] - traj[t, :, :2]\n",
        "                dpos = (dpos + self.L / 2.0) % self.L - self.L / 2.0\n",
        "                dpos = (dpos - pos_mean) / pos_std\n",
        "\n",
        "                dvel = traj[t + 1, :, 2:] - traj[t, :, 2:]\n",
        "                dvel = (dvel - vel_mean) / vel_std\n",
        "\n",
        "                y_res = np.concatenate([dpos, dvel], axis=-1)\n",
        "\n",
        "                data_list.append(\n",
        "                    Data(\n",
        "                        x=torch.from_numpy(x_t).float(),\n",
        "                        y=torch.from_numpy(y_res).float(),\n",
        "                        edge_index=edge_index.clone(),\n",
        "                        pos0=pos0.clone(),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        os.makedirs(self.processed_data_path, exist_ok=True)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.get(idx)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}({len(self)})'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ShL8Ks3hEUFi"
      },
      "outputs": [],
      "source": [
        "egnn_train_dataset = EGNN_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(0, 15),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"EGNN_Boids_Equivariant.pt\"\n",
        "    )\n",
        "\n",
        "egnn_validation_dataset = EGNN_Dataset(\n",
        "    raw_data_path=\"../../data/boids/raw/\",\n",
        "    processed_data_path=\"../../data/boids/processed/\",\n",
        "    root=\"../../data/boids/\",\n",
        "    solution_idx_range=(16, 25),\n",
        "    timesteps=1000,\n",
        "    processed_file_name=\"EGNN_VAL_Boids_Equivariant.pt\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "init_positions = torch.load(\"../../data/boids/processed/positions_AR1_Boids_Equivariant.pt\")\n",
        "print(init_positions.shape)\n",
        "init_val_positions = torch.load(\"../../data/boids/processed/positions_AR1_VAL_Boids_Equivariant.pt\")\n",
        "print(init_val_positions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0gZiS4AVrmKM"
      },
      "outputs": [],
      "source": [
        "# Utilities for aggregation\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
        "    result = data.new_zeros((num_segments, data.size(1)))\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    return result\n",
        "\n",
        "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
        "    result = data.new_zeros((num_segments, data.size(1)))\n",
        "    count = data.new_zeros((num_segments, data.size(1)))\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    count.scatter_add_(0, segment_ids, torch.ones_like(data))\n",
        "    return result / count.clamp(min=1)\n",
        "\n",
        "# One EGNN layer\n",
        "class E_GCL(torch.nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf,\n",
        "                 edges_in_d=0, act_fn=torch.nn.SiLU(),\n",
        "                 residual=True, attention=False,\n",
        "                 normalize=False, coords_agg='mean', tanh=False, L=None):\n",
        "        super().__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        edge_coords_nf = 1\n",
        "        self.residual = residual\n",
        "        self.attention = attention\n",
        "        self.normalize = normalize\n",
        "        self.coords_agg = coords_agg\n",
        "        self.tanh = tanh\n",
        "        self.epsilon = 1e-8\n",
        "        self.L = L\n",
        "\n",
        "        self.edge_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_edge + edge_coords_nf + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            torch.nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn\n",
        "        )\n",
        "        self.node_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_nf + input_nf, hidden_nf),\n",
        "            act_fn,\n",
        "            torch.nn.Linear(hidden_nf, output_nf)\n",
        "        )\n",
        "        layer = torch.nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "        coord_mlp = [torch.nn.Linear(hidden_nf, hidden_nf), act_fn, layer]\n",
        "        if tanh:\n",
        "            coord_mlp.append(torch.nn.Tanh())\n",
        "        self.coord_mlp = torch.nn.Sequential(*coord_mlp)\n",
        "\n",
        "        if attention:\n",
        "            self.att_mlp = torch.nn.Sequential(\n",
        "                torch.nn.Linear(hidden_nf, 1),\n",
        "                torch.nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "    def coord2radial(self, edge_index, coord):\n",
        "        row, col = edge_index\n",
        "        coord_diff = coord[row] - coord[col]\n",
        "        if self.L is not None:\n",
        "            if isinstance(self.L, (list, tuple, torch.Tensor)):\n",
        "                Lvec = torch.tensor(self.L, device=coord.device, dtype=coord.dtype)\n",
        "            else:\n",
        "                Lvec = torch.tensor([self.L]*coord.size(1), device=coord.device, dtype=coord.dtype)\n",
        "            coord_diff = (coord_diff + 0.5 * Lvec) % Lvec - 0.5 * Lvec\n",
        "        radial = torch.sum(coord_diff**2, 1).unsqueeze(1)\n",
        "        if self.normalize:\n",
        "            norm = torch.sqrt(radial).detach() + self.epsilon\n",
        "            coord_diff = coord_diff / norm\n",
        "        return radial, coord_diff\n",
        "\n",
        "    def edge_model(self, source, target, radial, edge_attr):\n",
        "        if edge_attr is None:\n",
        "            out = torch.cat([source, target, radial], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, radial, edge_attr], dim=1)\n",
        "        out = self.edge_mlp(out)\n",
        "        if self.attention:\n",
        "            out = out * self.att_mlp(out)\n",
        "        return out\n",
        "\n",
        "    def node_model(self, h, edge_index, edge_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=h.size(0))\n",
        "        out = self.node_mlp(torch.cat([h, agg], dim=1))\n",
        "        if self.residual:\n",
        "            out = h + out\n",
        "        return out\n",
        "\n",
        "    def coord_model(self, coord, edge_index, coord_diff, edge_feat):\n",
        "        row, col = edge_index\n",
        "        trans = coord_diff * self.coord_mlp(edge_feat)\n",
        "        if self.coords_agg == 'sum':\n",
        "            agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0))\n",
        "        else:\n",
        "            agg = unsorted_segment_mean(trans, row, num_segments=coord.size(0))\n",
        "        coord = coord + agg\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, edge_index, coord, edge_attr=None):\n",
        "        radial, coord_diff = self.coord2radial(edge_index, coord)\n",
        "        edge_feat = self.edge_model(h[edge_index[0]], h[edge_index[1]], radial, edge_attr)\n",
        "        coord = self.coord_model(coord, edge_index, coord_diff, edge_feat)\n",
        "        h = self.node_model(h, edge_index, edge_feat)\n",
        "        return h, coord\n",
        "\n",
        "# Full EGNN model\n",
        "class EGNN_Boids(torch.nn.Module):\n",
        "    def __init__(self, in_node_nf, hidden_nf, out_node_nf,\n",
        "                 in_edge_nf=0, n_layers=4, device=\"cpu\", L=1000.0):\n",
        "        super().__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.embedding_in = torch.nn.Linear(in_node_nf - 2, hidden_nf)\n",
        "        self.embedding_out = torch.nn.Linear(hidden_nf, out_node_nf)\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            E_GCL(hidden_nf, hidden_nf, hidden_nf,\n",
        "                  edges_in_d=in_edge_nf, act_fn=torch.nn.SiLU(), L=L)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.device = device\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, data: torch_geometric.data.Data):\n",
        "        coord, feats = data.x[:, :2], data.x[:, 2:]\n",
        "        edges = data.edge_index\n",
        "        edge_attr = getattr(data, \"edge_attr\", None)\n",
        "\n",
        "        h = self.embedding_in(feats)\n",
        "        for gcl in self.layers:\n",
        "            h, coord = gcl(h, edges, coord, edge_attr)\n",
        "\n",
        "        dvel = self.embedding_out(h)\n",
        "\n",
        "        # Residual Δx is the updated coord minus original coord\n",
        "        dpos = coord - data.x[:, :2]\n",
        "\n",
        "        # Concatenate into output [Δx, Δv]\n",
        "        out = torch.cat([dpos, dvel], dim=-1)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odW6EkcarmKN",
        "outputId": "8fd18d4b-2a97-4348-d8c3-f921fb61cb14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Mean Train Loss: 1.2092895315737169, Mean Validation Loss: 4.430946970580946\n",
            "Epoch 1, Mean Train Loss: 0.8443866551736307, Mean Validation Loss: 4.642175772185844\n",
            "Epoch 2, Mean Train Loss: 1.1286809729396279, Mean Validation Loss: 2.3526516572676877\n",
            "Epoch 3, Mean Train Loss: 0.7391201777855814, Mean Validation Loss: 1.979302469103094\n",
            "Epoch 4, Mean Train Loss: 0.5611518091705238, Mean Validation Loss: 10.000943343694622\n",
            "Epoch 5, Mean Train Loss: 0.583112780432591, Mean Validation Loss: 3.975996123384452\n",
            "Epoch 6, Mean Train Loss: 0.7484177968456832, Mean Validation Loss: 3.32743976949158\n",
            "Epoch 7, Mean Train Loss: 0.6134107025264579, Mean Validation Loss: 3.6528280366763286\n",
            "Epoch 8, Mean Train Loss: 0.46578743221520835, Mean Validation Loss: 2.3809497814339964\n",
            "Epoch 9, Mean Train Loss: 0.467768979137445, Mean Validation Loss: 6.617666651220882\n",
            "Epoch 10, Mean Train Loss: 0.5946110088883653, Mean Validation Loss: 2.085411388234446\n",
            "Epoch 11, Mean Train Loss: 0.6347684612314607, Mean Validation Loss: 3.3110385493586194\n",
            "Epoch 12, Mean Train Loss: 0.795513595506135, Mean Validation Loss: 53.863249992091816\n",
            "Epoch 13, Mean Train Loss: 0.8010812910655752, Mean Validation Loss: 2.8210334756582602\n",
            "Epoch 14, Mean Train Loss: 0.5049318813034294, Mean Validation Loss: 4.469777534113211\n",
            "Epoch 15, Mean Train Loss: 0.4851587579941823, Mean Validation Loss: 3.831586892698325\n",
            "Epoch 16, Mean Train Loss: 0.3920620719297256, Mean Validation Loss: 3.147114862945203\n",
            "Epoch 17, Mean Train Loss: 0.41236520812420857, Mean Validation Loss: 3.160480645463641\n",
            "Epoch 18, Mean Train Loss: 0.34933796177944565, Mean Validation Loss: 2.0361056591578346\n",
            "Epoch 19, Mean Train Loss: 0.36391467047043335, Mean Validation Loss: 2.47231456972061\n",
            "Epoch 20, Mean Train Loss: 0.31651399428379107, Mean Validation Loss: 4.024789697824315\n",
            "Epoch 21, Mean Train Loss: 0.26838564480611116, Mean Validation Loss: 4.0965591908138705\n",
            "Epoch 22, Mean Train Loss: 0.48752398741367853, Mean Validation Loss: 4.07026325190131\n",
            "Epoch 23, Mean Train Loss: 0.3026692926422016, Mean Validation Loss: 4.583276283401006\n",
            "Epoch 24, Mean Train Loss: 0.30862180289014396, Mean Validation Loss: 12.972968419392904\n",
            "Epoch 25, Mean Train Loss: 0.32319969547470695, Mean Validation Loss: 14.850505028178985\n",
            "Epoch 26, Mean Train Loss: 0.3104368230341894, Mean Validation Loss: 2.1945885798085394\n",
            "Epoch 27, Mean Train Loss: 0.36908431315165746, Mean Validation Loss: 2.0221742284276694\n",
            "Epoch 28, Mean Train Loss: 0.3080416256631526, Mean Validation Loss: 13.122063925772002\n",
            "Epoch 29, Mean Train Loss: 0.20669846804404599, Mean Validation Loss: 5.432909777245207\n",
            "Epoch 30, Mean Train Loss: 0.1832160650524629, Mean Validation Loss: 5.699925117526675\n",
            "Epoch 31, Mean Train Loss: 0.15368046577518377, Mean Validation Loss: 9.505089086591667\n",
            "Epoch 32, Mean Train Loss: 0.14683565737741291, Mean Validation Loss: 1.889759447325997\n",
            "Epoch 33, Mean Train Loss: 0.1574713148516961, Mean Validation Loss: 5.211730440032674\n",
            "Epoch 34, Mean Train Loss: 0.15273262717180017, Mean Validation Loss: 1.4704148406013449\n",
            "Epoch 35, Mean Train Loss: 0.1394343800831817, Mean Validation Loss: 2.1284624285026457\n",
            "Epoch 36, Mean Train Loss: 0.11901425913749382, Mean Validation Loss: 2.064730740220364\n",
            "Epoch 37, Mean Train Loss: 0.13867175871353102, Mean Validation Loss: 1.9614014492740393\n",
            "Epoch 38, Mean Train Loss: 0.12133351807098469, Mean Validation Loss: 2.3196871203109755\n",
            "Epoch 39, Mean Train Loss: 0.09802356661390911, Mean Validation Loss: 1.8449181010697615\n",
            "Epoch 40, Mean Train Loss: 0.09534701050714885, Mean Validation Loss: 2.560949207454548\n",
            "Epoch 41, Mean Train Loss: 0.10765023561220409, Mean Validation Loss: 2.6551127932075937\n",
            "Epoch 42, Mean Train Loss: 0.10018692316604842, Mean Validation Loss: 1.9406438950389464\n",
            "Epoch 43, Mean Train Loss: 0.18977098802351353, Mean Validation Loss: 4.487865603225116\n",
            "Epoch 44, Mean Train Loss: 0.1732731134373034, Mean Validation Loss: 2.9369989654145563\n",
            "Epoch 45, Mean Train Loss: 0.12648328095744166, Mean Validation Loss: 2.2701465040710946\n",
            "Epoch 46, Mean Train Loss: 0.09818228774278177, Mean Validation Loss: 2.9725426031731454\n",
            "Epoch 47, Mean Train Loss: 0.08730259085890964, Mean Validation Loss: 2.1857376582057295\n",
            "Epoch 48, Mean Train Loss: 0.0630715366688748, Mean Validation Loss: 2.3427494534834183\n",
            "Epoch 49, Mean Train Loss: 0.06247377535701395, Mean Validation Loss: 1.552021182900869\n",
            "Epoch 50, Mean Train Loss: 0.04746106311825152, Mean Validation Loss: 1.42925450578996\n",
            "Epoch 51, Mean Train Loss: 0.05303180094200891, Mean Validation Loss: 1.4617379680275917\n",
            "Epoch 52, Mean Train Loss: 0.04570844549408111, Mean Validation Loss: 1.3574323127188996\n",
            "Epoch 53, Mean Train Loss: 0.0498099121858135, Mean Validation Loss: 1.348742661894749\n",
            "Epoch 54, Mean Train Loss: 0.05369547583659291, Mean Validation Loss: 1.2949738658818544\n",
            "Epoch 55, Mean Train Loss: 0.04837555885260216, Mean Validation Loss: 1.7181101893464936\n",
            "Epoch 56, Mean Train Loss: 0.047876589849459916, Mean Validation Loss: 1.428625505025799\n",
            "Epoch 57, Mean Train Loss: 0.05254163445196409, Mean Validation Loss: 1.8934015052628814\n",
            "Epoch 58, Mean Train Loss: 0.046328322098264076, Mean Validation Loss: 2.3378792621607025\n",
            "Epoch 59, Mean Train Loss: 0.0810345081121434, Mean Validation Loss: 1.2281970839130687\n",
            "Epoch 60, Mean Train Loss: 0.059468278156903885, Mean Validation Loss: 5.496069350982095\n",
            "Epoch 61, Mean Train Loss: 0.05799157802104098, Mean Validation Loss: 4.115915086127007\n",
            "Epoch 62, Mean Train Loss: 0.04564683847480083, Mean Validation Loss: 1.6450091692919506\n",
            "Epoch 63, Mean Train Loss: 0.04742658725078019, Mean Validation Loss: 2.100300016708393\n",
            "Epoch 64, Mean Train Loss: 0.04935737827277352, Mean Validation Loss: 2.568110231662073\n",
            "Epoch 65, Mean Train Loss: 0.05656234527968913, Mean Validation Loss: 2.531511271249589\n",
            "Epoch 66, Mean Train Loss: 0.05221596297596056, Mean Validation Loss: 2.6644122065733886\n",
            "Epoch 67, Mean Train Loss: 0.05036122066244427, Mean Validation Loss: 2.309230270524926\n",
            "Epoch 68, Mean Train Loss: 0.039272472082287006, Mean Validation Loss: 3.0623364211483435\n",
            "Epoch 69, Mean Train Loss: 0.031074884113418855, Mean Validation Loss: 2.1813856594384036\n",
            "Epoch 70, Mean Train Loss: 0.03143711324306563, Mean Validation Loss: 3.051069922313599\n",
            "Epoch 71, Mean Train Loss: 0.02953541776701175, Mean Validation Loss: 3.173433821316337\n",
            "Epoch 72, Mean Train Loss: 0.02435442106586853, Mean Validation Loss: 2.8544806679860155\n",
            "Epoch 73, Mean Train Loss: 0.02342832235544303, Mean Validation Loss: 1.9934133846651425\n",
            "Epoch 74, Mean Train Loss: 0.018706205301484268, Mean Validation Loss: 2.290417875636389\n",
            "Epoch 75, Mean Train Loss: 0.018160111677427936, Mean Validation Loss: 1.9682237447344046\n",
            "Epoch 76, Mean Train Loss: 0.01624449939702331, Mean Validation Loss: 3.2138943541496197\n",
            "Epoch 77, Mean Train Loss: 0.01604199766653538, Mean Validation Loss: 1.9840331911084486\n",
            "Epoch 78, Mean Train Loss: 0.01416062218099524, Mean Validation Loss: 1.9922642212713042\n",
            "Epoch 79, Mean Train Loss: 0.01375168619092114, Mean Validation Loss: 1.8976472430927231\n",
            "Epoch 80, Mean Train Loss: 0.011270491156948961, Mean Validation Loss: 1.927315297000336\n",
            "Epoch 81, Mean Train Loss: 0.010872520907616848, Mean Validation Loss: 1.9985060909507322\n",
            "Epoch 82, Mean Train Loss: 0.010411102046962962, Mean Validation Loss: 1.9129847745791264\n",
            "Epoch 83, Mean Train Loss: 0.010532570240047012, Mean Validation Loss: 1.8599109102684652\n",
            "Epoch 84, Mean Train Loss: 0.010593643853650827, Mean Validation Loss: 1.8468006192681623\n",
            "Epoch 85, Mean Train Loss: 0.00933100951691362, Mean Validation Loss: 1.9199611111585575\n",
            "Epoch 86, Mean Train Loss: 0.01064878784605893, Mean Validation Loss: 1.8760424198353673\n",
            "Epoch 87, Mean Train Loss: 0.00820069333632192, Mean Validation Loss: 1.8608831162838375\n",
            "Epoch 88, Mean Train Loss: 0.010431124551585402, Mean Validation Loss: 1.8583684184732923\n",
            "Epoch 89, Mean Train Loss: 0.009893179482344586, Mean Validation Loss: 1.8845246353331098\n",
            "Epoch 90, Mean Train Loss: 0.00986972644001133, Mean Validation Loss: 1.838060098442908\n",
            "Epoch 91, Mean Train Loss: 0.008294968879244361, Mean Validation Loss: 2.025531721080582\n",
            "Epoch 92, Mean Train Loss: 0.008563829812210782, Mean Validation Loss: 1.925220608153445\n",
            "Epoch 93, Mean Train Loss: 0.008094366276925271, Mean Validation Loss: 1.8000763318104647\n",
            "Epoch 94, Mean Train Loss: 0.007132466529116918, Mean Validation Loss: 1.9285420777206435\n",
            "Epoch 95, Mean Train Loss: 0.006860759367244208, Mean Validation Loss: 1.9731188229818077\n",
            "Epoch 96, Mean Train Loss: 0.006008908597999461, Mean Validation Loss: 2.026388957259808\n",
            "Epoch 97, Mean Train Loss: 0.006874754972174827, Mean Validation Loss: 2.0826486336754604\n",
            "Epoch 98, Mean Train Loss: 0.005513492357555446, Mean Validation Loss: 2.1194309948042114\n",
            "Epoch 99, Mean Train Loss: 0.005904476948959418, Mean Validation Loss: 2.1909508452470186\n"
          ]
        }
      ],
      "source": [
        "# Initialize the EGNN model\n",
        "egnn_model = EGNN_Boids(\n",
        "    in_node_nf=4,\n",
        "    hidden_nf=64,\n",
        "    out_node_nf=2,    # Δv prediction\n",
        "    n_layers=4,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Trainer for model\n",
        "egnn_trainer = Trainer(\n",
        "    egnn_model,\n",
        "    egnn_train_dataset,\n",
        "    egnn_validation_dataset,\n",
        "    batch_size=16,\n",
        "    loss_fn=torch.nn.MSELoss(),\n",
        "    epochs=100,\n",
        "    model_name=\"03-EGNN-Boids.pt\"\n",
        ")\n",
        "\n",
        "\n",
        "egnn_trainer.train_loop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMyILUMNrmKN"
      },
      "source": [
        "## Q4 Push-forward training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAvuO6VyrmKN"
      },
      "outputs": [],
      "source": [
        "def pbc_displacement(pos_i: torch.Tensor, pos_j: torch.Tensor, box: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    pos_i, pos_j: (..., 2) or (N,2) tensors\n",
        "    box: (2,) tensor [Lx, Ly]\n",
        "    returns: displacement pos_i - pos_j under minimum-image (same shape)\n",
        "    \"\"\"\n",
        "    diff = pos_i - pos_j\n",
        "    box = box.to(diff.device).to(diff.dtype)\n",
        "    return (diff + box / 2.0) % box - box / 2.0\n",
        "\n",
        "def build_radius_graph_pbc(pos: torch.Tensor, radius: float, box: torch.Tensor, self_loops: bool=False) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Build edge_index (2, E) for a single graph under PBC.\n",
        "    pos: (N,2)\n",
        "    box: (2,) tensor\n",
        "    radius: float scalar\n",
        "    Returns: edge_index (2, E) torch.long\n",
        "    \"\"\"\n",
        "    N = pos.shape[0]\n",
        "    # compute pairwise displacements\n",
        "    pos_i = pos.unsqueeze(1).expand(N, N, 2)   # (N,N,2)\n",
        "    pos_j = pos.unsqueeze(0).expand(N, N, 2)\n",
        "    disp = pbc_displacement(pos_i, pos_j, box) # (N,N,2)\n",
        "    dist2 = (disp**2).sum(dim=-1)               # (N,N)\n",
        "    mask = (dist2 <= (radius**2))\n",
        "    if not self_loops:\n",
        "        mask.fill_diagonal_(False)\n",
        "    # indices\n",
        "    row, col = mask.nonzero(as_tuple=True)\n",
        "    edge_index = torch.stack([row.long(), col.long()], dim=0)\n",
        "    return edge_index\n",
        "\n",
        "def apply_prediction_to_state(data: Data, pred: torch.Tensor, box: torch.Tensor) -> Data:\n",
        "    \"\"\"\n",
        "    data: Data with x = [pos, vel] (N,4) or batched.\n",
        "    pred: tensor (N,4) predicted [dpos, dvel]\n",
        "    Returns new_data where:\n",
        "      - new_pos = (pos + dpos) wrapped into [0, L)\n",
        "      - new_vel = vel + dvel   (optionally clip)\n",
        "      - x is updated to concat(new_pos, new_vel)\n",
        "      - pos field not used here (we keep x only, as per Option B)\n",
        "    \"\"\"\n",
        "    device = data.x.device\n",
        "    pos = data.x[:, :2]\n",
        "    vel = data.x[:, 2:]\n",
        "    dpos = pred[:, :2]\n",
        "    dvel = pred[:, 2:]\n",
        "    new_pos = (pos + dpos) % box  # keep in [0,L)\n",
        "    new_vel = vel + dvel\n",
        "    new_x = torch.cat([new_pos, new_vel], dim=-1)\n",
        "    new_data = Data(x=new_x, edge_index=data.edge_index, edge_attr=getattr(data, \"edge_attr\", None)) # edge_index/edge_attr; will be recomputed as needed\n",
        "    return new_data\n",
        "\n",
        "def rollout_push_forward(model,\n",
        "                         init_data: Data,\n",
        "                         gt_sequence: list,   # list of Data objects for subsequent ground truth states, length >= rollout_steps\n",
        "                         rollout_steps: int,\n",
        "                         radius: float,\n",
        "                         box: torch.Tensor,\n",
        "                         device: torch.device,\n",
        "                         p_teacher: float = 0.0):\n",
        "    \"\"\"\n",
        "    Perform rollout_steps of push-forward training.\n",
        "    - model: returns pred Δ state for the input data\n",
        "    - init_data: Data with initial x (pos+vel)\n",
        "    - gt_sequence: list of ground-truth Data objects for next steps (each with x)\n",
        "    - p_teacher: probability of using ground-truth next state (teacher forcing) at each step;\n",
        "                 with probability (1-p_teacher) we use model prediction to step forward.\n",
        "    Returns:\n",
        "      preds: list of pred tensors (each (N,4))\n",
        "      targets: list of gt tensors (each (N,4))  # targets for each step equal to GT delta between successive gt_sequence items\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    targets = []\n",
        "    cur_data = init_data  # Data containing x = [pos,vel]\n",
        "    cur_data = cur_data.to(device)\n",
        "    box = box.to(device).float()\n",
        "\n",
        "    for t in range(rollout_steps):\n",
        "        # Build edge_index for current positions (PBC-aware)\n",
        "        pos = cur_data.x[:, :2]\n",
        "        edge_index = build_radius_graph_pbc(pos, radius, box, self_loops=False).to(device)\n",
        "        cur_data.edge_index = edge_index\n",
        "\n",
        "        pred = model(cur_data)  \n",
        "        preds.append(pred)\n",
        "\n",
        "        # target: GT delta between gt_sequence[t] and gt_sequence[t+1]\n",
        "        gt_now = gt_sequence[t].x.to(device)\n",
        "        gt_next = gt_sequence[t+1].x.to(device)\n",
        "        dpos_gt = pbc_displacement(gt_next[:, :2], gt_now[:, :2], box)\n",
        "        dvel_gt = gt_next[:, 2:] - gt_now[:, 2:]\n",
        "        delta_gt = torch.cat([dpos_gt, dvel_gt], dim=-1)\n",
        "        targets.append(delta_gt)\n",
        "\n",
        "        # Decide whether to teacher force or push-forward with prediction\n",
        "        if random.random() < p_teacher:\n",
        "            # teacher: set cur_data to ground truth next\n",
        "            new_x = gt_next\n",
        "            new_data = Data(x=new_x, edge_index=None)  # edge_index recomputed at top of loop\n",
        "        else:\n",
        "            # push-forward\n",
        "            new_data = apply_prediction_to_state(cur_data, pred, box)\n",
        "        # prepare next loop\n",
        "        cur_data = new_data\n",
        "\n",
        "    return preds, targets\n",
        "\n",
        "def rollout_loss(preds: list, targets: list, w_pos: float=1.0, w_vel: float=1.0):\n",
        "    \"\"\"\n",
        "    preds, targets: lists of tensors (T steps) each (N,4)\n",
        "    returns: scalar loss (torch.Tensor) with gradient\n",
        "    \"\"\"\n",
        "    loss = 0.0\n",
        "    total_elems = 0\n",
        "    for p, g in zip(preds, targets):\n",
        "        dpos_p, dvel_p = p[:, :2], p[:, 2:]\n",
        "        dpos_g, dvel_g = g[:, :2], g[:, 2:]\n",
        "        loss_pos = F.mse_loss(dpos_p, dpos_g, reduction='sum')\n",
        "        loss_vel = F.mse_loss(dvel_p, dvel_g, reduction='sum')\n",
        "        loss = loss + (w_pos * loss_pos + w_vel * loss_vel)\n",
        "        total_elems += p.numel()  # number of scalars in this step\n",
        "    return loss / total_elems    # torch.Tensor, not float\n",
        "\n",
        "def push_forward_train_epoch(model,\n",
        "                             dataloader,\n",
        "                             optimizer,\n",
        "                             device: torch.device,\n",
        "                             box: torch.Tensor,\n",
        "                             radius: float,\n",
        "                             rollout_steps: int = 5,\n",
        "                             scheduler_fn = None,\n",
        "                             p_teacher_fn = None,\n",
        "                             w_pos: float = 1.0,\n",
        "                             w_vel: float = 1.0,\n",
        "                             grad_clip: float = 1.0,\n",
        "                             log_every: int = 10):\n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = 0.0\n",
        "        batch_examples = batch if isinstance(batch, list) else [batch]\n",
        "\n",
        "        for example in batch_examples:\n",
        "            # Extract initial Data and list of GT Data\n",
        "            init_data = example['init']    # Data with x = [pos,vel]\n",
        "            gt_list = example['gt']        # len >= rollout_steps + 1; gt_list[0] == init state\n",
        "            assert len(gt_list) >= rollout_steps + 1, \"gt sequence shorter than rollout_steps+1\"\n",
        "\n",
        "            # teacher forcing prob for this batch/example\n",
        "            p_teacher = p_teacher_fn() if (p_teacher_fn is not None) else 0.0\n",
        "\n",
        "            # Run rollout (we use preds,target lists)\n",
        "            preds, targets = rollout_push_forward(model=model,\n",
        "                                                 init_data=init_data,\n",
        "                                                 gt_sequence=gt_list,\n",
        "                                                 rollout_steps=rollout_steps,\n",
        "                                                 radius=radius,\n",
        "                                                 box=box,\n",
        "                                                 device=device,\n",
        "                                                 p_teacher=p_teacher)\n",
        "            # compute loss for this example\n",
        "            ex_loss = rollout_loss(preds, targets, w_pos=w_pos, w_vel=w_vel)\n",
        "            batch_loss += ex_loss\n",
        "\n",
        "\n",
        "        # average over examples in batch\n",
        "        batch_loss = batch_loss / max(1, len(batch_examples))\n",
        "        batch_loss.backward()\n",
        "        # gradient clipping\n",
        "        clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += batch_loss.item()\n",
        "        n_batches += 1\n",
        "\n",
        "        if (batch_idx % log_every) == 0:\n",
        "            print(f\"Batch {batch_idx}: batch_loss={batch_loss.item():.6f}\")\n",
        "\n",
        "    mean_loss = total_loss / max(1, n_batches)\n",
        "    # optional scheduler step (if provided as e.g. ReduceLROnPlateau use scheduler_fn(mean_loss))\n",
        "    if scheduler_fn is not None:\n",
        "        scheduler_fn(mean_loss)\n",
        "    return mean_loss\n",
        "\n",
        "def boids_collate_fn(batch):\n",
        "    return batch  # just return list of dicts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYeKzHKArmKN"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ARSeqDataset(Dataset):\n",
        "    def __init__(self, raw_data_path, solution_idx_range=(0, 25), timesteps=10, rollout_steps=5,\n",
        "                 box_size=torch.tensor([1000., 1000.]), v_min=None, v_max=None):\n",
        "        self.raw_data_path = raw_data_path\n",
        "        self.solution_idx_range = solution_idx_range\n",
        "        self.timesteps = timesteps\n",
        "        self.rollout_steps = rollout_steps\n",
        "\n",
        "        self.box_size = box_size\n",
        "\n",
        "        self.files = [p for p in os.listdir(raw_data_path)\n",
        "                      if solution_idx_range[0] <= int(p.split(\"_\")[-1][:-4]) < solution_idx_range[1]]\n",
        "\n",
        "        # Build (file_id, start_t) indices\n",
        "        self.indices = []\n",
        "        for f_id, fn in enumerate(self.files):\n",
        "            traj = np.load(os.path.join(raw_data_path, fn))  # shape (T, N, 4)\n",
        "            T = traj.shape[0]\n",
        "            for t in range(T - rollout_steps - 1):\n",
        "                self.indices.append((f_id, t))\n",
        "\n",
        "        # Set or infer velocity normalization min/max if not provided\n",
        "        if v_min is None or v_max is None:\n",
        "            self.v_min, self.v_max = self.compute_velocity_min_max()\n",
        "        else:\n",
        "            self.v_min = v_min\n",
        "            self.v_max = v_max\n",
        "\n",
        "    def compute_velocity_min_max(self):\n",
        "        v_min = torch.tensor([float('inf'), float('inf')])\n",
        "        v_max = torch.tensor([-float('inf'), -float('inf')])\n",
        "        for fn in self.files:\n",
        "            traj = np.load(os.path.join(self.raw_data_path, fn))\n",
        "            velocities = torch.from_numpy(traj[:, :, 2:]).float()  # (T, N, 2)\n",
        "            v_min = torch.min(v_min, velocities.amin(dim=(0, 1)))\n",
        "            v_max = torch.max(v_max, velocities.amax(dim=(0, 1)))\n",
        "        return v_min, v_max\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f_id, t = self.indices[idx]\n",
        "        traj = np.load(os.path.join(self.raw_data_path, self.files[f_id]))  # (T, N, 4)\n",
        "\n",
        "        gt_list = []\n",
        "        for k in range(self.rollout_steps + 1):\n",
        "            frame = traj[t + k]  # (N, 4), [pos_x,pos_y,vel_x,vel_y]\n",
        "\n",
        "            # Normalize position to [0,1] by dividing by box size\n",
        "            pos = torch.from_numpy(frame[:, :2]).float() / self.box_size\n",
        "\n",
        "            # Normalize velocity to [-1,1] per component using min-max\n",
        "            vel = torch.from_numpy(frame[:, 2:]).float()\n",
        "            vel_norm = 2.0 * (vel - self.v_min) / (self.v_max - self.v_min + 1e-6) - 1.0\n",
        "\n",
        "            x = torch.cat([pos, vel_norm], dim=-1)\n",
        "            gt_list.append(Data(x=x))\n",
        "\n",
        "        return {\n",
        "            \"init\": gt_list[0],\n",
        "            \"gt\": gt_list\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "train_seq_dataset = ARSeqDataset(\"../../data/boids/raw/\", solution_idx_range=(0,15), rollout_steps=5)\n",
        "val_seq_dataset   = ARSeqDataset(\"../../data/boids/raw/\", solution_idx_range=(16,25), rollout_steps=5)\n",
        "\n",
        "train_loader = DataLoader(train_seq_dataset, batch_size=4, shuffle=True, collate_fn=boids_collate_fn)\n",
        "val_loader = DataLoader(val_seq_dataset, batch_size=4, shuffle=False, collate_fn=boids_collate_fn)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "box = torch.tensor([1000,1000], dtype=torch.float32, device=device)\n",
        "radius = 40.0\n",
        "\n",
        "def p_teacher_schedule(epoch, max_epochs):\n",
        "    start, end = 1.0, 0.0\n",
        "    return max(end, start - (epoch / max_epochs) * (start - end))\n",
        "\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNtyhrqgrmKS",
        "outputId": "d913f240-a4a3-42bc-ce34-e2f124eabf2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EGNN Model\n",
            "Batch 0: batch_loss=492.814178\n",
            "Batch 10: batch_loss=16.162607\n",
            "Batch 20: batch_loss=0.101882\n",
            "Batch 30: batch_loss=0.972842\n",
            "Batch 40: batch_loss=0.056903\n",
            "Batch 50: batch_loss=0.029534\n",
            "Batch 60: batch_loss=0.044379\n",
            "Batch 70: batch_loss=0.054193\n",
            "Batch 80: batch_loss=0.011873\n",
            "Batch 90: batch_loss=0.006727\n",
            "Batch 100: batch_loss=0.021391\n",
            "Batch 110: batch_loss=0.009286\n",
            "Batch 120: batch_loss=0.063021\n",
            "Batch 130: batch_loss=0.014974\n",
            "Batch 140: batch_loss=0.030386\n",
            "Batch 150: batch_loss=0.005692\n",
            "Batch 160: batch_loss=0.002939\n",
            "Batch 170: batch_loss=0.006475\n",
            "Batch 180: batch_loss=0.007194\n",
            "Batch 190: batch_loss=0.004810\n",
            "Batch 200: batch_loss=0.004315\n",
            "Batch 210: batch_loss=0.010812\n",
            "Batch 220: batch_loss=0.004083\n",
            "Batch 230: batch_loss=0.008250\n",
            "Batch 240: batch_loss=0.004846\n",
            "Batch 250: batch_loss=0.003678\n",
            "Batch 260: batch_loss=0.004481\n",
            "Batch 270: batch_loss=0.005044\n",
            "Batch 280: batch_loss=0.005034\n",
            "Batch 290: batch_loss=0.010668\n",
            "Batch 300: batch_loss=0.006339\n",
            "Batch 310: batch_loss=0.003684\n",
            "Batch 320: batch_loss=0.002685\n",
            "Batch 330: batch_loss=0.009549\n",
            "Batch 340: batch_loss=0.005539\n",
            "Batch 350: batch_loss=0.016108\n",
            "Batch 360: batch_loss=0.014905\n",
            "Batch 370: batch_loss=0.011576\n",
            "Batch 380: batch_loss=0.009843\n",
            "Batch 390: batch_loss=0.000707\n",
            "Batch 400: batch_loss=0.002548\n",
            "Batch 410: batch_loss=0.006533\n",
            "Batch 420: batch_loss=0.009925\n",
            "Batch 430: batch_loss=0.007561\n",
            "Batch 440: batch_loss=0.001568\n",
            "Batch 450: batch_loss=0.005178\n",
            "Batch 460: batch_loss=0.004271\n",
            "Batch 470: batch_loss=0.007832\n",
            "Batch 480: batch_loss=0.005547\n",
            "Batch 490: batch_loss=0.002200\n",
            "Batch 500: batch_loss=0.005029\n",
            "Batch 510: batch_loss=0.003776\n",
            "Batch 520: batch_loss=0.004951\n",
            "Batch 530: batch_loss=0.004798\n",
            "Batch 540: batch_loss=0.009630\n",
            "Batch 550: batch_loss=0.001344\n",
            "Batch 560: batch_loss=0.014933\n",
            "Batch 570: batch_loss=0.012815\n",
            "Batch 580: batch_loss=0.010024\n",
            "Batch 590: batch_loss=0.003005\n",
            "Batch 600: batch_loss=0.012486\n",
            "Batch 610: batch_loss=0.015655\n",
            "Batch 620: batch_loss=0.001651\n",
            "Batch 630: batch_loss=0.001858\n",
            "Batch 640: batch_loss=0.007395\n",
            "Batch 650: batch_loss=0.003352\n",
            "Batch 660: batch_loss=0.001264\n",
            "Batch 670: batch_loss=0.002128\n",
            "Batch 680: batch_loss=0.005110\n",
            "Batch 690: batch_loss=0.002275\n",
            "Batch 700: batch_loss=0.006638\n",
            "Batch 710: batch_loss=0.004493\n",
            "Batch 720: batch_loss=0.005269\n",
            "Batch 730: batch_loss=0.004483\n",
            "Batch 740: batch_loss=0.002211\n",
            "Batch 750: batch_loss=0.001832\n",
            "Batch 760: batch_loss=0.002965\n",
            "Batch 770: batch_loss=0.002237\n",
            "Batch 780: batch_loss=0.004629\n",
            "Batch 790: batch_loss=0.005689\n",
            "Batch 800: batch_loss=0.002755\n",
            "Batch 810: batch_loss=0.003315\n",
            "Batch 820: batch_loss=0.004167\n",
            "Batch 830: batch_loss=0.006164\n",
            "Batch 840: batch_loss=0.007071\n",
            "Batch 850: batch_loss=0.433446\n",
            "Batch 860: batch_loss=0.002389\n",
            "Batch 870: batch_loss=0.008293\n",
            "Batch 880: batch_loss=0.002404\n",
            "Batch 890: batch_loss=0.005172\n",
            "Batch 900: batch_loss=0.003071\n",
            "Batch 910: batch_loss=0.004842\n",
            "Batch 920: batch_loss=0.003168\n",
            "Batch 930: batch_loss=0.012836\n",
            "Batch 940: batch_loss=0.002340\n",
            "Batch 950: batch_loss=0.003351\n",
            "Batch 960: batch_loss=0.002231\n",
            "Batch 970: batch_loss=0.000684\n",
            "Batch 980: batch_loss=0.004990\n",
            "Batch 990: batch_loss=0.006160\n",
            "Batch 1000: batch_loss=0.002008\n",
            "Batch 1010: batch_loss=0.009829\n",
            "Batch 1020: batch_loss=0.000790\n",
            "Batch 1030: batch_loss=0.003896\n",
            "Batch 1040: batch_loss=0.008416\n",
            "Batch 1050: batch_loss=0.001671\n",
            "Batch 1060: batch_loss=0.004334\n",
            "Batch 1070: batch_loss=0.005607\n",
            "Batch 1080: batch_loss=0.009833\n",
            "Batch 1090: batch_loss=0.003436\n",
            "Batch 1100: batch_loss=0.000501\n",
            "Batch 1110: batch_loss=0.003061\n",
            "Batch 1120: batch_loss=0.001354\n",
            "Batch 1130: batch_loss=0.001403\n",
            "Batch 1140: batch_loss=0.000284\n",
            "Batch 1150: batch_loss=0.004826\n",
            "Batch 1160: batch_loss=0.003167\n",
            "Batch 1170: batch_loss=0.002583\n",
            "Batch 1180: batch_loss=0.002868\n",
            "Batch 1190: batch_loss=0.001645\n",
            "Batch 1200: batch_loss=0.000499\n",
            "Batch 1210: batch_loss=0.002961\n",
            "Batch 1220: batch_loss=0.001455\n",
            "Batch 1230: batch_loss=0.004526\n",
            "Batch 1240: batch_loss=0.006779\n",
            "Batch 1250: batch_loss=0.000544\n",
            "Batch 1260: batch_loss=0.000967\n",
            "Batch 1270: batch_loss=0.006093\n",
            "Batch 1280: batch_loss=0.000495\n",
            "Batch 1290: batch_loss=0.006155\n",
            "Batch 1300: batch_loss=0.001605\n",
            "Batch 1310: batch_loss=0.004951\n",
            "Batch 1320: batch_loss=0.002783\n",
            "Batch 1330: batch_loss=0.000670\n",
            "Batch 1340: batch_loss=0.003261\n",
            "Batch 1350: batch_loss=0.004126\n",
            "Batch 1360: batch_loss=0.002316\n",
            "Batch 1370: batch_loss=0.000249\n",
            "Batch 1380: batch_loss=0.002432\n",
            "Batch 1390: batch_loss=0.001431\n",
            "Batch 1400: batch_loss=0.001764\n",
            "Batch 1410: batch_loss=0.002055\n",
            "Batch 1420: batch_loss=0.003201\n",
            "Batch 1430: batch_loss=0.003312\n",
            "Batch 1440: batch_loss=0.003076\n",
            "Batch 1450: batch_loss=0.001046\n",
            "Batch 1460: batch_loss=0.001319\n",
            "Batch 1470: batch_loss=0.004140\n",
            "Batch 1480: batch_loss=0.002077\n",
            "Batch 1490: batch_loss=0.003228\n",
            "Batch 1500: batch_loss=0.002560\n",
            "Batch 1510: batch_loss=0.004159\n",
            "Batch 1520: batch_loss=0.000302\n",
            "Batch 1530: batch_loss=0.003502\n",
            "Batch 1540: batch_loss=0.009556\n",
            "Batch 1550: batch_loss=0.002379\n",
            "Batch 1560: batch_loss=0.001389\n",
            "Batch 1570: batch_loss=0.001823\n",
            "Batch 1580: batch_loss=0.012013\n",
            "Batch 1590: batch_loss=0.001017\n",
            "Batch 1600: batch_loss=0.008196\n",
            "Batch 1610: batch_loss=0.007652\n",
            "Batch 1620: batch_loss=0.006548\n",
            "Batch 1630: batch_loss=0.001988\n",
            "Batch 1640: batch_loss=0.000350\n",
            "Batch 1650: batch_loss=0.000669\n",
            "Batch 1660: batch_loss=0.002737\n",
            "Batch 1670: batch_loss=0.001324\n",
            "Batch 1680: batch_loss=0.004887\n",
            "Batch 1690: batch_loss=0.001907\n",
            "Batch 1700: batch_loss=0.001761\n",
            "Batch 1710: batch_loss=0.001906\n",
            "Batch 1720: batch_loss=0.000716\n",
            "Batch 1730: batch_loss=0.003076\n",
            "Batch 1740: batch_loss=0.002037\n",
            "Batch 1750: batch_loss=0.000881\n",
            "Batch 1760: batch_loss=0.003081\n",
            "Batch 1770: batch_loss=0.002668\n",
            "Batch 1780: batch_loss=0.007575\n",
            "Batch 1790: batch_loss=0.001408\n",
            "Batch 1800: batch_loss=0.000486\n",
            "Batch 1810: batch_loss=0.004107\n",
            "Batch 1820: batch_loss=0.001691\n",
            "Batch 1830: batch_loss=0.000594\n",
            "Batch 1840: batch_loss=0.005890\n",
            "Batch 1850: batch_loss=0.000478\n",
            "Batch 1860: batch_loss=0.001441\n",
            "Batch 1870: batch_loss=0.000502\n",
            "Batch 1880: batch_loss=0.001261\n",
            "Batch 1890: batch_loss=0.000556\n",
            "Batch 1900: batch_loss=0.001479\n",
            "Batch 1910: batch_loss=0.001866\n",
            "Batch 1920: batch_loss=0.002831\n",
            "Batch 1930: batch_loss=0.001036\n",
            "Batch 1940: batch_loss=0.002564\n",
            "Batch 1950: batch_loss=0.000992\n",
            "Batch 1960: batch_loss=0.004413\n",
            "Batch 1970: batch_loss=0.002000\n",
            "Batch 1980: batch_loss=0.002187\n",
            "Batch 1990: batch_loss=0.003009\n",
            "Batch 2000: batch_loss=0.002223\n",
            "Batch 2010: batch_loss=0.003549\n",
            "Batch 2020: batch_loss=0.002331\n",
            "Batch 2030: batch_loss=0.002438\n",
            "Batch 2040: batch_loss=0.002353\n",
            "Batch 2050: batch_loss=0.001476\n",
            "Batch 2060: batch_loss=0.002335\n",
            "Batch 2070: batch_loss=0.004541\n",
            "Batch 2080: batch_loss=0.002575\n",
            "Batch 2090: batch_loss=0.002264\n",
            "Batch 2100: batch_loss=0.003135\n",
            "Batch 2110: batch_loss=0.002713\n",
            "Batch 2120: batch_loss=0.004675\n",
            "Batch 2130: batch_loss=0.000481\n",
            "Batch 2140: batch_loss=0.002608\n",
            "Batch 2150: batch_loss=0.001919\n",
            "Batch 2160: batch_loss=0.001094\n",
            "Batch 2170: batch_loss=0.003053\n",
            "Batch 2180: batch_loss=0.003168\n",
            "Batch 2190: batch_loss=0.001910\n",
            "Batch 2200: batch_loss=0.003633\n",
            "Batch 2210: batch_loss=0.004531\n",
            "Batch 2220: batch_loss=0.001592\n",
            "Batch 2230: batch_loss=0.004352\n",
            "Batch 2240: batch_loss=0.000867\n",
            "Batch 2250: batch_loss=0.002499\n",
            "Batch 2260: batch_loss=0.001929\n",
            "Batch 2270: batch_loss=0.001262\n",
            "Batch 2280: batch_loss=0.003594\n",
            "Batch 2290: batch_loss=0.001689\n",
            "Batch 2300: batch_loss=0.000312\n",
            "Batch 2310: batch_loss=0.005728\n",
            "Batch 2320: batch_loss=0.001967\n",
            "Batch 2330: batch_loss=0.000978\n",
            "Batch 2340: batch_loss=0.009145\n",
            "Batch 2350: batch_loss=0.003006\n",
            "Batch 2360: batch_loss=0.003958\n",
            "Batch 2370: batch_loss=0.002827\n",
            "Batch 2380: batch_loss=0.001703\n",
            "Batch 2390: batch_loss=0.002740\n",
            "Batch 2400: batch_loss=0.002989\n",
            "Batch 2410: batch_loss=0.006635\n",
            "Batch 2420: batch_loss=0.001713\n",
            "Batch 2430: batch_loss=0.013180\n",
            "Batch 2440: batch_loss=0.000661\n",
            "Batch 2450: batch_loss=0.003106\n",
            "Batch 2460: batch_loss=0.001159\n",
            "Batch 2470: batch_loss=0.000971\n",
            "Batch 2480: batch_loss=0.001601\n",
            "Batch 2490: batch_loss=0.001345\n",
            "Batch 2500: batch_loss=0.001350\n",
            "Batch 2510: batch_loss=0.001093\n",
            "Batch 2520: batch_loss=0.001780\n",
            "Batch 2530: batch_loss=0.002180\n",
            "Batch 2540: batch_loss=0.002377\n",
            "Batch 2550: batch_loss=0.003320\n",
            "Batch 2560: batch_loss=0.001745\n",
            "Batch 2570: batch_loss=0.003184\n",
            "Batch 2580: batch_loss=0.001194\n",
            "Batch 2590: batch_loss=0.002478\n",
            "Batch 2600: batch_loss=0.002885\n",
            "Batch 2610: batch_loss=0.001949\n",
            "Batch 2620: batch_loss=0.001204\n",
            "Batch 2630: batch_loss=0.003556\n",
            "Batch 2640: batch_loss=0.005153\n",
            "Batch 2650: batch_loss=0.001624\n",
            "Batch 2660: batch_loss=0.008342\n",
            "Batch 2670: batch_loss=0.002758\n",
            "Batch 2680: batch_loss=0.000455\n",
            "Batch 2690: batch_loss=0.002256\n",
            "Batch 2700: batch_loss=0.004329\n",
            "Batch 2710: batch_loss=0.008035\n",
            "Batch 2720: batch_loss=0.008275\n",
            "Batch 2730: batch_loss=0.001906\n",
            "Batch 2740: batch_loss=0.000995\n",
            "Batch 2750: batch_loss=0.003288\n",
            "Batch 2760: batch_loss=0.007002\n",
            "Batch 2770: batch_loss=0.002754\n",
            "Batch 2780: batch_loss=0.001426\n",
            "Batch 2790: batch_loss=0.000753\n",
            "Batch 2800: batch_loss=0.002302\n",
            "Batch 2810: batch_loss=0.004040\n",
            "Batch 2820: batch_loss=0.003905\n",
            "Batch 2830: batch_loss=0.002734\n",
            "Batch 2840: batch_loss=0.001628\n",
            "Batch 2850: batch_loss=0.000962\n",
            "Batch 2860: batch_loss=0.003850\n",
            "Batch 2870: batch_loss=0.005497\n",
            "Batch 2880: batch_loss=0.002226\n",
            "Batch 2890: batch_loss=0.000270\n",
            "Batch 2900: batch_loss=0.003719\n",
            "Batch 2910: batch_loss=0.002174\n",
            "Batch 2920: batch_loss=0.001177\n",
            "Batch 2930: batch_loss=0.004429\n",
            "Batch 2940: batch_loss=0.002871\n",
            "Batch 2950: batch_loss=0.007355\n",
            "Batch 2960: batch_loss=0.001290\n",
            "Batch 2970: batch_loss=0.001818\n",
            "Batch 2980: batch_loss=0.000332\n",
            "Batch 2990: batch_loss=0.001888\n",
            "Batch 3000: batch_loss=0.001990\n",
            "Batch 3010: batch_loss=0.001877\n",
            "Batch 3020: batch_loss=0.000474\n",
            "Batch 3030: batch_loss=0.000904\n",
            "Batch 3040: batch_loss=0.002837\n",
            "Batch 3050: batch_loss=0.000308\n",
            "Batch 3060: batch_loss=0.001876\n",
            "Batch 3070: batch_loss=0.001440\n",
            "Batch 3080: batch_loss=0.002279\n",
            "Batch 3090: batch_loss=0.002984\n",
            "Batch 3100: batch_loss=0.005231\n",
            "Batch 3110: batch_loss=0.001816\n",
            "Batch 3120: batch_loss=0.002706\n",
            "Batch 3130: batch_loss=0.002229\n",
            "Batch 3140: batch_loss=0.001514\n",
            "Batch 3150: batch_loss=0.003438\n",
            "Batch 3160: batch_loss=0.000703\n",
            "Batch 3170: batch_loss=0.001452\n",
            "Batch 3180: batch_loss=0.000961\n",
            "Batch 3190: batch_loss=0.003314\n",
            "Batch 3200: batch_loss=0.002610\n",
            "Batch 3210: batch_loss=0.001835\n",
            "Batch 3220: batch_loss=0.001663\n",
            "Batch 3230: batch_loss=0.000667\n",
            "Batch 3240: batch_loss=0.002788\n",
            "Batch 3250: batch_loss=0.000099\n",
            "Batch 3260: batch_loss=0.002289\n",
            "Batch 3270: batch_loss=0.000571\n",
            "Batch 3280: batch_loss=0.006559\n",
            "Batch 3290: batch_loss=0.003642\n",
            "Batch 3300: batch_loss=0.001820\n",
            "Batch 3310: batch_loss=0.001339\n",
            "Batch 3320: batch_loss=0.001719\n",
            "Batch 3330: batch_loss=0.000918\n",
            "Batch 3340: batch_loss=0.005238\n",
            "Batch 3350: batch_loss=0.001068\n",
            "Batch 3360: batch_loss=0.004462\n",
            "Batch 3370: batch_loss=0.004505\n",
            "Batch 3380: batch_loss=0.000309\n",
            "Batch 3390: batch_loss=0.000780\n",
            "Batch 3400: batch_loss=0.001645\n",
            "Batch 3410: batch_loss=0.000986\n",
            "Batch 3420: batch_loss=0.002120\n",
            "Batch 3430: batch_loss=0.000381\n",
            "Batch 3440: batch_loss=0.002319\n",
            "Batch 3450: batch_loss=0.002394\n",
            "Batch 3460: batch_loss=0.006164\n",
            "Batch 3470: batch_loss=0.001924\n",
            "Batch 3480: batch_loss=0.001984\n",
            "Batch 3490: batch_loss=0.001260\n",
            "Batch 3500: batch_loss=0.001107\n",
            "Batch 3510: batch_loss=0.002034\n",
            "Batch 3520: batch_loss=0.003015\n",
            "Batch 3530: batch_loss=0.003522\n",
            "Batch 3540: batch_loss=0.002359\n",
            "Batch 3550: batch_loss=0.002916\n",
            "Batch 3560: batch_loss=0.002100\n",
            "Batch 3570: batch_loss=0.001209\n",
            "Batch 3580: batch_loss=0.004127\n",
            "Batch 3590: batch_loss=0.002379\n",
            "Batch 3600: batch_loss=0.000368\n",
            "Batch 3610: batch_loss=0.000191\n",
            "Batch 3620: batch_loss=0.001935\n",
            "Batch 3630: batch_loss=0.000128\n",
            "Batch 3640: batch_loss=0.000270\n",
            "Batch 3650: batch_loss=0.002604\n",
            "Batch 3660: batch_loss=0.001101\n",
            "Batch 3670: batch_loss=0.000261\n",
            "Batch 3680: batch_loss=0.003649\n",
            "Batch 3690: batch_loss=0.000635\n",
            "Batch 3700: batch_loss=0.003641\n",
            "Batch 3710: batch_loss=0.001550\n",
            "Batch 3720: batch_loss=0.002117\n",
            "Epoch 1/10, Train Loss: 0.401825, Val Loss: 0.011439\n",
            "Batch 0: batch_loss=0.001227\n",
            "Batch 10: batch_loss=0.001972\n",
            "Batch 20: batch_loss=0.001160\n",
            "Batch 30: batch_loss=0.001244\n",
            "Batch 40: batch_loss=0.001930\n",
            "Batch 50: batch_loss=0.005346\n",
            "Batch 60: batch_loss=0.001098\n",
            "Batch 70: batch_loss=0.002340\n",
            "Batch 80: batch_loss=0.001919\n",
            "Batch 90: batch_loss=0.002023\n",
            "Batch 100: batch_loss=0.000285\n",
            "Batch 110: batch_loss=0.000170\n",
            "Batch 120: batch_loss=0.001380\n",
            "Batch 130: batch_loss=0.002609\n",
            "Batch 140: batch_loss=0.001030\n",
            "Batch 150: batch_loss=0.002840\n",
            "Batch 160: batch_loss=0.000869\n",
            "Batch 170: batch_loss=0.007709\n",
            "Batch 180: batch_loss=0.001181\n",
            "Batch 190: batch_loss=0.000954\n",
            "Batch 200: batch_loss=0.001859\n",
            "Batch 210: batch_loss=0.001852\n",
            "Batch 220: batch_loss=0.002084\n",
            "Batch 230: batch_loss=0.003290\n",
            "Batch 240: batch_loss=0.001168\n",
            "Batch 250: batch_loss=0.000985\n",
            "Batch 260: batch_loss=0.001028\n",
            "Batch 270: batch_loss=0.003702\n",
            "Batch 280: batch_loss=0.000947\n",
            "Batch 290: batch_loss=0.002233\n",
            "Batch 300: batch_loss=0.003526\n",
            "Batch 310: batch_loss=0.003202\n",
            "Batch 320: batch_loss=0.000282\n",
            "Batch 330: batch_loss=0.003798\n",
            "Batch 340: batch_loss=0.003770\n",
            "Batch 350: batch_loss=0.002907\n",
            "Batch 360: batch_loss=0.001044\n",
            "Batch 370: batch_loss=0.000315\n",
            "Batch 380: batch_loss=0.001892\n",
            "Batch 390: batch_loss=0.003582\n",
            "Batch 400: batch_loss=0.002713\n",
            "Batch 410: batch_loss=0.000078\n",
            "Batch 420: batch_loss=0.001008\n",
            "Batch 430: batch_loss=0.002742\n",
            "Batch 440: batch_loss=0.003091\n",
            "Batch 450: batch_loss=0.002548\n",
            "Batch 460: batch_loss=0.003515\n",
            "Batch 470: batch_loss=0.001426\n",
            "Batch 480: batch_loss=0.002061\n",
            "Batch 490: batch_loss=0.002595\n",
            "Batch 500: batch_loss=0.000162\n",
            "Batch 510: batch_loss=0.001023\n",
            "Batch 520: batch_loss=0.000282\n",
            "Batch 530: batch_loss=0.002606\n",
            "Batch 540: batch_loss=0.000360\n",
            "Batch 550: batch_loss=0.001286\n",
            "Batch 560: batch_loss=0.002267\n",
            "Batch 570: batch_loss=0.001299\n",
            "Batch 580: batch_loss=0.000908\n",
            "Batch 590: batch_loss=0.002675\n",
            "Batch 600: batch_loss=0.003591\n",
            "Batch 610: batch_loss=0.003573\n",
            "Batch 620: batch_loss=0.001812\n",
            "Batch 630: batch_loss=0.001823\n",
            "Batch 640: batch_loss=0.001745\n",
            "Batch 650: batch_loss=0.000904\n",
            "Batch 660: batch_loss=0.001263\n",
            "Batch 670: batch_loss=0.000995\n",
            "Batch 680: batch_loss=0.001935\n",
            "Batch 690: batch_loss=0.002817\n",
            "Batch 700: batch_loss=0.001848\n",
            "Batch 710: batch_loss=0.000164\n",
            "Batch 720: batch_loss=0.003180\n",
            "Batch 730: batch_loss=0.001129\n",
            "Batch 740: batch_loss=0.004623\n",
            "Batch 750: batch_loss=0.000117\n",
            "Batch 760: batch_loss=0.001733\n",
            "Batch 770: batch_loss=0.002289\n",
            "Batch 780: batch_loss=0.000911\n",
            "Batch 790: batch_loss=0.001187\n",
            "Batch 800: batch_loss=0.001794\n",
            "Batch 810: batch_loss=0.000197\n",
            "Batch 820: batch_loss=0.001865\n",
            "Batch 830: batch_loss=0.002412\n",
            "Batch 840: batch_loss=0.000944\n",
            "Batch 850: batch_loss=0.002860\n",
            "Batch 860: batch_loss=0.002090\n",
            "Batch 870: batch_loss=0.006508\n",
            "Batch 880: batch_loss=0.000314\n",
            "Batch 890: batch_loss=0.001765\n",
            "Batch 900: batch_loss=0.002037\n",
            "Batch 910: batch_loss=0.001985\n",
            "Batch 920: batch_loss=0.000179\n",
            "Batch 930: batch_loss=0.001131\n",
            "Batch 940: batch_loss=0.001418\n",
            "Batch 950: batch_loss=0.002711\n",
            "Batch 960: batch_loss=0.000166\n",
            "Batch 970: batch_loss=0.002045\n",
            "Batch 980: batch_loss=0.001858\n",
            "Batch 990: batch_loss=0.002146\n",
            "Batch 1000: batch_loss=0.002245\n",
            "Batch 1010: batch_loss=0.003064\n",
            "Batch 1020: batch_loss=0.000286\n",
            "Batch 1030: batch_loss=0.000125\n",
            "Batch 1040: batch_loss=0.000231\n",
            "Batch 1050: batch_loss=0.001718\n",
            "Batch 1060: batch_loss=0.001482\n",
            "Batch 1070: batch_loss=0.001147\n",
            "Batch 1080: batch_loss=0.003946\n",
            "Batch 1090: batch_loss=0.001002\n",
            "Batch 1100: batch_loss=0.002776\n",
            "Batch 1110: batch_loss=0.003329\n",
            "Batch 1120: batch_loss=0.002477\n",
            "Batch 1130: batch_loss=0.001712\n",
            "Batch 1140: batch_loss=0.000466\n",
            "Batch 1150: batch_loss=0.002715\n",
            "Batch 1160: batch_loss=0.002145\n",
            "Batch 1170: batch_loss=0.002659\n",
            "Batch 1180: batch_loss=0.003369\n",
            "Batch 1190: batch_loss=0.001285\n",
            "Batch 1200: batch_loss=0.001891\n",
            "Batch 1210: batch_loss=0.001828\n",
            "Batch 1220: batch_loss=0.003075\n",
            "Batch 1230: batch_loss=0.001962\n",
            "Batch 1240: batch_loss=0.002658\n",
            "Batch 1250: batch_loss=0.002706\n",
            "Batch 1260: batch_loss=0.002533\n",
            "Batch 1270: batch_loss=0.002613\n",
            "Batch 1280: batch_loss=0.002771\n",
            "Batch 1290: batch_loss=0.001154\n",
            "Batch 1300: batch_loss=0.002106\n",
            "Batch 1310: batch_loss=0.000238\n",
            "Batch 1320: batch_loss=0.001277\n",
            "Batch 1330: batch_loss=0.000937\n",
            "Batch 1340: batch_loss=0.000230\n",
            "Batch 1350: batch_loss=0.000476\n",
            "Batch 1360: batch_loss=0.004666\n",
            "Batch 1370: batch_loss=0.001152\n",
            "Batch 1380: batch_loss=0.001037\n",
            "Batch 1390: batch_loss=0.000373\n",
            "Batch 1400: batch_loss=0.003604\n",
            "Batch 1410: batch_loss=0.003118\n",
            "Batch 1420: batch_loss=0.000257\n",
            "Batch 1430: batch_loss=0.002245\n",
            "Batch 1440: batch_loss=0.000913\n",
            "Batch 1450: batch_loss=0.000191\n",
            "Batch 1460: batch_loss=0.002852\n",
            "Batch 1470: batch_loss=0.001805\n",
            "Batch 1480: batch_loss=0.001128\n",
            "Batch 1490: batch_loss=0.003403\n",
            "Batch 1500: batch_loss=0.001193\n",
            "Batch 1510: batch_loss=0.000154\n",
            "Batch 1520: batch_loss=0.004561\n",
            "Batch 1530: batch_loss=0.002560\n",
            "Batch 1540: batch_loss=0.001225\n",
            "Batch 1550: batch_loss=0.001870\n",
            "Batch 1560: batch_loss=0.002814\n",
            "Batch 1570: batch_loss=0.000491\n",
            "Batch 1580: batch_loss=0.000945\n",
            "Batch 1590: batch_loss=0.003675\n",
            "Batch 1600: batch_loss=0.001443\n",
            "Batch 1610: batch_loss=0.000114\n",
            "Batch 1620: batch_loss=0.003048\n",
            "Batch 1630: batch_loss=0.002744\n",
            "Batch 1640: batch_loss=0.003350\n",
            "Batch 1650: batch_loss=0.000999\n",
            "Batch 1660: batch_loss=0.001888\n",
            "Batch 1670: batch_loss=0.000307\n",
            "Batch 1680: batch_loss=0.000152\n",
            "Batch 1690: batch_loss=0.001756\n",
            "Batch 1700: batch_loss=0.000878\n",
            "Batch 1710: batch_loss=0.001720\n",
            "Batch 1720: batch_loss=0.001750\n",
            "Batch 1730: batch_loss=0.000970\n",
            "Batch 1740: batch_loss=0.000233\n",
            "Batch 1750: batch_loss=0.001967\n",
            "Batch 1760: batch_loss=0.002169\n",
            "Batch 1770: batch_loss=0.000202\n",
            "Batch 1780: batch_loss=0.002820\n",
            "Batch 1790: batch_loss=0.001193\n",
            "Batch 1800: batch_loss=0.001862\n",
            "Batch 1810: batch_loss=0.000512\n",
            "Batch 1820: batch_loss=0.000211\n",
            "Batch 1830: batch_loss=0.000148\n",
            "Batch 1840: batch_loss=0.002671\n",
            "Batch 1850: batch_loss=0.002729\n",
            "Batch 1860: batch_loss=0.001864\n",
            "Batch 1870: batch_loss=0.004001\n",
            "Batch 1880: batch_loss=0.004410\n",
            "Batch 1890: batch_loss=0.001742\n",
            "Batch 1900: batch_loss=0.001381\n",
            "Batch 1910: batch_loss=0.002905\n",
            "Batch 1920: batch_loss=0.000120\n",
            "Batch 1930: batch_loss=0.001765\n",
            "Batch 1940: batch_loss=0.004320\n",
            "Batch 1950: batch_loss=0.000144\n",
            "Batch 1960: batch_loss=0.001932\n",
            "Batch 1970: batch_loss=0.001604\n",
            "Batch 1980: batch_loss=0.002279\n",
            "Batch 1990: batch_loss=0.001615\n",
            "Batch 2000: batch_loss=0.001226\n",
            "Batch 2010: batch_loss=0.000144\n",
            "Batch 2020: batch_loss=0.003429\n",
            "Batch 2030: batch_loss=0.000143\n",
            "Batch 2040: batch_loss=0.000970\n",
            "Batch 2050: batch_loss=0.000996\n",
            "Batch 2060: batch_loss=0.000984\n",
            "Batch 2070: batch_loss=0.001113\n",
            "Batch 2080: batch_loss=0.001234\n",
            "Batch 2090: batch_loss=0.000879\n",
            "Batch 2100: batch_loss=0.000885\n",
            "Batch 2110: batch_loss=0.000936\n",
            "Batch 2120: batch_loss=0.005075\n",
            "Batch 2130: batch_loss=0.000580\n",
            "Batch 2140: batch_loss=0.001891\n",
            "Batch 2150: batch_loss=0.000943\n",
            "Batch 2160: batch_loss=0.001776\n",
            "Batch 2170: batch_loss=0.001867\n",
            "Batch 2180: batch_loss=0.000893\n",
            "Batch 2190: batch_loss=0.003356\n",
            "Batch 2200: batch_loss=0.001009\n",
            "Batch 2210: batch_loss=0.001193\n",
            "Batch 2220: batch_loss=0.007000\n",
            "Batch 2230: batch_loss=0.000352\n",
            "Batch 2240: batch_loss=0.002574\n",
            "Batch 2250: batch_loss=0.001093\n",
            "Batch 2260: batch_loss=0.001996\n",
            "Batch 2270: batch_loss=0.004238\n",
            "Batch 2280: batch_loss=0.001787\n",
            "Batch 2290: batch_loss=0.000236\n",
            "Batch 2300: batch_loss=0.002688\n",
            "Batch 2310: batch_loss=0.001882\n",
            "Batch 2320: batch_loss=0.002863\n",
            "Batch 2330: batch_loss=0.003464\n",
            "Batch 2340: batch_loss=0.001082\n",
            "Batch 2350: batch_loss=0.000234\n",
            "Batch 2360: batch_loss=0.001904\n",
            "Batch 2370: batch_loss=0.001135\n",
            "Batch 2380: batch_loss=0.000919\n",
            "Batch 2390: batch_loss=0.000917\n",
            "Batch 2400: batch_loss=0.004380\n",
            "Batch 2410: batch_loss=0.003473\n",
            "Batch 2420: batch_loss=0.002622\n",
            "Batch 2430: batch_loss=0.001525\n",
            "Batch 2440: batch_loss=0.001171\n",
            "Batch 2450: batch_loss=0.000169\n",
            "Batch 2460: batch_loss=0.001799\n",
            "Batch 2470: batch_loss=0.004241\n",
            "Batch 2480: batch_loss=0.002834\n",
            "Batch 2490: batch_loss=0.001296\n",
            "Batch 2500: batch_loss=0.000150\n",
            "Batch 2510: batch_loss=0.000160\n",
            "Batch 2520: batch_loss=0.001262\n",
            "Batch 2530: batch_loss=0.000301\n",
            "Batch 2540: batch_loss=0.002425\n",
            "Batch 2550: batch_loss=0.002930\n",
            "Batch 2560: batch_loss=0.000246\n",
            "Batch 2570: batch_loss=0.003951\n",
            "Batch 2580: batch_loss=0.001909\n",
            "Batch 2590: batch_loss=0.001936\n",
            "Batch 2600: batch_loss=0.000697\n",
            "Batch 2610: batch_loss=0.002826\n",
            "Batch 2620: batch_loss=0.002954\n",
            "Batch 2630: batch_loss=0.002043\n",
            "Batch 2640: batch_loss=0.007893\n",
            "Batch 2650: batch_loss=0.002505\n",
            "Batch 2660: batch_loss=0.000066\n",
            "Batch 2670: batch_loss=0.005161\n",
            "Batch 2680: batch_loss=0.000912\n",
            "Batch 2690: batch_loss=0.001757\n",
            "Batch 2700: batch_loss=0.000972\n",
            "Batch 2710: batch_loss=0.002268\n",
            "Batch 2720: batch_loss=0.001886\n",
            "Batch 2730: batch_loss=0.000188\n",
            "Batch 2740: batch_loss=0.000321\n",
            "Batch 2750: batch_loss=0.005920\n",
            "Batch 2760: batch_loss=0.000231\n",
            "Batch 2770: batch_loss=0.002347\n",
            "Batch 2780: batch_loss=0.002882\n",
            "Batch 2790: batch_loss=0.000063\n",
            "Batch 2800: batch_loss=0.001777\n",
            "Batch 2810: batch_loss=0.001798\n",
            "Batch 2820: batch_loss=0.000216\n",
            "Batch 2830: batch_loss=0.003449\n",
            "Batch 2840: batch_loss=0.001034\n",
            "Batch 2850: batch_loss=0.000923\n",
            "Batch 2860: batch_loss=0.000789\n",
            "Batch 2870: batch_loss=0.001114\n",
            "Batch 2880: batch_loss=0.001827\n",
            "Batch 2890: batch_loss=0.001169\n",
            "Batch 2900: batch_loss=0.001315\n",
            "Batch 2910: batch_loss=0.001926\n",
            "Batch 2920: batch_loss=0.001233\n",
            "Batch 2930: batch_loss=0.003614\n",
            "Batch 2940: batch_loss=0.003237\n",
            "Batch 2950: batch_loss=0.000425\n",
            "Batch 2960: batch_loss=0.000984\n",
            "Batch 2970: batch_loss=0.000234\n",
            "Batch 2980: batch_loss=0.001047\n",
            "Batch 2990: batch_loss=0.001699\n",
            "Batch 3000: batch_loss=0.001799\n",
            "Batch 3010: batch_loss=0.001263\n",
            "Batch 3020: batch_loss=0.001736\n",
            "Batch 3030: batch_loss=0.001093\n",
            "Batch 3040: batch_loss=0.002516\n",
            "Batch 3050: batch_loss=0.000983\n",
            "Batch 3060: batch_loss=0.001062\n",
            "Batch 3070: batch_loss=0.000225\n",
            "Batch 3080: batch_loss=0.003378\n",
            "Batch 3090: batch_loss=0.000889\n",
            "Batch 3100: batch_loss=0.000900\n",
            "Batch 3110: batch_loss=0.001758\n",
            "Batch 3120: batch_loss=0.001858\n",
            "Batch 3130: batch_loss=0.003021\n",
            "Batch 3140: batch_loss=0.000091\n",
            "Batch 3150: batch_loss=0.001777\n",
            "Batch 3160: batch_loss=0.000279\n",
            "Batch 3170: batch_loss=0.002719\n",
            "Batch 3180: batch_loss=0.000977\n",
            "Batch 3190: batch_loss=0.001857\n",
            "Batch 3200: batch_loss=0.000238\n",
            "Batch 3210: batch_loss=0.000073\n",
            "Batch 3220: batch_loss=0.000108\n",
            "Batch 3230: batch_loss=0.000915\n",
            "Batch 3240: batch_loss=0.000998\n",
            "Batch 3250: batch_loss=0.001880\n",
            "Batch 3260: batch_loss=0.001771\n",
            "Batch 3270: batch_loss=0.000976\n",
            "Batch 3280: batch_loss=0.000069\n",
            "Batch 3290: batch_loss=0.001862\n",
            "Batch 3300: batch_loss=0.000977\n",
            "Batch 3310: batch_loss=0.000575\n",
            "Batch 3320: batch_loss=0.000223\n",
            "Batch 3330: batch_loss=0.001357\n",
            "Batch 3340: batch_loss=0.000959\n",
            "Batch 3350: batch_loss=0.001805\n",
            "Batch 3360: batch_loss=0.002500\n",
            "Batch 3370: batch_loss=0.001738\n",
            "Batch 3380: batch_loss=0.000978\n",
            "Batch 3390: batch_loss=0.000247\n",
            "Batch 3400: batch_loss=0.001846\n",
            "Batch 3410: batch_loss=0.003369\n",
            "Batch 3420: batch_loss=0.000973\n",
            "Batch 3430: batch_loss=0.001087\n",
            "Batch 3440: batch_loss=0.002585\n",
            "Batch 3450: batch_loss=0.000058\n",
            "Batch 3460: batch_loss=0.001871\n",
            "Batch 3470: batch_loss=0.000979\n",
            "Batch 3480: batch_loss=0.000941\n",
            "Batch 3490: batch_loss=0.000958\n",
            "Batch 3500: batch_loss=0.001725\n",
            "Batch 3510: batch_loss=0.000150\n",
            "Batch 3520: batch_loss=0.003391\n",
            "Batch 3530: batch_loss=0.001070\n",
            "Batch 3540: batch_loss=0.002858\n",
            "Batch 3550: batch_loss=0.000099\n",
            "Batch 3560: batch_loss=0.001217\n",
            "Batch 3570: batch_loss=0.000918\n",
            "Batch 3580: batch_loss=0.002554\n",
            "Batch 3590: batch_loss=0.001376\n",
            "Batch 3600: batch_loss=0.001780\n",
            "Batch 3610: batch_loss=0.002120\n",
            "Batch 3620: batch_loss=0.001787\n",
            "Batch 3630: batch_loss=0.000106\n",
            "Batch 3640: batch_loss=0.002987\n",
            "Batch 3650: batch_loss=0.001784\n",
            "Batch 3660: batch_loss=0.001820\n",
            "Batch 3670: batch_loss=0.002677\n",
            "Batch 3680: batch_loss=0.000135\n",
            "Batch 3690: batch_loss=0.001056\n",
            "Batch 3700: batch_loss=0.001001\n",
            "Batch 3710: batch_loss=0.001062\n",
            "Batch 3720: batch_loss=0.000968\n",
            "Epoch 2/10, Train Loss: 0.001826, Val Loss: 0.001881\n",
            "Batch 0: batch_loss=0.001756\n",
            "Batch 10: batch_loss=0.001146\n",
            "Batch 20: batch_loss=0.003396\n",
            "Batch 30: batch_loss=0.001767\n",
            "Batch 40: batch_loss=0.000094\n",
            "Batch 50: batch_loss=0.000264\n",
            "Batch 60: batch_loss=0.002963\n",
            "Batch 70: batch_loss=0.001102\n",
            "Batch 80: batch_loss=0.000915\n",
            "Batch 90: batch_loss=0.000055\n",
            "Batch 100: batch_loss=0.001728\n",
            "Batch 110: batch_loss=0.000224\n",
            "Batch 120: batch_loss=0.002536\n",
            "Batch 130: batch_loss=0.001789\n",
            "Batch 140: batch_loss=0.000899\n",
            "Batch 150: batch_loss=0.000929\n",
            "Batch 160: batch_loss=0.000081\n",
            "Batch 170: batch_loss=0.000957\n",
            "Batch 180: batch_loss=0.003421\n",
            "Batch 190: batch_loss=0.001262\n",
            "Batch 200: batch_loss=0.002574\n",
            "Batch 210: batch_loss=0.002165\n",
            "Batch 220: batch_loss=0.000452\n",
            "Batch 230: batch_loss=0.001858\n",
            "Batch 240: batch_loss=0.000045\n",
            "Batch 250: batch_loss=0.000115\n",
            "Batch 260: batch_loss=0.000435\n",
            "Batch 270: batch_loss=0.001124\n",
            "Batch 280: batch_loss=0.000122\n",
            "Batch 290: batch_loss=0.001761\n",
            "Batch 300: batch_loss=0.002585\n",
            "Batch 310: batch_loss=0.001789\n",
            "Batch 320: batch_loss=0.001899\n",
            "Batch 330: batch_loss=0.001757\n",
            "Batch 340: batch_loss=0.000152\n",
            "Batch 350: batch_loss=0.001733\n",
            "Batch 360: batch_loss=0.000224\n",
            "Batch 370: batch_loss=0.001054\n",
            "Batch 380: batch_loss=0.000270\n",
            "Batch 390: batch_loss=0.003574\n",
            "Batch 400: batch_loss=0.001790\n",
            "Batch 410: batch_loss=0.000256\n",
            "Batch 420: batch_loss=0.001919\n",
            "Batch 430: batch_loss=0.001086\n",
            "Batch 440: batch_loss=0.000252\n",
            "Batch 450: batch_loss=0.000992\n",
            "Batch 460: batch_loss=0.001698\n",
            "Batch 470: batch_loss=0.003350\n",
            "Batch 480: batch_loss=0.003465\n",
            "Batch 490: batch_loss=0.000594\n",
            "Batch 500: batch_loss=0.001275\n",
            "Batch 510: batch_loss=0.001050\n",
            "Batch 520: batch_loss=0.001714\n",
            "Batch 530: batch_loss=0.002687\n",
            "Batch 540: batch_loss=0.000974\n",
            "Batch 550: batch_loss=0.000167\n",
            "Batch 560: batch_loss=0.002629\n",
            "Batch 570: batch_loss=0.001909\n",
            "Batch 580: batch_loss=0.002509\n",
            "Batch 590: batch_loss=0.001052\n",
            "Batch 600: batch_loss=0.000974\n",
            "Batch 610: batch_loss=0.000105\n",
            "Batch 620: batch_loss=0.001795\n",
            "Batch 630: batch_loss=0.002561\n",
            "Batch 640: batch_loss=0.000943\n",
            "Batch 650: batch_loss=0.003370\n",
            "Batch 660: batch_loss=0.000130\n",
            "Batch 670: batch_loss=0.000131\n",
            "Batch 680: batch_loss=0.010176\n",
            "Batch 690: batch_loss=0.000126\n",
            "Batch 700: batch_loss=0.000919\n",
            "Batch 710: batch_loss=0.002558\n",
            "Batch 720: batch_loss=0.000192\n",
            "Batch 730: batch_loss=0.001803\n",
            "Batch 740: batch_loss=0.000117\n",
            "Batch 750: batch_loss=0.003660\n",
            "Batch 760: batch_loss=0.000943\n",
            "Batch 770: batch_loss=0.001995\n",
            "Batch 780: batch_loss=0.001207\n",
            "Batch 790: batch_loss=0.002631\n",
            "Batch 800: batch_loss=0.001779\n",
            "Batch 810: batch_loss=0.000116\n",
            "Batch 820: batch_loss=0.001713\n",
            "Batch 830: batch_loss=0.000897\n",
            "Batch 840: batch_loss=0.001758\n",
            "Batch 850: batch_loss=0.002579\n",
            "Batch 860: batch_loss=0.001685\n",
            "Batch 870: batch_loss=0.002588\n",
            "Batch 880: batch_loss=0.002634\n",
            "Batch 890: batch_loss=0.000935\n",
            "Batch 900: batch_loss=0.001777\n",
            "Batch 910: batch_loss=0.000978\n",
            "Batch 920: batch_loss=0.000093\n",
            "Batch 930: batch_loss=0.000073\n",
            "Batch 940: batch_loss=0.001789\n",
            "Batch 950: batch_loss=0.004337\n",
            "Batch 960: batch_loss=0.000216\n",
            "Batch 970: batch_loss=0.002574\n",
            "Batch 980: batch_loss=0.000311\n",
            "Batch 990: batch_loss=0.000087\n",
            "Batch 1000: batch_loss=0.000968\n",
            "Batch 1010: batch_loss=0.001985\n",
            "Batch 1020: batch_loss=0.001850\n",
            "Batch 1030: batch_loss=0.007477\n",
            "Batch 1040: batch_loss=0.000980\n",
            "Batch 1050: batch_loss=0.001273\n",
            "Batch 1060: batch_loss=0.001198\n",
            "Batch 1070: batch_loss=0.001320\n",
            "Batch 1080: batch_loss=0.003315\n",
            "Batch 1090: batch_loss=0.000966\n",
            "Batch 1100: batch_loss=0.001004\n",
            "Batch 1110: batch_loss=0.001214\n",
            "Batch 1120: batch_loss=0.001825\n",
            "Batch 1130: batch_loss=0.000939\n",
            "Batch 1140: batch_loss=0.002685\n",
            "Batch 1150: batch_loss=0.000036\n",
            "Batch 1160: batch_loss=0.007858\n",
            "Batch 1170: batch_loss=0.000077\n",
            "Batch 1180: batch_loss=0.000931\n",
            "Batch 1190: batch_loss=0.001754\n",
            "Batch 1200: batch_loss=0.001750\n",
            "Batch 1210: batch_loss=0.001706\n",
            "Batch 1220: batch_loss=0.002701\n",
            "Batch 1230: batch_loss=0.000146\n",
            "Batch 1240: batch_loss=0.001793\n",
            "Batch 1250: batch_loss=0.001226\n",
            "Batch 1260: batch_loss=0.002292\n",
            "Batch 1270: batch_loss=0.000948\n",
            "Batch 1280: batch_loss=0.001844\n",
            "Batch 1290: batch_loss=0.002746\n",
            "Batch 1300: batch_loss=0.000885\n",
            "Batch 1310: batch_loss=0.000177\n",
            "Batch 1320: batch_loss=0.001703\n",
            "Batch 1330: batch_loss=0.001129\n",
            "Batch 1340: batch_loss=0.000111\n",
            "Batch 1350: batch_loss=0.001933\n",
            "Batch 1360: batch_loss=0.001005\n",
            "Batch 1370: batch_loss=0.001145\n",
            "Batch 1380: batch_loss=0.000174\n",
            "Batch 1390: batch_loss=0.000139\n",
            "Batch 1400: batch_loss=0.000193\n",
            "Batch 1410: batch_loss=0.002688\n",
            "Batch 1420: batch_loss=0.001161\n",
            "Batch 1430: batch_loss=0.002588\n",
            "Batch 1440: batch_loss=0.000152\n",
            "Batch 1450: batch_loss=0.003437\n",
            "Batch 1460: batch_loss=0.000164\n",
            "Batch 1470: batch_loss=0.001255\n",
            "Batch 1480: batch_loss=0.000105\n",
            "Batch 1490: batch_loss=0.001104\n",
            "Batch 1500: batch_loss=0.001833\n",
            "Batch 1510: batch_loss=0.002938\n",
            "Batch 1520: batch_loss=0.000943\n",
            "Batch 1530: batch_loss=0.001349\n",
            "Batch 1540: batch_loss=0.001013\n",
            "Batch 1550: batch_loss=0.001984\n",
            "Batch 1560: batch_loss=0.001048\n",
            "Batch 1570: batch_loss=0.000897\n",
            "Batch 1580: batch_loss=0.000152\n",
            "Batch 1590: batch_loss=0.000130\n",
            "Batch 1600: batch_loss=0.001785\n",
            "Batch 1610: batch_loss=0.000091\n",
            "Batch 1620: batch_loss=0.000951\n",
            "Batch 1630: batch_loss=0.000962\n",
            "Batch 1640: batch_loss=0.003604\n",
            "Batch 1650: batch_loss=0.001824\n",
            "Batch 1660: batch_loss=0.000343\n",
            "Batch 1670: batch_loss=0.000914\n",
            "Batch 1680: batch_loss=0.004897\n",
            "Batch 1690: batch_loss=0.001856\n",
            "Batch 1700: batch_loss=0.001912\n",
            "Batch 1710: batch_loss=0.001857\n",
            "Batch 1720: batch_loss=0.001744\n",
            "Batch 1730: batch_loss=0.000150\n",
            "Batch 1740: batch_loss=0.000968\n",
            "Batch 1750: batch_loss=0.001010\n",
            "Batch 1760: batch_loss=0.001120\n",
            "Batch 1770: batch_loss=0.001962\n",
            "Batch 1780: batch_loss=0.000936\n",
            "Batch 1790: batch_loss=0.001751\n",
            "Batch 1800: batch_loss=0.004203\n",
            "Batch 1810: batch_loss=0.001058\n",
            "Batch 1820: batch_loss=0.001806\n",
            "Batch 1830: batch_loss=0.000234\n",
            "Batch 1840: batch_loss=0.000951\n",
            "Batch 1850: batch_loss=0.000342\n",
            "Batch 1860: batch_loss=0.000127\n",
            "Batch 1870: batch_loss=0.003370\n",
            "Batch 1880: batch_loss=0.000091\n",
            "Batch 1890: batch_loss=0.000957\n",
            "Batch 1900: batch_loss=0.003389\n",
            "Batch 1910: batch_loss=0.003059\n",
            "Batch 1920: batch_loss=0.000426\n",
            "Batch 1930: batch_loss=0.001309\n",
            "Batch 1940: batch_loss=0.002643\n",
            "Batch 1950: batch_loss=0.000936\n",
            "Batch 1960: batch_loss=0.001713\n",
            "Batch 1970: batch_loss=0.008204\n",
            "Batch 1980: batch_loss=0.000152\n",
            "Batch 1990: batch_loss=0.001819\n",
            "Batch 2000: batch_loss=0.001784\n",
            "Batch 2010: batch_loss=0.001740\n",
            "Batch 2020: batch_loss=0.000194\n",
            "Batch 2030: batch_loss=0.001006\n",
            "Batch 2040: batch_loss=0.000187\n",
            "Batch 2050: batch_loss=0.000124\n",
            "Batch 2060: batch_loss=0.002024\n",
            "Batch 2070: batch_loss=0.000991\n",
            "Batch 2080: batch_loss=0.002641\n",
            "Batch 2090: batch_loss=0.003348\n",
            "Batch 2100: batch_loss=0.000895\n",
            "Batch 2110: batch_loss=0.000164\n",
            "Batch 2120: batch_loss=0.001721\n",
            "Batch 2130: batch_loss=0.001768\n",
            "Batch 2140: batch_loss=0.000088\n",
            "Batch 2150: batch_loss=0.000947\n",
            "Batch 2160: batch_loss=0.004311\n",
            "Batch 2170: batch_loss=0.002526\n",
            "Batch 2180: batch_loss=0.001780\n",
            "Batch 2190: batch_loss=0.002569\n",
            "Batch 2200: batch_loss=0.001869\n",
            "Batch 2210: batch_loss=0.008429\n",
            "Batch 2220: batch_loss=0.001701\n",
            "Batch 2230: batch_loss=0.000930\n",
            "Batch 2240: batch_loss=0.004498\n",
            "Batch 2250: batch_loss=0.000199\n",
            "Batch 2260: batch_loss=0.000105\n",
            "Batch 2270: batch_loss=0.000413\n",
            "Batch 2280: batch_loss=0.004211\n",
            "Batch 2290: batch_loss=0.000089\n",
            "Batch 2300: batch_loss=0.001791\n",
            "Batch 2310: batch_loss=0.001083\n",
            "Batch 2320: batch_loss=0.001745\n",
            "Batch 2330: batch_loss=0.000082\n",
            "Batch 2340: batch_loss=0.002025\n",
            "Batch 2350: batch_loss=0.001002\n",
            "Batch 2360: batch_loss=0.000979\n",
            "Batch 2370: batch_loss=0.001894\n",
            "Batch 2380: batch_loss=0.002615\n",
            "Batch 2390: batch_loss=0.000190\n",
            "Batch 2400: batch_loss=0.001830\n",
            "Batch 2410: batch_loss=0.006697\n",
            "Batch 2420: batch_loss=0.002575\n",
            "Batch 2430: batch_loss=0.000126\n",
            "Batch 2440: batch_loss=0.000177\n",
            "Batch 2450: batch_loss=0.000053\n",
            "Batch 2460: batch_loss=0.000908\n",
            "Batch 2470: batch_loss=0.000881\n",
            "Batch 2480: batch_loss=0.000882\n",
            "Batch 2490: batch_loss=0.000945\n",
            "Batch 2500: batch_loss=0.002391\n",
            "Batch 2510: batch_loss=0.003403\n",
            "Batch 2520: batch_loss=0.003334\n",
            "Batch 2530: batch_loss=0.000978\n",
            "Batch 2540: batch_loss=0.003042\n",
            "Batch 2550: batch_loss=0.002595\n",
            "Batch 2560: batch_loss=0.005835\n",
            "Batch 2570: batch_loss=0.000709\n",
            "Batch 2580: batch_loss=0.000409\n",
            "Batch 2590: batch_loss=0.000950\n",
            "Batch 2600: batch_loss=0.001750\n",
            "Batch 2610: batch_loss=0.003910\n",
            "Batch 2620: batch_loss=0.001075\n",
            "Batch 2630: batch_loss=0.001707\n",
            "Batch 2640: batch_loss=0.003368\n",
            "Batch 2650: batch_loss=0.000929\n",
            "Batch 2660: batch_loss=0.001744\n",
            "Batch 2670: batch_loss=0.001062\n",
            "Batch 2680: batch_loss=0.003348\n",
            "Batch 2690: batch_loss=0.003432\n",
            "Batch 2700: batch_loss=0.000151\n",
            "Batch 2710: batch_loss=0.004252\n",
            "Batch 2720: batch_loss=0.000966\n",
            "Batch 2730: batch_loss=0.000923\n",
            "Batch 2740: batch_loss=0.002538\n",
            "Batch 2750: batch_loss=0.000117\n",
            "Batch 2760: batch_loss=0.002673\n",
            "Batch 2770: batch_loss=0.001718\n",
            "Batch 2780: batch_loss=0.002680\n",
            "Batch 2790: batch_loss=0.000112\n",
            "Batch 2800: batch_loss=0.000904\n",
            "Batch 2810: batch_loss=0.000090\n",
            "Batch 2820: batch_loss=0.001799\n",
            "Batch 2830: batch_loss=0.002603\n",
            "Batch 2840: batch_loss=0.001183\n",
            "Batch 2850: batch_loss=0.002520\n",
            "Batch 2860: batch_loss=0.000961\n",
            "Batch 2870: batch_loss=0.000272\n",
            "Batch 2880: batch_loss=0.001141\n",
            "Batch 2890: batch_loss=0.002585\n",
            "Batch 2900: batch_loss=0.001925\n",
            "Batch 2910: batch_loss=0.001798\n",
            "Batch 2920: batch_loss=0.002348\n",
            "Batch 2930: batch_loss=0.003440\n",
            "Batch 2940: batch_loss=0.002546\n",
            "Batch 2950: batch_loss=0.000059\n",
            "Batch 2960: batch_loss=0.001868\n",
            "Batch 2970: batch_loss=0.000095\n",
            "Batch 2980: batch_loss=0.000982\n",
            "Batch 2990: batch_loss=0.002576\n",
            "Batch 3000: batch_loss=0.000077\n",
            "Batch 3010: batch_loss=0.000085\n",
            "Batch 3020: batch_loss=0.001066\n",
            "Batch 3030: batch_loss=0.001933\n",
            "Batch 3040: batch_loss=0.001188\n",
            "Batch 3050: batch_loss=0.000906\n",
            "Batch 3060: batch_loss=0.002538\n",
            "Batch 3070: batch_loss=0.000967\n",
            "Batch 3080: batch_loss=0.002576\n",
            "Batch 3090: batch_loss=0.000134\n",
            "Batch 3100: batch_loss=0.002569\n",
            "Batch 3110: batch_loss=0.001674\n",
            "Batch 3120: batch_loss=0.001002\n",
            "Batch 3130: batch_loss=0.001081\n",
            "Batch 3140: batch_loss=0.001717\n",
            "Batch 3150: batch_loss=0.000869\n",
            "Batch 3160: batch_loss=0.001719\n",
            "Batch 3170: batch_loss=0.001701\n",
            "Batch 3180: batch_loss=0.000080\n",
            "Batch 3190: batch_loss=0.000098\n",
            "Batch 3200: batch_loss=0.000929\n",
            "Batch 3210: batch_loss=0.002633\n",
            "Batch 3220: batch_loss=0.002536\n",
            "Batch 3230: batch_loss=0.000081\n",
            "Batch 3240: batch_loss=0.000201\n",
            "Batch 3250: batch_loss=0.004161\n",
            "Batch 3260: batch_loss=0.001862\n",
            "Batch 3270: batch_loss=0.001011\n",
            "Batch 3280: batch_loss=0.001895\n",
            "Batch 3290: batch_loss=0.000963\n",
            "Batch 3300: batch_loss=0.000976\n",
            "Batch 3310: batch_loss=0.002660\n",
            "Batch 3320: batch_loss=0.001886\n",
            "Batch 3330: batch_loss=0.000966\n",
            "Batch 3340: batch_loss=0.000133\n",
            "Batch 3350: batch_loss=0.001726\n",
            "Batch 3360: batch_loss=0.000948\n",
            "Batch 3370: batch_loss=0.000217\n",
            "Batch 3380: batch_loss=0.002533\n",
            "Batch 3390: batch_loss=0.000947\n",
            "Batch 3400: batch_loss=0.001084\n",
            "Batch 3410: batch_loss=0.003941\n",
            "Batch 3420: batch_loss=0.000893\n",
            "Batch 3430: batch_loss=0.000934\n",
            "Batch 3440: batch_loss=0.000982\n",
            "Batch 3450: batch_loss=0.001735\n",
            "Batch 3460: batch_loss=0.003452\n",
            "Batch 3470: batch_loss=0.000108\n",
            "Batch 3480: batch_loss=0.000998\n",
            "Batch 3490: batch_loss=0.000042\n",
            "Batch 3500: batch_loss=0.000914\n",
            "Batch 3510: batch_loss=0.000105\n",
            "Batch 3520: batch_loss=0.001738\n",
            "Batch 3530: batch_loss=0.000042\n",
            "Batch 3540: batch_loss=0.000953\n",
            "Batch 3550: batch_loss=0.000990\n",
            "Batch 3560: batch_loss=0.002838\n",
            "Batch 3570: batch_loss=0.000969\n",
            "Batch 3580: batch_loss=0.002581\n",
            "Batch 3590: batch_loss=0.001710\n",
            "Batch 3600: batch_loss=0.000186\n",
            "Batch 3610: batch_loss=0.000044\n",
            "Batch 3620: batch_loss=0.000988\n",
            "Batch 3630: batch_loss=0.000218\n",
            "Batch 3640: batch_loss=0.001876\n",
            "Batch 3650: batch_loss=0.004233\n",
            "Batch 3660: batch_loss=0.002518\n",
            "Batch 3670: batch_loss=0.000148\n",
            "Batch 3680: batch_loss=0.000062\n",
            "Batch 3690: batch_loss=0.000944\n",
            "Batch 3700: batch_loss=0.000919\n",
            "Batch 3710: batch_loss=0.004189\n",
            "Batch 3720: batch_loss=0.008228\n",
            "Epoch 3/10, Train Loss: 0.001550, Val Loss: 0.001651\n",
            "Batch 0: batch_loss=0.001838\n",
            "Batch 10: batch_loss=0.000264\n",
            "Batch 20: batch_loss=0.000231\n",
            "Batch 30: batch_loss=0.001701\n",
            "Batch 40: batch_loss=0.002772\n",
            "Batch 50: batch_loss=0.002615\n",
            "Batch 60: batch_loss=0.000114\n",
            "Batch 70: batch_loss=0.001002\n",
            "Batch 80: batch_loss=0.001880\n",
            "Batch 90: batch_loss=0.000893\n",
            "Batch 100: batch_loss=0.000116\n",
            "Batch 110: batch_loss=0.004181\n",
            "Batch 120: batch_loss=0.001108\n",
            "Batch 130: batch_loss=0.003365\n",
            "Batch 140: batch_loss=0.002516\n",
            "Batch 150: batch_loss=0.004134\n",
            "Batch 160: batch_loss=0.003532\n",
            "Batch 170: batch_loss=0.002803\n",
            "Batch 180: batch_loss=0.000892\n",
            "Batch 190: batch_loss=0.001164\n",
            "Batch 200: batch_loss=0.000156\n",
            "Batch 210: batch_loss=0.004643\n",
            "Batch 220: batch_loss=0.010884\n",
            "Batch 230: batch_loss=0.000104\n",
            "Batch 240: batch_loss=0.003324\n",
            "Batch 250: batch_loss=0.001714\n",
            "Batch 260: batch_loss=0.002110\n",
            "Batch 270: batch_loss=0.002762\n",
            "Batch 280: batch_loss=0.000278\n",
            "Batch 290: batch_loss=0.000217\n",
            "Batch 300: batch_loss=0.001739\n",
            "Batch 310: batch_loss=0.000317\n",
            "Batch 320: batch_loss=0.001007\n",
            "Batch 330: batch_loss=0.000964\n",
            "Batch 340: batch_loss=0.001733\n",
            "Batch 350: batch_loss=0.000875\n",
            "Batch 360: batch_loss=0.001033\n",
            "Batch 370: batch_loss=0.002637\n",
            "Batch 380: batch_loss=0.000229\n",
            "Batch 390: batch_loss=0.001089\n",
            "Batch 400: batch_loss=0.000164\n",
            "Batch 410: batch_loss=0.001104\n",
            "Batch 420: batch_loss=0.000147\n",
            "Batch 430: batch_loss=0.000949\n",
            "Batch 440: batch_loss=0.005064\n",
            "Batch 450: batch_loss=0.000974\n",
            "Batch 460: batch_loss=0.001195\n",
            "Batch 470: batch_loss=0.001140\n",
            "Batch 480: batch_loss=0.003483\n",
            "Batch 490: batch_loss=0.001185\n",
            "Batch 500: batch_loss=0.001053\n",
            "Batch 510: batch_loss=0.000190\n",
            "Batch 520: batch_loss=0.000212\n",
            "Batch 530: batch_loss=0.002557\n",
            "Batch 540: batch_loss=0.000864\n",
            "Batch 550: batch_loss=0.002606\n",
            "Batch 560: batch_loss=0.001769\n",
            "Batch 570: batch_loss=0.001247\n",
            "Batch 580: batch_loss=0.001013\n",
            "Batch 590: batch_loss=0.000060\n",
            "Batch 600: batch_loss=0.000927\n",
            "Batch 610: batch_loss=0.001880\n",
            "Batch 620: batch_loss=0.001748\n",
            "Batch 630: batch_loss=0.000101\n",
            "Batch 640: batch_loss=0.000129\n",
            "Batch 650: batch_loss=0.000057\n",
            "Batch 660: batch_loss=0.003348\n",
            "Batch 670: batch_loss=0.000871\n",
            "Batch 680: batch_loss=0.000988\n",
            "Batch 690: batch_loss=0.001097\n",
            "Batch 700: batch_loss=0.000992\n",
            "Batch 710: batch_loss=0.004237\n",
            "Batch 720: batch_loss=0.003358\n",
            "Batch 730: batch_loss=0.000170\n",
            "Batch 740: batch_loss=0.000921\n",
            "Batch 750: batch_loss=0.000953\n",
            "Batch 760: batch_loss=0.001789\n",
            "Batch 770: batch_loss=0.001012\n",
            "Batch 780: batch_loss=0.000177\n",
            "Batch 790: batch_loss=0.003423\n",
            "Batch 800: batch_loss=0.000868\n",
            "Batch 810: batch_loss=0.001730\n",
            "Batch 820: batch_loss=0.000155\n",
            "Batch 830: batch_loss=0.001860\n",
            "Batch 840: batch_loss=0.001757\n",
            "Batch 850: batch_loss=0.002525\n",
            "Batch 860: batch_loss=0.001082\n",
            "Batch 870: batch_loss=0.000186\n",
            "Batch 880: batch_loss=0.001761\n",
            "Batch 890: batch_loss=0.000133\n",
            "Batch 900: batch_loss=0.000916\n",
            "Batch 910: batch_loss=0.000071\n",
            "Batch 920: batch_loss=0.003468\n",
            "Batch 930: batch_loss=0.000156\n",
            "Batch 940: batch_loss=0.000144\n",
            "Batch 950: batch_loss=0.000940\n",
            "Batch 960: batch_loss=0.001768\n",
            "Batch 970: batch_loss=0.000900\n",
            "Batch 980: batch_loss=0.000067\n",
            "Batch 990: batch_loss=0.000957\n",
            "Batch 1000: batch_loss=0.000932\n",
            "Batch 1010: batch_loss=0.001726\n",
            "Batch 1020: batch_loss=0.001744\n",
            "Batch 1030: batch_loss=0.001020\n",
            "Batch 1040: batch_loss=0.001703\n",
            "Batch 1050: batch_loss=0.001714\n",
            "Batch 1060: batch_loss=0.000861\n",
            "Batch 1070: batch_loss=0.001703\n",
            "Batch 1080: batch_loss=0.000950\n",
            "Batch 1090: batch_loss=0.001759\n",
            "Batch 1100: batch_loss=0.001720\n",
            "Batch 1110: batch_loss=0.001221\n",
            "Batch 1120: batch_loss=0.001707\n",
            "Batch 1130: batch_loss=0.001729\n",
            "Batch 1140: batch_loss=0.001784\n",
            "Batch 1150: batch_loss=0.000915\n",
            "Batch 1160: batch_loss=0.004990\n",
            "Batch 1170: batch_loss=0.000968\n",
            "Batch 1180: batch_loss=0.000940\n",
            "Batch 1190: batch_loss=0.000069\n",
            "Batch 1200: batch_loss=0.001777\n",
            "Batch 1210: batch_loss=0.002576\n",
            "Batch 1220: batch_loss=0.004335\n",
            "Batch 1230: batch_loss=0.001773\n",
            "Batch 1240: batch_loss=0.000124\n",
            "Batch 1250: batch_loss=0.000179\n",
            "Batch 1260: batch_loss=0.000046\n",
            "Batch 1270: batch_loss=0.000894\n",
            "Batch 1280: batch_loss=0.001017\n",
            "Batch 1290: batch_loss=0.001693\n",
            "Batch 1300: batch_loss=0.004221\n",
            "Batch 1310: batch_loss=0.001747\n",
            "Batch 1320: batch_loss=0.001740\n",
            "Batch 1330: batch_loss=0.001834\n",
            "Batch 1340: batch_loss=0.000031\n",
            "Batch 1350: batch_loss=0.000123\n",
            "Batch 1360: batch_loss=0.001893\n",
            "Batch 1370: batch_loss=0.000907\n",
            "Batch 1380: batch_loss=0.000120\n",
            "Batch 1390: batch_loss=0.001702\n",
            "Batch 1400: batch_loss=0.000898\n",
            "Batch 1410: batch_loss=0.002519\n",
            "Batch 1420: batch_loss=0.000263\n",
            "Batch 1430: batch_loss=0.000272\n",
            "Batch 1440: batch_loss=0.000140\n",
            "Batch 1450: batch_loss=0.003315\n",
            "Batch 1460: batch_loss=0.001092\n",
            "Batch 1470: batch_loss=0.000183\n",
            "Batch 1480: batch_loss=0.000964\n",
            "Batch 1490: batch_loss=0.000143\n",
            "Batch 1500: batch_loss=0.000094\n",
            "Batch 1510: batch_loss=0.000250\n",
            "Batch 1520: batch_loss=0.001835\n",
            "Batch 1530: batch_loss=0.000894\n",
            "Batch 1540: batch_loss=0.001868\n",
            "Batch 1550: batch_loss=0.001732\n",
            "Batch 1560: batch_loss=0.000872\n",
            "Batch 1570: batch_loss=0.001030\n",
            "Batch 1580: batch_loss=0.001748\n",
            "Batch 1590: batch_loss=0.001845\n",
            "Batch 1600: batch_loss=0.000117\n",
            "Batch 1610: batch_loss=0.000960\n",
            "Batch 1620: batch_loss=0.002480\n",
            "Batch 1630: batch_loss=0.001173\n",
            "Batch 1640: batch_loss=0.001713\n",
            "Batch 1650: batch_loss=0.001163\n",
            "Batch 1660: batch_loss=0.000047\n",
            "Batch 1670: batch_loss=0.001772\n",
            "Batch 1680: batch_loss=0.001124\n",
            "Batch 1690: batch_loss=0.000937\n",
            "Batch 1700: batch_loss=0.000270\n",
            "Batch 1710: batch_loss=0.002565\n",
            "Batch 1720: batch_loss=0.003310\n",
            "Batch 1730: batch_loss=0.001805\n",
            "Batch 1740: batch_loss=0.002548\n",
            "Batch 1750: batch_loss=0.001994\n",
            "Batch 1760: batch_loss=0.003495\n",
            "Batch 1770: batch_loss=0.000222\n",
            "Batch 1780: batch_loss=0.000315\n",
            "Batch 1790: batch_loss=0.001698\n",
            "Batch 1800: batch_loss=0.000974\n",
            "Batch 1810: batch_loss=0.006496\n",
            "Batch 1820: batch_loss=0.002667\n",
            "Batch 1830: batch_loss=0.001057\n",
            "Batch 1840: batch_loss=0.001736\n",
            "Batch 1850: batch_loss=0.000929\n",
            "Batch 1860: batch_loss=0.001785\n",
            "Batch 1870: batch_loss=0.000977\n",
            "Batch 1880: batch_loss=0.000899\n",
            "Batch 1890: batch_loss=0.002533\n",
            "Batch 1900: batch_loss=0.000980\n",
            "Batch 1910: batch_loss=0.000975\n",
            "Batch 1920: batch_loss=0.002535\n",
            "Batch 1930: batch_loss=0.001921\n",
            "Batch 1940: batch_loss=0.002542\n",
            "Batch 1950: batch_loss=0.000925\n",
            "Batch 1960: batch_loss=0.002705\n",
            "Batch 1970: batch_loss=0.000939\n",
            "Batch 1980: batch_loss=0.002596\n",
            "Batch 1990: batch_loss=0.001826\n",
            "Batch 2000: batch_loss=0.003442\n",
            "Batch 2010: batch_loss=0.000241\n",
            "Batch 2020: batch_loss=0.000869\n",
            "Batch 2030: batch_loss=0.002551\n",
            "Batch 2040: batch_loss=0.000127\n",
            "Batch 2050: batch_loss=0.000856\n",
            "Batch 2060: batch_loss=0.002578\n",
            "Batch 2070: batch_loss=0.001709\n",
            "Batch 2080: batch_loss=0.003412\n",
            "Batch 2090: batch_loss=0.002556\n",
            "Batch 2100: batch_loss=0.000084\n",
            "Batch 2110: batch_loss=0.002741\n",
            "Batch 2120: batch_loss=0.000956\n",
            "Batch 2130: batch_loss=0.003332\n",
            "Batch 2140: batch_loss=0.002497\n",
            "Batch 2150: batch_loss=0.000861\n",
            "Batch 2160: batch_loss=0.000184\n",
            "Batch 2170: batch_loss=0.000124\n",
            "Batch 2180: batch_loss=0.001840\n",
            "Batch 2190: batch_loss=0.001748\n",
            "Batch 2200: batch_loss=0.003425\n",
            "Batch 2210: batch_loss=0.001679\n",
            "Batch 2220: batch_loss=0.000925\n",
            "Batch 2230: batch_loss=0.002596\n",
            "Batch 2240: batch_loss=0.000121\n",
            "Batch 2250: batch_loss=0.000205\n",
            "Batch 2260: batch_loss=0.002582\n",
            "Batch 2270: batch_loss=0.000145\n",
            "Batch 2280: batch_loss=0.000857\n",
            "Batch 2290: batch_loss=0.002578\n",
            "Batch 2300: batch_loss=0.000088\n",
            "Batch 2310: batch_loss=0.001760\n",
            "Batch 2320: batch_loss=0.000966\n",
            "Batch 2330: batch_loss=0.000107\n",
            "Batch 2340: batch_loss=0.000065\n",
            "Batch 2350: batch_loss=0.001729\n",
            "Batch 2360: batch_loss=0.000209\n",
            "Batch 2370: batch_loss=0.001107\n",
            "Batch 2380: batch_loss=0.000945\n",
            "Batch 2390: batch_loss=0.001247\n",
            "Batch 2400: batch_loss=0.001967\n",
            "Batch 2410: batch_loss=0.002574\n",
            "Batch 2420: batch_loss=0.001800\n",
            "Batch 2430: batch_loss=0.001761\n",
            "Batch 2440: batch_loss=0.000931\n",
            "Batch 2450: batch_loss=0.001702\n",
            "Batch 2460: batch_loss=0.001735\n",
            "Batch 2470: batch_loss=0.001710\n",
            "Batch 2480: batch_loss=0.002511\n",
            "Batch 2490: batch_loss=0.000869\n",
            "Batch 2500: batch_loss=0.000998\n",
            "Batch 2510: batch_loss=0.001715\n",
            "Batch 2520: batch_loss=0.003366\n",
            "Batch 2530: batch_loss=0.001742\n",
            "Batch 2540: batch_loss=0.000944\n",
            "Batch 2550: batch_loss=0.000078\n",
            "Batch 2560: batch_loss=0.001844\n",
            "Batch 2570: batch_loss=0.002577\n",
            "Batch 2580: batch_loss=0.000976\n",
            "Batch 2590: batch_loss=0.002848\n",
            "Batch 2600: batch_loss=0.001115\n",
            "Batch 2610: batch_loss=0.003472\n",
            "Batch 2620: batch_loss=0.002052\n",
            "Batch 2630: batch_loss=0.002550\n",
            "Batch 2640: batch_loss=0.001746\n",
            "Batch 2650: batch_loss=0.004331\n",
            "Batch 2660: batch_loss=0.001754\n",
            "Batch 2670: batch_loss=0.001781\n",
            "Batch 2680: batch_loss=0.000931\n",
            "Batch 2690: batch_loss=0.002529\n",
            "Batch 2700: batch_loss=0.000927\n",
            "Batch 2710: batch_loss=0.000903\n",
            "Batch 2720: batch_loss=0.002560\n",
            "Batch 2730: batch_loss=0.001705\n",
            "Batch 2740: batch_loss=0.001675\n",
            "Batch 2750: batch_loss=0.000143\n",
            "Batch 2760: batch_loss=0.000027\n",
            "Batch 2770: batch_loss=0.002616\n",
            "Batch 2780: batch_loss=0.001864\n",
            "Batch 2790: batch_loss=0.001739\n",
            "Batch 2800: batch_loss=0.003439\n",
            "Batch 2810: batch_loss=0.003361\n",
            "Batch 2820: batch_loss=0.000042\n",
            "Batch 2830: batch_loss=0.003464\n",
            "Batch 2840: batch_loss=0.001754\n",
            "Batch 2850: batch_loss=0.007346\n",
            "Batch 2860: batch_loss=0.001067\n",
            "Batch 2870: batch_loss=0.003358\n",
            "Batch 2880: batch_loss=0.000136\n",
            "Batch 2890: batch_loss=0.005187\n",
            "Batch 2900: batch_loss=0.000121\n",
            "Batch 2910: batch_loss=0.000889\n",
            "Batch 2920: batch_loss=0.001718\n",
            "Batch 2930: batch_loss=0.000894\n",
            "Batch 2940: batch_loss=0.000863\n",
            "Batch 2950: batch_loss=0.002502\n",
            "Batch 2960: batch_loss=0.000890\n",
            "Batch 2970: batch_loss=0.001670\n",
            "Batch 2980: batch_loss=0.000259\n",
            "Batch 2990: batch_loss=0.000911\n",
            "Batch 3000: batch_loss=0.001754\n",
            "Batch 3010: batch_loss=0.000080\n",
            "Batch 3020: batch_loss=0.002575\n",
            "Batch 3030: batch_loss=0.001835\n",
            "Batch 3040: batch_loss=0.001665\n",
            "Batch 3050: batch_loss=0.002662\n",
            "Batch 3060: batch_loss=0.001275\n",
            "Batch 3070: batch_loss=0.001072\n",
            "Batch 3080: batch_loss=0.003339\n",
            "Batch 3090: batch_loss=0.001027\n",
            "Batch 3100: batch_loss=0.001420\n",
            "Batch 3110: batch_loss=0.002002\n",
            "Batch 3120: batch_loss=0.000967\n",
            "Batch 3130: batch_loss=0.001097\n",
            "Batch 3140: batch_loss=0.000999\n",
            "Batch 3150: batch_loss=0.001729\n",
            "Batch 3160: batch_loss=0.005113\n",
            "Batch 3170: batch_loss=0.001787\n",
            "Batch 3180: batch_loss=0.001699\n",
            "Batch 3190: batch_loss=0.000932\n",
            "Batch 3200: batch_loss=0.000134\n",
            "Batch 3210: batch_loss=0.000069\n",
            "Batch 3220: batch_loss=0.001746\n",
            "Batch 3230: batch_loss=0.000977\n",
            "Batch 3240: batch_loss=0.000069\n",
            "Batch 3250: batch_loss=0.001124\n",
            "Batch 3260: batch_loss=0.000188\n",
            "Batch 3270: batch_loss=0.000211\n",
            "Batch 3280: batch_loss=0.000133\n",
            "Batch 3290: batch_loss=0.001717\n",
            "Batch 3300: batch_loss=0.000942\n",
            "Batch 3310: batch_loss=0.000988\n",
            "Batch 3320: batch_loss=0.000954\n",
            "Batch 3330: batch_loss=0.000997\n",
            "Batch 3340: batch_loss=0.000036\n",
            "Batch 3350: batch_loss=0.002545\n",
            "Batch 3360: batch_loss=0.000986\n",
            "Batch 3370: batch_loss=0.000934\n",
            "Batch 3380: batch_loss=0.002506\n",
            "Batch 3390: batch_loss=0.000918\n",
            "Batch 3400: batch_loss=0.000123\n",
            "Batch 3410: batch_loss=0.000200\n",
            "Batch 3420: batch_loss=0.001773\n",
            "Batch 3430: batch_loss=0.001710\n",
            "Batch 3440: batch_loss=0.002616\n",
            "Batch 3450: batch_loss=0.000878\n",
            "Batch 3460: batch_loss=0.000196\n",
            "Batch 3470: batch_loss=0.000922\n",
            "Batch 3480: batch_loss=0.001759\n",
            "Batch 3490: batch_loss=0.000951\n",
            "Batch 3500: batch_loss=0.002505\n",
            "Batch 3510: batch_loss=0.000086\n",
            "Batch 3520: batch_loss=0.000929\n",
            "Batch 3530: batch_loss=0.002535\n",
            "Batch 3540: batch_loss=0.001624\n",
            "Batch 3550: batch_loss=0.000053\n",
            "Batch 3560: batch_loss=0.000118\n",
            "Batch 3570: batch_loss=0.000290\n",
            "Batch 3580: batch_loss=0.002572\n",
            "Batch 3590: batch_loss=0.000092\n",
            "Batch 3600: batch_loss=0.001819\n",
            "Batch 3610: batch_loss=0.002593\n",
            "Batch 3620: batch_loss=0.000867\n",
            "Batch 3630: batch_loss=0.000886\n",
            "Batch 3640: batch_loss=0.000980\n",
            "Batch 3650: batch_loss=0.000919\n",
            "Batch 3660: batch_loss=0.000085\n",
            "Batch 3670: batch_loss=0.000971\n",
            "Batch 3680: batch_loss=0.000049\n",
            "Batch 3690: batch_loss=0.000056\n",
            "Batch 3700: batch_loss=0.001681\n",
            "Batch 3710: batch_loss=0.002601\n",
            "Batch 3720: batch_loss=0.005068\n",
            "Epoch 4/10, Train Loss: 0.001493, Val Loss: 0.001685\n",
            "Batch 0: batch_loss=0.001914\n",
            "Batch 10: batch_loss=0.000885\n",
            "Batch 20: batch_loss=0.000157\n",
            "Batch 30: batch_loss=0.000120\n",
            "Batch 40: batch_loss=0.000956\n",
            "Batch 50: batch_loss=0.000299\n",
            "Batch 60: batch_loss=0.002737\n",
            "Batch 70: batch_loss=0.001005\n",
            "Batch 80: batch_loss=0.002549\n",
            "Batch 90: batch_loss=0.000096\n",
            "Batch 100: batch_loss=0.002553\n",
            "Batch 110: batch_loss=0.002544\n",
            "Batch 120: batch_loss=0.000914\n",
            "Batch 130: batch_loss=0.000152\n",
            "Batch 140: batch_loss=0.002555\n",
            "Batch 150: batch_loss=0.001818\n",
            "Batch 160: batch_loss=0.000902\n",
            "Batch 170: batch_loss=0.002616\n",
            "Batch 180: batch_loss=0.001131\n",
            "Batch 190: batch_loss=0.001870\n",
            "Batch 200: batch_loss=0.000979\n",
            "Batch 210: batch_loss=0.006014\n",
            "Batch 220: batch_loss=0.001153\n",
            "Batch 230: batch_loss=0.001686\n",
            "Batch 240: batch_loss=0.002558\n",
            "Batch 250: batch_loss=0.002491\n",
            "Batch 260: batch_loss=0.006681\n",
            "Batch 270: batch_loss=0.000913\n",
            "Batch 280: batch_loss=0.001686\n",
            "Batch 290: batch_loss=0.001711\n",
            "Batch 300: batch_loss=0.004967\n",
            "Batch 310: batch_loss=0.003294\n",
            "Batch 320: batch_loss=0.002551\n",
            "Batch 330: batch_loss=0.001730\n",
            "Batch 340: batch_loss=0.000075\n",
            "Batch 350: batch_loss=0.000948\n",
            "Batch 360: batch_loss=0.000075\n",
            "Batch 370: batch_loss=0.001681\n",
            "Batch 380: batch_loss=0.001816\n",
            "Batch 390: batch_loss=0.000053\n",
            "Batch 400: batch_loss=0.000195\n",
            "Batch 410: batch_loss=0.001701\n",
            "Batch 420: batch_loss=0.000037\n",
            "Batch 430: batch_loss=0.002558\n",
            "Batch 440: batch_loss=0.002642\n",
            "Batch 450: batch_loss=0.000944\n",
            "Batch 460: batch_loss=0.000941\n",
            "Batch 470: batch_loss=0.000083\n",
            "Batch 480: batch_loss=0.000094\n",
            "Batch 490: batch_loss=0.001773\n",
            "Batch 500: batch_loss=0.000869\n",
            "Batch 510: batch_loss=0.000884\n",
            "Batch 520: batch_loss=0.001720\n",
            "Batch 530: batch_loss=0.002592\n",
            "Batch 540: batch_loss=0.001027\n",
            "Batch 550: batch_loss=0.003434\n",
            "Batch 560: batch_loss=0.004191\n",
            "Batch 570: batch_loss=0.002549\n",
            "Batch 580: batch_loss=0.000919\n",
            "Batch 590: batch_loss=0.000868\n",
            "Batch 600: batch_loss=0.004239\n",
            "Batch 610: batch_loss=0.001777\n",
            "Batch 620: batch_loss=0.000081\n",
            "Batch 630: batch_loss=0.000228\n",
            "Batch 640: batch_loss=0.001707\n",
            "Batch 650: batch_loss=0.001867\n",
            "Batch 660: batch_loss=0.002709\n",
            "Batch 670: batch_loss=0.003328\n",
            "Batch 680: batch_loss=0.000082\n",
            "Batch 690: batch_loss=0.000123\n",
            "Batch 700: batch_loss=0.000880\n",
            "Batch 710: batch_loss=0.002399\n",
            "Batch 720: batch_loss=0.000122\n",
            "Batch 730: batch_loss=0.000139\n",
            "Batch 740: batch_loss=0.002558\n",
            "Batch 750: batch_loss=0.000171\n",
            "Batch 760: batch_loss=0.003337\n",
            "Batch 770: batch_loss=0.000914\n",
            "Batch 780: batch_loss=0.000918\n",
            "Batch 790: batch_loss=0.002556\n",
            "Batch 800: batch_loss=0.000030\n",
            "Batch 810: batch_loss=0.004156\n",
            "Batch 820: batch_loss=0.000858\n",
            "Batch 830: batch_loss=0.000081\n",
            "Batch 840: batch_loss=0.000867\n",
            "Batch 850: batch_loss=0.001757\n",
            "Batch 860: batch_loss=0.000060\n",
            "Batch 870: batch_loss=0.000093\n",
            "Batch 880: batch_loss=0.000088\n",
            "Batch 890: batch_loss=0.000060\n",
            "Batch 900: batch_loss=0.001699\n",
            "Batch 910: batch_loss=0.000934\n",
            "Batch 920: batch_loss=0.000877\n",
            "Batch 930: batch_loss=0.003400\n",
            "Batch 940: batch_loss=0.002481\n",
            "Batch 950: batch_loss=0.001706\n",
            "Batch 960: batch_loss=0.000082\n",
            "Batch 970: batch_loss=0.000081\n",
            "Batch 980: batch_loss=0.001741\n",
            "Batch 990: batch_loss=0.001777\n",
            "Batch 1000: batch_loss=0.000155\n",
            "Batch 1010: batch_loss=0.000079\n",
            "Batch 1020: batch_loss=0.003325\n",
            "Batch 1030: batch_loss=0.002619\n",
            "Batch 1040: batch_loss=0.000966\n",
            "Batch 1050: batch_loss=0.002528\n",
            "Batch 1060: batch_loss=0.001665\n",
            "Batch 1070: batch_loss=0.003383\n",
            "Batch 1080: batch_loss=0.004128\n",
            "Batch 1090: batch_loss=0.000908\n",
            "Batch 1100: batch_loss=0.001699\n",
            "Batch 1110: batch_loss=0.000869\n",
            "Batch 1120: batch_loss=0.000063\n",
            "Batch 1130: batch_loss=0.001725\n",
            "Batch 1140: batch_loss=0.005043\n",
            "Batch 1150: batch_loss=0.003391\n",
            "Batch 1160: batch_loss=0.000999\n",
            "Batch 1170: batch_loss=0.001692\n",
            "Batch 1180: batch_loss=0.001867\n",
            "Batch 1190: batch_loss=0.000997\n",
            "Batch 1200: batch_loss=0.003312\n",
            "Batch 1210: batch_loss=0.000298\n",
            "Batch 1220: batch_loss=0.000849\n",
            "Batch 1230: batch_loss=0.000039\n",
            "Batch 1240: batch_loss=0.001743\n",
            "Batch 1250: batch_loss=0.000866\n",
            "Batch 1260: batch_loss=0.002623\n",
            "Batch 1270: batch_loss=0.000934\n",
            "Batch 1280: batch_loss=0.001739\n",
            "Batch 1290: batch_loss=0.003336\n",
            "Batch 1300: batch_loss=0.001768\n",
            "Batch 1310: batch_loss=0.001773\n",
            "Batch 1320: batch_loss=0.000941\n",
            "Batch 1330: batch_loss=0.000050\n",
            "Batch 1340: batch_loss=0.000996\n",
            "Batch 1350: batch_loss=0.001033\n",
            "Batch 1360: batch_loss=0.000993\n",
            "Batch 1370: batch_loss=0.000096\n",
            "Batch 1380: batch_loss=0.000914\n",
            "Batch 1390: batch_loss=0.001772\n",
            "Batch 1400: batch_loss=0.001732\n",
            "Batch 1410: batch_loss=0.000151\n",
            "Batch 1420: batch_loss=0.001737\n",
            "Batch 1430: batch_loss=0.001708\n",
            "Batch 1440: batch_loss=0.000080\n",
            "Batch 1450: batch_loss=0.000109\n",
            "Batch 1460: batch_loss=0.001679\n",
            "Batch 1470: batch_loss=0.004150\n",
            "Batch 1480: batch_loss=0.000290\n",
            "Batch 1490: batch_loss=0.000066\n",
            "Batch 1500: batch_loss=0.001805\n",
            "Batch 1510: batch_loss=0.000866\n",
            "Batch 1520: batch_loss=0.000955\n",
            "Batch 1530: batch_loss=0.000980\n",
            "Batch 1540: batch_loss=0.000904\n",
            "Batch 1550: batch_loss=0.000945\n",
            "Batch 1560: batch_loss=0.000071\n",
            "Batch 1570: batch_loss=0.001726\n",
            "Batch 1580: batch_loss=0.002517\n",
            "Batch 1590: batch_loss=0.001824\n",
            "Batch 1600: batch_loss=0.000032\n",
            "Batch 1610: batch_loss=0.000883\n",
            "Batch 1620: batch_loss=0.000936\n",
            "Batch 1630: batch_loss=0.003426\n",
            "Batch 1640: batch_loss=0.000082\n",
            "Batch 1650: batch_loss=0.000860\n",
            "Batch 1660: batch_loss=0.000041\n",
            "Batch 1670: batch_loss=0.001113\n",
            "Batch 1680: batch_loss=0.001697\n",
            "Batch 1690: batch_loss=0.000063\n",
            "Batch 1700: batch_loss=0.000081\n",
            "Batch 1710: batch_loss=0.000870\n",
            "Batch 1720: batch_loss=0.000876\n",
            "Batch 1730: batch_loss=0.001664\n",
            "Batch 1740: batch_loss=0.000102\n",
            "Batch 1750: batch_loss=0.000928\n",
            "Batch 1760: batch_loss=0.000112\n",
            "Batch 1770: batch_loss=0.001763\n",
            "Batch 1780: batch_loss=0.001718\n",
            "Batch 1790: batch_loss=0.000936\n",
            "Batch 1800: batch_loss=0.000092\n",
            "Batch 1810: batch_loss=0.002508\n",
            "Batch 1820: batch_loss=0.001799\n",
            "Batch 1830: batch_loss=0.002571\n",
            "Batch 1840: batch_loss=0.000150\n",
            "Batch 1850: batch_loss=0.002534\n",
            "Batch 1860: batch_loss=0.000143\n",
            "Batch 1870: batch_loss=0.002821\n",
            "Batch 1880: batch_loss=0.000085\n",
            "Batch 1890: batch_loss=0.001019\n",
            "Batch 1900: batch_loss=0.000937\n",
            "Batch 1910: batch_loss=0.001713\n",
            "Batch 1920: batch_loss=0.005117\n",
            "Batch 1930: batch_loss=0.000137\n",
            "Batch 1940: batch_loss=0.000896\n",
            "Batch 1950: batch_loss=0.000917\n",
            "Batch 1960: batch_loss=0.002650\n",
            "Batch 1970: batch_loss=0.001830\n",
            "Batch 1980: batch_loss=0.002611\n",
            "Batch 1990: batch_loss=0.001039\n",
            "Batch 2000: batch_loss=0.002521\n",
            "Batch 2010: batch_loss=0.003352\n",
            "Batch 2020: batch_loss=0.001682\n",
            "Batch 2030: batch_loss=0.000903\n",
            "Batch 2040: batch_loss=0.000058\n",
            "Batch 2050: batch_loss=0.001699\n",
            "Batch 2060: batch_loss=0.000941\n",
            "Batch 2070: batch_loss=0.002600\n",
            "Batch 2080: batch_loss=0.000147\n",
            "Batch 2090: batch_loss=0.000929\n",
            "Batch 2100: batch_loss=0.000900\n",
            "Batch 2110: batch_loss=0.000084\n",
            "Batch 2120: batch_loss=0.001695\n",
            "Batch 2130: batch_loss=0.002591\n",
            "Batch 2140: batch_loss=0.000084\n",
            "Batch 2150: batch_loss=0.000870\n",
            "Batch 2160: batch_loss=0.005178\n",
            "Batch 2170: batch_loss=0.002639\n",
            "Batch 2180: batch_loss=0.000088\n",
            "Batch 2190: batch_loss=0.000888\n",
            "Batch 2200: batch_loss=0.000949\n",
            "Batch 2210: batch_loss=0.001786\n",
            "Batch 2220: batch_loss=0.004824\n",
            "Batch 2230: batch_loss=0.000850\n",
            "Batch 2240: batch_loss=0.001674\n",
            "Batch 2250: batch_loss=0.000852\n",
            "Batch 2260: batch_loss=0.002502\n",
            "Batch 2270: batch_loss=0.000072\n",
            "Batch 2280: batch_loss=0.000051\n",
            "Batch 2290: batch_loss=0.003453\n",
            "Batch 2300: batch_loss=0.000137\n",
            "Batch 2310: batch_loss=0.003365\n",
            "Batch 2320: batch_loss=0.000982\n",
            "Batch 2330: batch_loss=0.001855\n",
            "Batch 2340: batch_loss=0.000930\n",
            "Batch 2350: batch_loss=0.000927\n",
            "Batch 2360: batch_loss=0.002511\n",
            "Batch 2370: batch_loss=0.000966\n",
            "Batch 2380: batch_loss=0.002596\n",
            "Batch 2390: batch_loss=0.000140\n",
            "Batch 2400: batch_loss=0.002519\n",
            "Batch 2410: batch_loss=0.001699\n",
            "Batch 2420: batch_loss=0.000212\n",
            "Batch 2430: batch_loss=0.002451\n",
            "Batch 2440: batch_loss=0.001723\n",
            "Batch 2450: batch_loss=0.001079\n",
            "Batch 2460: batch_loss=0.000233\n",
            "Batch 2470: batch_loss=0.001001\n",
            "Batch 2480: batch_loss=0.001823\n",
            "Batch 2490: batch_loss=0.000854\n",
            "Batch 2500: batch_loss=0.000848\n",
            "Batch 2510: batch_loss=0.000110\n",
            "Batch 2520: batch_loss=0.000883\n",
            "Batch 2530: batch_loss=0.000081\n",
            "Batch 2540: batch_loss=0.000854\n",
            "Batch 2550: batch_loss=0.000956\n",
            "Batch 2560: batch_loss=0.000081\n",
            "Batch 2570: batch_loss=0.002500\n",
            "Batch 2580: batch_loss=0.001777\n",
            "Batch 2590: batch_loss=0.001697\n",
            "Batch 2600: batch_loss=0.000172\n",
            "Batch 2610: batch_loss=0.001706\n",
            "Batch 2620: batch_loss=0.001755\n",
            "Batch 2630: batch_loss=0.003345\n",
            "Batch 2640: batch_loss=0.000964\n",
            "Batch 2650: batch_loss=0.001815\n",
            "Batch 2660: batch_loss=0.000199\n",
            "Batch 2670: batch_loss=0.000121\n",
            "Batch 2680: batch_loss=0.003350\n",
            "Batch 2690: batch_loss=0.000863\n",
            "Batch 2700: batch_loss=0.001803\n",
            "Batch 2710: batch_loss=0.000958\n",
            "Batch 2720: batch_loss=0.000940\n",
            "Batch 2730: batch_loss=0.001732\n",
            "Batch 2740: batch_loss=0.000872\n",
            "Batch 2750: batch_loss=0.001710\n",
            "Batch 2760: batch_loss=0.002563\n",
            "Batch 2770: batch_loss=0.000873\n",
            "Batch 2780: batch_loss=0.000990\n",
            "Batch 2790: batch_loss=0.000886\n",
            "Batch 2800: batch_loss=0.002641\n",
            "Batch 2810: batch_loss=0.001697\n",
            "Batch 2820: batch_loss=0.000104\n",
            "Batch 2830: batch_loss=0.001658\n",
            "Batch 2840: batch_loss=0.001796\n",
            "Batch 2850: batch_loss=0.001658\n",
            "Batch 2860: batch_loss=0.000950\n",
            "Batch 2870: batch_loss=0.000056\n",
            "Batch 2880: batch_loss=0.000416\n",
            "Batch 2890: batch_loss=0.000930\n",
            "Batch 2900: batch_loss=0.001762\n",
            "Batch 2910: batch_loss=0.000875\n",
            "Batch 2920: batch_loss=0.002596\n",
            "Batch 2930: batch_loss=0.000062\n",
            "Batch 2940: batch_loss=0.002544\n",
            "Batch 2950: batch_loss=0.002617\n",
            "Batch 2960: batch_loss=0.001742\n",
            "Batch 2970: batch_loss=0.000067\n",
            "Batch 2980: batch_loss=0.000096\n",
            "Batch 2990: batch_loss=0.000911\n",
            "Batch 3000: batch_loss=0.001733\n",
            "Batch 3010: batch_loss=0.000097\n",
            "Batch 3020: batch_loss=0.000958\n",
            "Batch 3030: batch_loss=0.002607\n",
            "Batch 3040: batch_loss=0.000065\n",
            "Batch 3050: batch_loss=0.003383\n",
            "Batch 3060: batch_loss=0.001710\n",
            "Batch 3070: batch_loss=0.000901\n",
            "Batch 3080: batch_loss=0.001701\n",
            "Batch 3090: batch_loss=0.001026\n",
            "Batch 3100: batch_loss=0.000993\n",
            "Batch 3110: batch_loss=0.000093\n",
            "Batch 3120: batch_loss=0.000176\n",
            "Batch 3130: batch_loss=0.001854\n",
            "Batch 3140: batch_loss=0.000869\n",
            "Batch 3150: batch_loss=0.001702\n",
            "Batch 3160: batch_loss=0.000886\n",
            "Batch 3170: batch_loss=0.000997\n",
            "Batch 3180: batch_loss=0.004531\n",
            "Batch 3190: batch_loss=0.000922\n",
            "Batch 3200: batch_loss=0.000985\n",
            "Batch 3210: batch_loss=0.003340\n",
            "Batch 3220: batch_loss=0.000071\n",
            "Batch 3230: batch_loss=0.000220\n",
            "Batch 3240: batch_loss=0.000895\n",
            "Batch 3250: batch_loss=0.000856\n",
            "Batch 3260: batch_loss=0.000890\n",
            "Batch 3270: batch_loss=0.001764\n",
            "Batch 3280: batch_loss=0.000956\n",
            "Batch 3290: batch_loss=0.000950\n",
            "Batch 3300: batch_loss=0.000142\n",
            "Batch 3310: batch_loss=0.000079\n",
            "Batch 3320: batch_loss=0.002558\n",
            "Batch 3330: batch_loss=0.000961\n",
            "Batch 3340: batch_loss=0.005832\n",
            "Batch 3350: batch_loss=0.004229\n",
            "Batch 3360: batch_loss=0.000047\n",
            "Batch 3370: batch_loss=0.000944\n",
            "Batch 3380: batch_loss=0.000887\n",
            "Batch 3390: batch_loss=0.001132\n",
            "Batch 3400: batch_loss=0.001691\n",
            "Batch 3410: batch_loss=0.001745\n",
            "Batch 3420: batch_loss=0.000064\n",
            "Batch 3430: batch_loss=0.000901\n",
            "Batch 3440: batch_loss=0.001729\n",
            "Batch 3450: batch_loss=0.000080\n",
            "Batch 3460: batch_loss=0.000935\n",
            "Batch 3470: batch_loss=0.000862\n",
            "Batch 3480: batch_loss=0.000047\n",
            "Batch 3490: batch_loss=0.000856\n",
            "Batch 3500: batch_loss=0.002605\n",
            "Batch 3510: batch_loss=0.002515\n",
            "Batch 3520: batch_loss=0.000203\n",
            "Batch 3530: batch_loss=0.001723\n",
            "Batch 3540: batch_loss=0.000879\n",
            "Batch 3550: batch_loss=0.001697\n",
            "Batch 3560: batch_loss=0.000087\n",
            "Batch 3570: batch_loss=0.004219\n",
            "Batch 3580: batch_loss=0.002498\n",
            "Batch 3590: batch_loss=0.000083\n",
            "Batch 3600: batch_loss=0.000078\n",
            "Batch 3610: batch_loss=0.001821\n",
            "Batch 3620: batch_loss=0.001785\n",
            "Batch 3630: batch_loss=0.002648\n",
            "Batch 3640: batch_loss=0.000227\n",
            "Batch 3650: batch_loss=0.001762\n",
            "Batch 3660: batch_loss=0.000154\n",
            "Batch 3670: batch_loss=0.000177\n",
            "Batch 3680: batch_loss=0.002652\n",
            "Batch 3690: batch_loss=0.001790\n",
            "Batch 3700: batch_loss=0.001143\n",
            "Batch 3710: batch_loss=0.001802\n",
            "Batch 3720: batch_loss=0.002116\n",
            "Epoch 5/10, Train Loss: 0.001450, Val Loss: 0.001826\n",
            "Batch 0: batch_loss=0.001119\n",
            "Batch 10: batch_loss=0.000902\n",
            "Batch 20: batch_loss=0.001065\n",
            "Batch 30: batch_loss=0.000127\n",
            "Batch 40: batch_loss=0.002690\n",
            "Batch 50: batch_loss=0.001693\n",
            "Batch 60: batch_loss=0.004524\n",
            "Batch 70: batch_loss=0.003308\n",
            "Batch 80: batch_loss=0.003422\n",
            "Batch 90: batch_loss=0.005293\n",
            "Batch 100: batch_loss=0.000983\n",
            "Batch 110: batch_loss=0.000869\n",
            "Batch 120: batch_loss=0.001013\n",
            "Batch 130: batch_loss=0.000045\n",
            "Batch 140: batch_loss=0.002491\n",
            "Batch 150: batch_loss=0.002575\n",
            "Batch 160: batch_loss=0.002647\n",
            "Batch 170: batch_loss=0.000078\n",
            "Batch 180: batch_loss=0.000951\n",
            "Batch 190: batch_loss=0.001816\n",
            "Batch 200: batch_loss=0.000865\n",
            "Batch 210: batch_loss=0.002533\n",
            "Batch 220: batch_loss=0.000906\n",
            "Batch 230: batch_loss=0.002636\n",
            "Batch 240: batch_loss=0.004528\n",
            "Batch 250: batch_loss=0.004179\n",
            "Batch 260: batch_loss=0.002596\n",
            "Batch 270: batch_loss=0.000863\n",
            "Batch 280: batch_loss=0.002523\n",
            "Batch 290: batch_loss=0.000155\n",
            "Batch 300: batch_loss=0.000922\n",
            "Batch 310: batch_loss=0.000066\n",
            "Batch 320: batch_loss=0.000930\n",
            "Batch 330: batch_loss=0.000072\n",
            "Batch 340: batch_loss=0.000101\n",
            "Batch 350: batch_loss=0.004275\n",
            "Batch 360: batch_loss=0.000938\n",
            "Batch 370: batch_loss=0.000149\n",
            "Batch 380: batch_loss=0.002568\n",
            "Batch 390: batch_loss=0.000929\n",
            "Batch 400: batch_loss=0.000041\n",
            "Batch 410: batch_loss=0.001687\n",
            "Batch 420: batch_loss=0.001811\n",
            "Batch 430: batch_loss=0.000912\n",
            "Batch 440: batch_loss=0.001710\n",
            "Batch 450: batch_loss=0.000904\n",
            "Batch 460: batch_loss=0.001758\n",
            "Batch 470: batch_loss=0.000053\n",
            "Batch 480: batch_loss=0.002576\n",
            "Batch 490: batch_loss=0.000924\n",
            "Batch 500: batch_loss=0.001764\n",
            "Batch 510: batch_loss=0.000066\n",
            "Batch 520: batch_loss=0.000982\n",
            "Batch 530: batch_loss=0.001016\n",
            "Batch 540: batch_loss=0.000036\n",
            "Batch 550: batch_loss=0.000857\n",
            "Batch 560: batch_loss=0.000999\n",
            "Batch 570: batch_loss=0.000919\n",
            "Batch 580: batch_loss=0.003406\n",
            "Batch 590: batch_loss=0.002636\n",
            "Batch 600: batch_loss=0.002523\n",
            "Batch 610: batch_loss=0.000912\n",
            "Batch 620: batch_loss=0.000950\n",
            "Batch 630: batch_loss=0.001728\n",
            "Batch 640: batch_loss=0.000960\n",
            "Batch 650: batch_loss=0.001715\n",
            "Batch 660: batch_loss=0.003418\n",
            "Batch 670: batch_loss=0.003372\n",
            "Batch 680: batch_loss=0.000090\n",
            "Batch 690: batch_loss=0.000211\n",
            "Batch 700: batch_loss=0.003306\n",
            "Batch 710: batch_loss=0.003377\n",
            "Batch 720: batch_loss=0.000956\n",
            "Batch 730: batch_loss=0.000206\n",
            "Batch 740: batch_loss=0.000868\n",
            "Batch 750: batch_loss=0.001666\n",
            "Batch 760: batch_loss=0.000915\n",
            "Batch 770: batch_loss=0.001682\n",
            "Batch 780: batch_loss=0.001843\n",
            "Batch 790: batch_loss=0.000882\n",
            "Batch 800: batch_loss=0.004976\n",
            "Batch 810: batch_loss=0.001077\n",
            "Batch 820: batch_loss=0.001688\n",
            "Batch 830: batch_loss=0.000949\n",
            "Batch 840: batch_loss=0.000116\n",
            "Batch 850: batch_loss=0.000081\n",
            "Batch 860: batch_loss=0.002594\n",
            "Batch 870: batch_loss=0.006833\n",
            "Batch 880: batch_loss=0.000897\n",
            "Batch 890: batch_loss=0.000862\n",
            "Batch 900: batch_loss=0.003641\n",
            "Batch 910: batch_loss=0.000107\n",
            "Batch 920: batch_loss=0.000201\n",
            "Batch 930: batch_loss=0.000047\n",
            "Batch 940: batch_loss=0.000131\n",
            "Batch 950: batch_loss=0.002601\n",
            "Batch 960: batch_loss=0.000906\n",
            "Batch 970: batch_loss=0.000047\n",
            "Batch 980: batch_loss=0.000934\n",
            "Batch 990: batch_loss=0.001716\n",
            "Batch 1000: batch_loss=0.003330\n",
            "Batch 1010: batch_loss=0.003343\n",
            "Batch 1020: batch_loss=0.000921\n",
            "Batch 1030: batch_loss=0.000879\n",
            "Batch 1040: batch_loss=0.000856\n",
            "Batch 1050: batch_loss=0.000129\n",
            "Batch 1060: batch_loss=0.001041\n",
            "Batch 1070: batch_loss=0.002524\n",
            "Batch 1080: batch_loss=0.001745\n",
            "Batch 1090: batch_loss=0.001038\n",
            "Batch 1100: batch_loss=0.002544\n",
            "Batch 1110: batch_loss=0.000856\n",
            "Batch 1120: batch_loss=0.001761\n",
            "Batch 1130: batch_loss=0.001697\n",
            "Batch 1140: batch_loss=0.000884\n",
            "Batch 1150: batch_loss=0.000084\n",
            "Batch 1160: batch_loss=0.000873\n",
            "Batch 1170: batch_loss=0.000122\n",
            "Batch 1180: batch_loss=0.000149\n",
            "Batch 1190: batch_loss=0.000962\n",
            "Batch 1200: batch_loss=0.000109\n",
            "Batch 1210: batch_loss=0.000089\n",
            "Batch 1220: batch_loss=0.001770\n",
            "Batch 1230: batch_loss=0.002528\n",
            "Batch 1240: batch_loss=0.000999\n",
            "Batch 1250: batch_loss=0.000128\n",
            "Batch 1260: batch_loss=0.000866\n",
            "Batch 1270: batch_loss=0.000900\n",
            "Batch 1280: batch_loss=0.004166\n",
            "Batch 1290: batch_loss=0.001720\n",
            "Batch 1300: batch_loss=0.000065\n",
            "Batch 1310: batch_loss=0.000063\n",
            "Batch 1320: batch_loss=0.002518\n",
            "Batch 1330: batch_loss=0.001754\n",
            "Batch 1340: batch_loss=0.000882\n",
            "Batch 1350: batch_loss=0.001058\n",
            "Batch 1360: batch_loss=0.001008\n",
            "Batch 1370: batch_loss=0.003332\n",
            "Batch 1380: batch_loss=0.000086\n",
            "Batch 1390: batch_loss=0.000855\n",
            "Batch 1400: batch_loss=0.002522\n",
            "Batch 1410: batch_loss=0.000921\n",
            "Batch 1420: batch_loss=0.002544\n",
            "Batch 1430: batch_loss=0.001728\n",
            "Batch 1440: batch_loss=0.000036\n",
            "Batch 1450: batch_loss=0.003523\n",
            "Batch 1460: batch_loss=0.002597\n",
            "Batch 1470: batch_loss=0.000108\n",
            "Batch 1480: batch_loss=0.001782\n",
            "Batch 1490: batch_loss=0.001756\n",
            "Batch 1500: batch_loss=0.001705\n",
            "Batch 1510: batch_loss=0.000065\n",
            "Batch 1520: batch_loss=0.000028\n",
            "Batch 1530: batch_loss=0.000085\n",
            "Batch 1540: batch_loss=0.000159\n",
            "Batch 1550: batch_loss=0.000867\n",
            "Batch 1560: batch_loss=0.001656\n",
            "Batch 1570: batch_loss=0.002532\n",
            "Batch 1580: batch_loss=0.000104\n",
            "Batch 1590: batch_loss=0.000027\n",
            "Batch 1600: batch_loss=0.000143\n",
            "Batch 1610: batch_loss=0.005850\n",
            "Batch 1620: batch_loss=0.000084\n",
            "Batch 1630: batch_loss=0.001734\n",
            "Batch 1640: batch_loss=0.000862\n",
            "Batch 1650: batch_loss=0.000898\n",
            "Batch 1660: batch_loss=0.001698\n",
            "Batch 1670: batch_loss=0.000027\n",
            "Batch 1680: batch_loss=0.000910\n",
            "Batch 1690: batch_loss=0.001723\n",
            "Batch 1700: batch_loss=0.000881\n",
            "Batch 1710: batch_loss=0.000940\n",
            "Batch 1720: batch_loss=0.000934\n",
            "Batch 1730: batch_loss=0.001776\n",
            "Batch 1740: batch_loss=0.008205\n",
            "Batch 1750: batch_loss=0.000990\n",
            "Batch 1760: batch_loss=0.000901\n",
            "Batch 1770: batch_loss=0.002810\n",
            "Batch 1780: batch_loss=0.000876\n",
            "Batch 1790: batch_loss=0.003398\n",
            "Batch 1800: batch_loss=0.000921\n",
            "Batch 1810: batch_loss=0.000041\n",
            "Batch 1820: batch_loss=0.001730\n",
            "Batch 1830: batch_loss=0.000900\n",
            "Batch 1840: batch_loss=0.001911\n",
            "Batch 1850: batch_loss=0.001769\n",
            "Batch 1860: batch_loss=0.001092\n",
            "Batch 1870: batch_loss=0.000077\n",
            "Batch 1880: batch_loss=0.001830\n",
            "Batch 1890: batch_loss=0.000879\n",
            "Batch 1900: batch_loss=0.000196\n",
            "Batch 1910: batch_loss=0.001750\n",
            "Batch 1920: batch_loss=0.002594\n",
            "Batch 1930: batch_loss=0.000899\n",
            "Batch 1940: batch_loss=0.001664\n",
            "Batch 1950: batch_loss=0.000131\n",
            "Batch 1960: batch_loss=0.002605\n",
            "Batch 1970: batch_loss=0.000965\n",
            "Batch 1980: batch_loss=0.001752\n",
            "Batch 1990: batch_loss=0.000900\n",
            "Batch 2000: batch_loss=0.000117\n",
            "Batch 2010: batch_loss=0.002625\n",
            "Batch 2020: batch_loss=0.002482\n",
            "Batch 2030: batch_loss=0.000947\n",
            "Batch 2040: batch_loss=0.000956\n",
            "Batch 2050: batch_loss=0.001710\n",
            "Batch 2060: batch_loss=0.002543\n",
            "Batch 2070: batch_loss=0.000910\n",
            "Batch 2080: batch_loss=0.003312\n",
            "Batch 2090: batch_loss=0.000091\n",
            "Batch 2100: batch_loss=0.003320\n",
            "Batch 2110: batch_loss=0.003472\n",
            "Batch 2120: batch_loss=0.002534\n",
            "Batch 2130: batch_loss=0.001722\n",
            "Batch 2140: batch_loss=0.000955\n",
            "Batch 2150: batch_loss=0.000902\n",
            "Batch 2160: batch_loss=0.001900\n",
            "Batch 2170: batch_loss=0.000111\n",
            "Batch 2180: batch_loss=0.001930\n",
            "Batch 2190: batch_loss=0.000959\n",
            "Batch 2200: batch_loss=0.003428\n",
            "Batch 2210: batch_loss=0.002685\n",
            "Batch 2220: batch_loss=0.001805\n",
            "Batch 2230: batch_loss=0.000915\n",
            "Batch 2240: batch_loss=0.002593\n",
            "Batch 2250: batch_loss=0.000171\n",
            "Batch 2260: batch_loss=0.001888\n",
            "Batch 2270: batch_loss=0.002118\n",
            "Batch 2280: batch_loss=0.001732\n",
            "Batch 2290: batch_loss=0.001751\n",
            "Batch 2300: batch_loss=0.000244\n",
            "Batch 2310: batch_loss=0.000167\n",
            "Batch 2320: batch_loss=0.000933\n",
            "Batch 2330: batch_loss=0.000914\n",
            "Batch 2340: batch_loss=0.002710\n",
            "Batch 2350: batch_loss=0.001765\n",
            "Batch 2360: batch_loss=0.002555\n",
            "Batch 2370: batch_loss=0.000961\n",
            "Batch 2380: batch_loss=0.001747\n",
            "Batch 2390: batch_loss=0.000071\n",
            "Batch 2400: batch_loss=0.000086\n",
            "Batch 2410: batch_loss=0.000879\n",
            "Batch 2420: batch_loss=0.002515\n",
            "Batch 2430: batch_loss=0.000903\n",
            "Batch 2440: batch_loss=0.000061\n",
            "Batch 2450: batch_loss=0.004126\n",
            "Batch 2460: batch_loss=0.000230\n",
            "Batch 2470: batch_loss=0.003341\n",
            "Batch 2480: batch_loss=0.000078\n",
            "Batch 2490: batch_loss=0.000934\n",
            "Batch 2500: batch_loss=0.002592\n",
            "Batch 2510: batch_loss=0.000100\n",
            "Batch 2520: batch_loss=0.001755\n",
            "Batch 2530: batch_loss=0.002547\n",
            "Batch 2540: batch_loss=0.000163\n",
            "Batch 2550: batch_loss=0.000147\n",
            "Batch 2560: batch_loss=0.001719\n",
            "Batch 2570: batch_loss=0.000873\n",
            "Batch 2580: batch_loss=0.000872\n",
            "Batch 2590: batch_loss=0.002540\n",
            "Batch 2600: batch_loss=0.002508\n",
            "Batch 2610: batch_loss=0.002578\n",
            "Batch 2620: batch_loss=0.000112\n",
            "Batch 2630: batch_loss=0.001776\n",
            "Batch 2640: batch_loss=0.001720\n",
            "Batch 2650: batch_loss=0.000963\n",
            "Batch 2660: batch_loss=0.000880\n",
            "Batch 2670: batch_loss=0.002542\n",
            "Batch 2680: batch_loss=0.000073\n",
            "Batch 2690: batch_loss=0.000915\n",
            "Batch 2700: batch_loss=0.001697\n",
            "Batch 2710: batch_loss=0.000936\n",
            "Batch 2720: batch_loss=0.001691\n",
            "Batch 2730: batch_loss=0.002509\n",
            "Batch 2740: batch_loss=0.002538\n",
            "Batch 2750: batch_loss=0.000165\n",
            "Batch 2760: batch_loss=0.001725\n",
            "Batch 2770: batch_loss=0.001011\n",
            "Batch 2780: batch_loss=0.001805\n",
            "Batch 2790: batch_loss=0.000151\n",
            "Batch 2800: batch_loss=0.002562\n",
            "Batch 2810: batch_loss=0.002576\n",
            "Batch 2820: batch_loss=0.001839\n",
            "Batch 2830: batch_loss=0.005048\n",
            "Batch 2840: batch_loss=0.003747\n",
            "Batch 2850: batch_loss=0.000936\n",
            "Batch 2860: batch_loss=0.001750\n",
            "Batch 2870: batch_loss=0.001724\n",
            "Batch 2880: batch_loss=0.000870\n",
            "Batch 2890: batch_loss=0.001047\n",
            "Batch 2900: batch_loss=0.000070\n",
            "Batch 2910: batch_loss=0.001722\n",
            "Batch 2920: batch_loss=0.000864\n",
            "Batch 2930: batch_loss=0.001702\n",
            "Batch 2940: batch_loss=0.001725\n",
            "Batch 2950: batch_loss=0.003481\n",
            "Batch 2960: batch_loss=0.000152\n",
            "Batch 2970: batch_loss=0.001935\n",
            "Batch 2980: batch_loss=0.001766\n",
            "Batch 2990: batch_loss=0.002576\n",
            "Batch 3000: batch_loss=0.000083\n",
            "Batch 3010: batch_loss=0.000095\n",
            "Batch 3020: batch_loss=0.001732\n",
            "Batch 3030: batch_loss=0.001685\n",
            "Batch 3040: batch_loss=0.002636\n",
            "Batch 3050: batch_loss=0.000915\n",
            "Batch 3060: batch_loss=0.001697\n",
            "Batch 3070: batch_loss=0.000943\n",
            "Batch 3080: batch_loss=0.000022\n",
            "Batch 3090: batch_loss=0.001747\n",
            "Batch 3100: batch_loss=0.001659\n",
            "Batch 3110: batch_loss=0.000166\n",
            "Batch 3120: batch_loss=0.001038\n",
            "Batch 3130: batch_loss=0.002547\n",
            "Batch 3140: batch_loss=0.000042\n",
            "Batch 3150: batch_loss=0.004195\n",
            "Batch 3160: batch_loss=0.000989\n",
            "Batch 3170: batch_loss=0.000968\n",
            "Batch 3180: batch_loss=0.002748\n",
            "Batch 3190: batch_loss=0.000088\n",
            "Batch 3200: batch_loss=0.002533\n",
            "Batch 3210: batch_loss=0.000100\n",
            "Batch 3220: batch_loss=0.000900\n",
            "Batch 3230: batch_loss=0.000862\n",
            "Batch 3240: batch_loss=0.001831\n",
            "Batch 3250: batch_loss=0.000104\n",
            "Batch 3260: batch_loss=0.000975\n",
            "Batch 3270: batch_loss=0.004828\n",
            "Batch 3280: batch_loss=0.003328\n",
            "Batch 3290: batch_loss=0.003313\n",
            "Batch 3300: batch_loss=0.000929\n",
            "Batch 3310: batch_loss=0.000911\n",
            "Batch 3320: batch_loss=0.001789\n",
            "Batch 3330: batch_loss=0.000095\n",
            "Batch 3340: batch_loss=0.000958\n",
            "Batch 3350: batch_loss=0.000113\n",
            "Batch 3360: batch_loss=0.000025\n",
            "Batch 3370: batch_loss=0.001747\n",
            "Batch 3380: batch_loss=0.001739\n",
            "Batch 3390: batch_loss=0.003341\n",
            "Batch 3400: batch_loss=0.002601\n",
            "Batch 3410: batch_loss=0.002482\n",
            "Batch 3420: batch_loss=0.001753\n",
            "Batch 3430: batch_loss=0.000052\n",
            "Batch 3440: batch_loss=0.001695\n",
            "Batch 3450: batch_loss=0.000903\n",
            "Batch 3460: batch_loss=0.000857\n",
            "Batch 3470: batch_loss=0.000098\n",
            "Batch 3480: batch_loss=0.001731\n",
            "Batch 3490: batch_loss=0.005885\n",
            "Batch 3500: batch_loss=0.000098\n",
            "Batch 3510: batch_loss=0.003427\n",
            "Batch 3520: batch_loss=0.000888\n",
            "Batch 3530: batch_loss=0.001747\n",
            "Batch 3540: batch_loss=0.001815\n",
            "Batch 3550: batch_loss=0.002002\n",
            "Batch 3560: batch_loss=0.001706\n",
            "Batch 3570: batch_loss=0.000867\n",
            "Batch 3580: batch_loss=0.001727\n",
            "Batch 3590: batch_loss=0.001720\n",
            "Batch 3600: batch_loss=0.002568\n",
            "Batch 3610: batch_loss=0.001702\n",
            "Batch 3620: batch_loss=0.000139\n",
            "Batch 3630: batch_loss=0.000886\n",
            "Batch 3640: batch_loss=0.000113\n",
            "Batch 3650: batch_loss=0.000871\n",
            "Batch 3660: batch_loss=0.000857\n",
            "Batch 3670: batch_loss=0.005853\n",
            "Batch 3680: batch_loss=0.000913\n",
            "Batch 3690: batch_loss=0.001716\n",
            "Batch 3700: batch_loss=0.002549\n",
            "Batch 3710: batch_loss=0.002546\n",
            "Batch 3720: batch_loss=0.000856\n",
            "Epoch 6/10, Train Loss: 0.001442, Val Loss: 0.001495\n",
            "Batch 0: batch_loss=0.004228\n",
            "Batch 10: batch_loss=0.001710\n",
            "Batch 20: batch_loss=0.001735\n",
            "Batch 30: batch_loss=0.002563\n",
            "Batch 40: batch_loss=0.000140\n",
            "Batch 50: batch_loss=0.000890\n",
            "Batch 60: batch_loss=0.001764\n",
            "Batch 70: batch_loss=0.000083\n",
            "Batch 80: batch_loss=0.001691\n",
            "Batch 90: batch_loss=0.003456\n",
            "Batch 100: batch_loss=0.000894\n",
            "Batch 110: batch_loss=0.000887\n",
            "Batch 120: batch_loss=0.000941\n",
            "Batch 130: batch_loss=0.001883\n",
            "Batch 140: batch_loss=0.000897\n",
            "Batch 150: batch_loss=0.001118\n",
            "Batch 160: batch_loss=0.001120\n",
            "Batch 170: batch_loss=0.002487\n",
            "Batch 180: batch_loss=0.003392\n",
            "Batch 190: batch_loss=0.002514\n",
            "Batch 200: batch_loss=0.001725\n",
            "Batch 210: batch_loss=0.001751\n",
            "Batch 220: batch_loss=0.000860\n",
            "Batch 230: batch_loss=0.000909\n",
            "Batch 240: batch_loss=0.000089\n",
            "Batch 250: batch_loss=0.001720\n",
            "Batch 260: batch_loss=0.001719\n",
            "Batch 270: batch_loss=0.000062\n",
            "Batch 280: batch_loss=0.000083\n",
            "Batch 290: batch_loss=0.000954\n",
            "Batch 300: batch_loss=0.002524\n",
            "Batch 310: batch_loss=0.001723\n",
            "Batch 320: batch_loss=0.002510\n",
            "Batch 330: batch_loss=0.002594\n",
            "Batch 340: batch_loss=0.001683\n",
            "Batch 350: batch_loss=0.001686\n",
            "Batch 360: batch_loss=0.001695\n",
            "Batch 370: batch_loss=0.002568\n",
            "Batch 380: batch_loss=0.000940\n",
            "Batch 390: batch_loss=0.001686\n",
            "Batch 400: batch_loss=0.000868\n",
            "Batch 410: batch_loss=0.001745\n",
            "Batch 420: batch_loss=0.003447\n",
            "Batch 430: batch_loss=0.000112\n",
            "Batch 440: batch_loss=0.000090\n",
            "Batch 450: batch_loss=0.000104\n",
            "Batch 460: batch_loss=0.000051\n",
            "Batch 470: batch_loss=0.000071\n",
            "Batch 480: batch_loss=0.003355\n",
            "Batch 490: batch_loss=0.000907\n",
            "Batch 500: batch_loss=0.002579\n",
            "Batch 510: batch_loss=0.000120\n",
            "Batch 520: batch_loss=0.001733\n",
            "Batch 530: batch_loss=0.001750\n",
            "Batch 540: batch_loss=0.000935\n",
            "Batch 550: batch_loss=0.000889\n",
            "Batch 560: batch_loss=0.000869\n",
            "Batch 570: batch_loss=0.001663\n",
            "Batch 580: batch_loss=0.003323\n",
            "Batch 590: batch_loss=0.001811\n",
            "Batch 600: batch_loss=0.000896\n",
            "Batch 610: batch_loss=0.002521\n",
            "Batch 620: batch_loss=0.002586\n",
            "Batch 630: batch_loss=0.000909\n",
            "Batch 640: batch_loss=0.002368\n",
            "Batch 650: batch_loss=0.002613\n",
            "Batch 660: batch_loss=0.001796\n",
            "Batch 670: batch_loss=0.000052\n",
            "Batch 680: batch_loss=0.002606\n",
            "Batch 690: batch_loss=0.003432\n",
            "Batch 700: batch_loss=0.003385\n",
            "Batch 710: batch_loss=0.001131\n",
            "Batch 720: batch_loss=0.005181\n",
            "Batch 730: batch_loss=0.003365\n",
            "Batch 740: batch_loss=0.000058\n",
            "Batch 750: batch_loss=0.003371\n",
            "Batch 760: batch_loss=0.001656\n",
            "Batch 770: batch_loss=0.000931\n",
            "Batch 780: batch_loss=0.000981\n",
            "Batch 790: batch_loss=0.000875\n",
            "Batch 800: batch_loss=0.000121\n",
            "Batch 810: batch_loss=0.002579\n",
            "Batch 820: batch_loss=0.001698\n",
            "Batch 830: batch_loss=0.000945\n",
            "Batch 840: batch_loss=0.001783\n",
            "Batch 850: batch_loss=0.000053\n",
            "Batch 860: batch_loss=0.001678\n",
            "Batch 870: batch_loss=0.000942\n",
            "Batch 880: batch_loss=0.000140\n",
            "Batch 890: batch_loss=0.001715\n",
            "Batch 900: batch_loss=0.000085\n",
            "Batch 910: batch_loss=0.000895\n",
            "Batch 920: batch_loss=0.001007\n",
            "Batch 930: batch_loss=0.000864\n",
            "Batch 940: batch_loss=0.000047\n",
            "Batch 950: batch_loss=0.001745\n",
            "Batch 960: batch_loss=0.001693\n",
            "Batch 970: batch_loss=0.000932\n",
            "Batch 980: batch_loss=0.003447\n",
            "Batch 990: batch_loss=0.004216\n",
            "Batch 1000: batch_loss=0.002486\n",
            "Batch 1010: batch_loss=0.000946\n",
            "Batch 1020: batch_loss=0.001680\n",
            "Batch 1030: batch_loss=0.003367\n",
            "Batch 1040: batch_loss=0.000920\n",
            "Batch 1050: batch_loss=0.000104\n",
            "Batch 1060: batch_loss=0.000869\n",
            "Batch 1070: batch_loss=0.000977\n",
            "Batch 1080: batch_loss=0.000046\n",
            "Batch 1090: batch_loss=0.000949\n",
            "Batch 1100: batch_loss=0.001777\n",
            "Batch 1110: batch_loss=0.000078\n",
            "Batch 1120: batch_loss=0.000179\n",
            "Batch 1130: batch_loss=0.000080\n",
            "Batch 1140: batch_loss=0.000908\n",
            "Batch 1150: batch_loss=0.001701\n",
            "Batch 1160: batch_loss=0.000899\n",
            "Batch 1170: batch_loss=0.000054\n",
            "Batch 1180: batch_loss=0.003381\n",
            "Batch 1190: batch_loss=0.000107\n",
            "Batch 1200: batch_loss=0.000067\n",
            "Batch 1210: batch_loss=0.000091\n",
            "Batch 1220: batch_loss=0.000157\n",
            "Batch 1230: batch_loss=0.001706\n",
            "Batch 1240: batch_loss=0.005101\n",
            "Batch 1250: batch_loss=0.001768\n",
            "Batch 1260: batch_loss=0.000086\n",
            "Batch 1270: batch_loss=0.000847\n",
            "Batch 1280: batch_loss=0.001687\n",
            "Batch 1290: batch_loss=0.000928\n",
            "Batch 1300: batch_loss=0.001762\n",
            "Batch 1310: batch_loss=0.000073\n",
            "Batch 1320: batch_loss=0.000107\n",
            "Batch 1330: batch_loss=0.001716\n",
            "Batch 1340: batch_loss=0.000090\n",
            "Batch 1350: batch_loss=0.002489\n",
            "Batch 1360: batch_loss=0.000053\n",
            "Batch 1370: batch_loss=0.000858\n",
            "Batch 1380: batch_loss=0.000097\n",
            "Batch 1390: batch_loss=0.002487\n",
            "Batch 1400: batch_loss=0.004121\n",
            "Batch 1410: batch_loss=0.002502\n",
            "Batch 1420: batch_loss=0.000901\n",
            "Batch 1430: batch_loss=0.003296\n",
            "Batch 1440: batch_loss=0.000042\n",
            "Batch 1450: batch_loss=0.002538\n",
            "Batch 1460: batch_loss=0.002551\n",
            "Batch 1470: batch_loss=0.000115\n",
            "Batch 1480: batch_loss=0.000051\n",
            "Batch 1490: batch_loss=0.001690\n",
            "Batch 1500: batch_loss=0.000957\n",
            "Batch 1510: batch_loss=0.001737\n",
            "Batch 1520: batch_loss=0.001959\n",
            "Batch 1530: batch_loss=0.003319\n",
            "Batch 1540: batch_loss=0.003354\n",
            "Batch 1550: batch_loss=0.000104\n",
            "Batch 1560: batch_loss=0.000049\n",
            "Batch 1570: batch_loss=0.002506\n",
            "Batch 1580: batch_loss=0.003303\n",
            "Batch 1590: batch_loss=0.000107\n",
            "Batch 1600: batch_loss=0.000134\n",
            "Batch 1610: batch_loss=0.000885\n",
            "Batch 1620: batch_loss=0.000179\n",
            "Batch 1630: batch_loss=0.000893\n",
            "Batch 1640: batch_loss=0.000871\n",
            "Batch 1650: batch_loss=0.000942\n",
            "Batch 1660: batch_loss=0.000038\n",
            "Batch 1670: batch_loss=0.000907\n",
            "Batch 1680: batch_loss=0.000867\n",
            "Batch 1690: batch_loss=0.000036\n",
            "Batch 1700: batch_loss=0.001736\n",
            "Batch 1710: batch_loss=0.001683\n",
            "Batch 1720: batch_loss=0.000914\n",
            "Batch 1730: batch_loss=0.000872\n",
            "Batch 1740: batch_loss=0.001729\n",
            "Batch 1750: batch_loss=0.001738\n",
            "Batch 1760: batch_loss=0.001150\n",
            "Batch 1770: batch_loss=0.002570\n",
            "Batch 1780: batch_loss=0.000043\n",
            "Batch 1790: batch_loss=0.001679\n",
            "Batch 1800: batch_loss=0.000867\n",
            "Batch 1810: batch_loss=0.000060\n",
            "Batch 1820: batch_loss=0.000092\n",
            "Batch 1830: batch_loss=0.002636\n",
            "Batch 1840: batch_loss=0.004215\n",
            "Batch 1850: batch_loss=0.000977\n",
            "Batch 1860: batch_loss=0.000916\n",
            "Batch 1870: batch_loss=0.000972\n",
            "Batch 1880: batch_loss=0.000889\n",
            "Batch 1890: batch_loss=0.002500\n",
            "Batch 1900: batch_loss=0.000995\n",
            "Batch 1910: batch_loss=0.002510\n",
            "Batch 1920: batch_loss=0.000869\n",
            "Batch 1930: batch_loss=0.000968\n",
            "Batch 1940: batch_loss=0.001294\n",
            "Batch 1950: batch_loss=0.000956\n",
            "Batch 1960: batch_loss=0.000114\n",
            "Batch 1970: batch_loss=0.000073\n",
            "Batch 1980: batch_loss=0.001709\n",
            "Batch 1990: batch_loss=0.002525\n",
            "Batch 2000: batch_loss=0.001697\n",
            "Batch 2010: batch_loss=0.002565\n",
            "Batch 2020: batch_loss=0.000933\n",
            "Batch 2030: batch_loss=0.000044\n",
            "Batch 2040: batch_loss=0.000860\n",
            "Batch 2050: batch_loss=0.000856\n",
            "Batch 2060: batch_loss=0.002683\n",
            "Batch 2070: batch_loss=0.003310\n",
            "Batch 2080: batch_loss=0.000128\n",
            "Batch 2090: batch_loss=0.002503\n",
            "Batch 2100: batch_loss=0.000207\n",
            "Batch 2110: batch_loss=0.003302\n",
            "Batch 2120: batch_loss=0.004142\n",
            "Batch 2130: batch_loss=0.000997\n",
            "Batch 2140: batch_loss=0.003359\n",
            "Batch 2150: batch_loss=0.001699\n",
            "Batch 2160: batch_loss=0.000029\n",
            "Batch 2170: batch_loss=0.000113\n",
            "Batch 2180: batch_loss=0.001697\n",
            "Batch 2190: batch_loss=0.000882\n",
            "Batch 2200: batch_loss=0.002542\n",
            "Batch 2210: batch_loss=0.002018\n",
            "Batch 2220: batch_loss=0.001833\n",
            "Batch 2230: batch_loss=0.000873\n",
            "Batch 2240: batch_loss=0.003356\n",
            "Batch 2250: batch_loss=0.001722\n",
            "Batch 2260: batch_loss=0.000969\n",
            "Batch 2270: batch_loss=0.000960\n",
            "Batch 2280: batch_loss=0.000036\n",
            "Batch 2290: batch_loss=0.000051\n",
            "Batch 2300: batch_loss=0.000073\n",
            "Batch 2310: batch_loss=0.000063\n",
            "Batch 2320: batch_loss=0.000889\n",
            "Batch 2330: batch_loss=0.000884\n",
            "Batch 2340: batch_loss=0.000131\n",
            "Batch 2350: batch_loss=0.000094\n",
            "Batch 2360: batch_loss=0.002504\n",
            "Batch 2370: batch_loss=0.000845\n",
            "Batch 2380: batch_loss=0.002700\n",
            "Batch 2390: batch_loss=0.000990\n",
            "Batch 2400: batch_loss=0.002576\n",
            "Batch 2410: batch_loss=0.002581\n",
            "Batch 2420: batch_loss=0.000062\n",
            "Batch 2430: batch_loss=0.004862\n",
            "Batch 2440: batch_loss=0.003358\n",
            "Batch 2450: batch_loss=0.002622\n",
            "Batch 2460: batch_loss=0.000895\n",
            "Batch 2470: batch_loss=0.000895\n",
            "Batch 2480: batch_loss=0.000064\n",
            "Batch 2490: batch_loss=0.000886\n",
            "Batch 2500: batch_loss=0.000124\n",
            "Batch 2510: batch_loss=0.000846\n",
            "Batch 2520: batch_loss=0.003308\n",
            "Batch 2530: batch_loss=0.002542\n",
            "Batch 2540: batch_loss=0.000857\n",
            "Batch 2550: batch_loss=0.002524\n",
            "Batch 2560: batch_loss=0.000887\n",
            "Batch 2570: batch_loss=0.000867\n",
            "Batch 2580: batch_loss=0.000114\n",
            "Batch 2590: batch_loss=0.000931\n",
            "Batch 2600: batch_loss=0.000920\n",
            "Batch 2610: batch_loss=0.000877\n",
            "Batch 2620: batch_loss=0.001861\n",
            "Batch 2630: batch_loss=0.001703\n",
            "Batch 2640: batch_loss=0.000881\n",
            "Batch 2650: batch_loss=0.003321\n",
            "Batch 2660: batch_loss=0.001708\n",
            "Batch 2670: batch_loss=0.000037\n",
            "Batch 2680: batch_loss=0.000079\n",
            "Batch 2690: batch_loss=0.000884\n",
            "Batch 2700: batch_loss=0.001671\n",
            "Batch 2710: batch_loss=0.000049\n",
            "Batch 2720: batch_loss=0.001869\n",
            "Batch 2730: batch_loss=0.003411\n",
            "Batch 2740: batch_loss=0.000896\n",
            "Batch 2750: batch_loss=0.002604\n",
            "Batch 2760: batch_loss=0.001694\n",
            "Batch 2770: batch_loss=0.000122\n",
            "Batch 2780: batch_loss=0.001791\n",
            "Batch 2790: batch_loss=0.000103\n",
            "Batch 2800: batch_loss=0.000109\n",
            "Batch 2810: batch_loss=0.000866\n",
            "Batch 2820: batch_loss=0.000920\n",
            "Batch 2830: batch_loss=0.000929\n",
            "Batch 2840: batch_loss=0.001800\n",
            "Batch 2850: batch_loss=0.000911\n",
            "Batch 2860: batch_loss=0.000879\n",
            "Batch 2870: batch_loss=0.000901\n",
            "Batch 2880: batch_loss=0.000945\n",
            "Batch 2890: batch_loss=0.000074\n",
            "Batch 2900: batch_loss=0.001101\n",
            "Batch 2910: batch_loss=0.000855\n",
            "Batch 2920: batch_loss=0.000252\n",
            "Batch 2930: batch_loss=0.006727\n",
            "Batch 2940: batch_loss=0.001790\n",
            "Batch 2950: batch_loss=0.000089\n",
            "Batch 2960: batch_loss=0.000206\n",
            "Batch 2970: batch_loss=0.000103\n",
            "Batch 2980: batch_loss=0.000952\n",
            "Batch 2990: batch_loss=0.002511\n",
            "Batch 3000: batch_loss=0.000133\n",
            "Batch 3010: batch_loss=0.001712\n",
            "Batch 3020: batch_loss=0.000080\n",
            "Batch 3030: batch_loss=0.004840\n",
            "Batch 3040: batch_loss=0.000116\n",
            "Batch 3050: batch_loss=0.003574\n",
            "Batch 3060: batch_loss=0.001684\n",
            "Batch 3070: batch_loss=0.000072\n",
            "Batch 3080: batch_loss=0.000073\n",
            "Batch 3090: batch_loss=0.000208\n",
            "Batch 3100: batch_loss=0.001738\n",
            "Batch 3110: batch_loss=0.002531\n",
            "Batch 3120: batch_loss=0.001737\n",
            "Batch 3130: batch_loss=0.000888\n",
            "Batch 3140: batch_loss=0.000075\n",
            "Batch 3150: batch_loss=0.001712\n",
            "Batch 3160: batch_loss=0.000872\n",
            "Batch 3170: batch_loss=0.000086\n",
            "Batch 3180: batch_loss=0.000893\n",
            "Batch 3190: batch_loss=0.000102\n",
            "Batch 3200: batch_loss=0.000995\n",
            "Batch 3210: batch_loss=0.001685\n",
            "Batch 3220: batch_loss=0.003400\n",
            "Batch 3230: batch_loss=0.000871\n",
            "Batch 3240: batch_loss=0.000869\n",
            "Batch 3250: batch_loss=0.000970\n",
            "Batch 3260: batch_loss=0.000924\n",
            "Batch 3270: batch_loss=0.000899\n",
            "Batch 3280: batch_loss=0.002514\n",
            "Batch 3290: batch_loss=0.002545\n",
            "Batch 3300: batch_loss=0.000938\n",
            "Batch 3310: batch_loss=0.001779\n",
            "Batch 3320: batch_loss=0.000845\n",
            "Batch 3330: batch_loss=0.000910\n",
            "Batch 3340: batch_loss=0.001691\n",
            "Batch 3350: batch_loss=0.002508\n",
            "Batch 3360: batch_loss=0.001753\n",
            "Batch 3370: batch_loss=0.000059\n",
            "Batch 3380: batch_loss=0.000068\n",
            "Batch 3390: batch_loss=0.001778\n",
            "Batch 3400: batch_loss=0.000866\n",
            "Batch 3410: batch_loss=0.000876\n",
            "Batch 3420: batch_loss=0.000864\n",
            "Batch 3430: batch_loss=0.001742\n",
            "Batch 3440: batch_loss=0.003377\n",
            "Batch 3450: batch_loss=0.000921\n",
            "Batch 3460: batch_loss=0.000066\n",
            "Batch 3470: batch_loss=0.000077\n",
            "Batch 3480: batch_loss=0.001010\n",
            "Batch 3490: batch_loss=0.000866\n",
            "Batch 3500: batch_loss=0.001745\n",
            "Batch 3510: batch_loss=0.003443\n",
            "Batch 3520: batch_loss=0.002596\n",
            "Batch 3530: batch_loss=0.001710\n",
            "Batch 3540: batch_loss=0.000060\n",
            "Batch 3550: batch_loss=0.000143\n",
            "Batch 3560: batch_loss=0.001747\n",
            "Batch 3570: batch_loss=0.000040\n",
            "Batch 3580: batch_loss=0.000150\n",
            "Batch 3590: batch_loss=0.000051\n",
            "Batch 3600: batch_loss=0.001796\n",
            "Batch 3610: batch_loss=0.000117\n",
            "Batch 3620: batch_loss=0.000184\n",
            "Batch 3630: batch_loss=0.001701\n",
            "Batch 3640: batch_loss=0.002504\n",
            "Batch 3650: batch_loss=0.002544\n",
            "Batch 3660: batch_loss=0.000111\n",
            "Batch 3670: batch_loss=0.000861\n",
            "Batch 3680: batch_loss=0.001745\n",
            "Batch 3690: batch_loss=0.002511\n",
            "Batch 3700: batch_loss=0.000878\n",
            "Batch 3710: batch_loss=0.004165\n",
            "Batch 3720: batch_loss=0.001697\n",
            "Epoch 7/10, Train Loss: 0.001425, Val Loss: 0.001499\n",
            "Batch 0: batch_loss=0.000088\n",
            "Batch 10: batch_loss=0.000937\n",
            "Batch 20: batch_loss=0.000918\n",
            "Batch 30: batch_loss=0.001815\n",
            "Batch 40: batch_loss=0.000128\n",
            "Batch 50: batch_loss=0.001038\n",
            "Batch 60: batch_loss=0.001023\n",
            "Batch 70: batch_loss=0.000107\n",
            "Batch 80: batch_loss=0.001749\n",
            "Batch 90: batch_loss=0.001902\n",
            "Batch 100: batch_loss=0.003389\n",
            "Batch 110: batch_loss=0.000997\n",
            "Batch 120: batch_loss=0.001695\n",
            "Batch 130: batch_loss=0.000865\n",
            "Batch 140: batch_loss=0.001755\n",
            "Batch 150: batch_loss=0.000922\n",
            "Batch 160: batch_loss=0.001697\n",
            "Batch 170: batch_loss=0.000895\n",
            "Batch 180: batch_loss=0.002696\n",
            "Batch 190: batch_loss=0.000899\n",
            "Batch 200: batch_loss=0.000968\n",
            "Batch 210: batch_loss=0.000863\n",
            "Batch 220: batch_loss=0.002571\n",
            "Batch 230: batch_loss=0.002626\n",
            "Batch 240: batch_loss=0.000089\n",
            "Batch 250: batch_loss=0.003335\n",
            "Batch 260: batch_loss=0.001694\n",
            "Batch 270: batch_loss=0.002537\n",
            "Batch 280: batch_loss=0.000060\n",
            "Batch 290: batch_loss=0.001704\n",
            "Batch 300: batch_loss=0.000057\n",
            "Batch 310: batch_loss=0.001758\n",
            "Batch 320: batch_loss=0.000062\n",
            "Batch 330: batch_loss=0.001666\n",
            "Batch 340: batch_loss=0.001715\n",
            "Batch 350: batch_loss=0.000085\n",
            "Batch 360: batch_loss=0.000238\n",
            "Batch 370: batch_loss=0.000896\n",
            "Batch 380: batch_loss=0.000037\n",
            "Batch 390: batch_loss=0.002628\n",
            "Batch 400: batch_loss=0.000109\n",
            "Batch 410: batch_loss=0.002572\n",
            "Batch 420: batch_loss=0.004470\n",
            "Batch 430: batch_loss=0.000911\n",
            "Batch 440: batch_loss=0.000868\n",
            "Batch 450: batch_loss=0.000898\n",
            "Batch 460: batch_loss=0.000130\n",
            "Batch 470: batch_loss=0.000869\n",
            "Batch 480: batch_loss=0.000967\n",
            "Batch 490: batch_loss=0.001720\n",
            "Batch 500: batch_loss=0.001000\n",
            "Batch 510: batch_loss=0.001722\n",
            "Batch 520: batch_loss=0.000872\n",
            "Batch 530: batch_loss=0.000869\n",
            "Batch 540: batch_loss=0.000875\n",
            "Batch 550: batch_loss=0.001701\n",
            "Batch 560: batch_loss=0.000873\n",
            "Batch 570: batch_loss=0.000906\n",
            "Batch 580: batch_loss=0.000900\n",
            "Batch 590: batch_loss=0.002600\n",
            "Batch 600: batch_loss=0.000944\n",
            "Batch 610: batch_loss=0.000892\n",
            "Batch 620: batch_loss=0.000140\n",
            "Batch 630: batch_loss=0.000044\n",
            "Batch 640: batch_loss=0.000103\n",
            "Batch 650: batch_loss=0.001761\n",
            "Batch 660: batch_loss=0.001768\n",
            "Batch 670: batch_loss=0.000087\n",
            "Batch 680: batch_loss=0.003421\n",
            "Batch 690: batch_loss=0.000923\n",
            "Batch 700: batch_loss=0.002514\n",
            "Batch 710: batch_loss=0.002488\n",
            "Batch 720: batch_loss=0.000059\n",
            "Batch 730: batch_loss=0.000107\n",
            "Batch 740: batch_loss=0.001694\n",
            "Batch 750: batch_loss=0.001773\n",
            "Batch 760: batch_loss=0.000070\n",
            "Batch 770: batch_loss=0.000086\n",
            "Batch 780: batch_loss=0.002521\n",
            "Batch 790: batch_loss=0.002570\n",
            "Batch 800: batch_loss=0.000945\n",
            "Batch 810: batch_loss=0.000145\n",
            "Batch 820: batch_loss=0.000893\n",
            "Batch 830: batch_loss=0.004150\n",
            "Batch 840: batch_loss=0.000118\n",
            "Batch 850: batch_loss=0.000063\n",
            "Batch 860: batch_loss=0.000131\n",
            "Batch 870: batch_loss=0.000081\n",
            "Batch 880: batch_loss=0.000058\n",
            "Batch 890: batch_loss=0.000915\n",
            "Batch 900: batch_loss=0.001752\n",
            "Batch 910: batch_loss=0.000920\n",
            "Batch 920: batch_loss=0.002482\n",
            "Batch 930: batch_loss=0.000856\n",
            "Batch 940: batch_loss=0.000056\n",
            "Batch 950: batch_loss=0.004991\n",
            "Batch 960: batch_loss=0.000049\n",
            "Batch 970: batch_loss=0.000923\n",
            "Batch 980: batch_loss=0.000977\n",
            "Batch 990: batch_loss=0.000176\n",
            "Batch 1000: batch_loss=0.000925\n",
            "Batch 1010: batch_loss=0.000846\n",
            "Batch 1020: batch_loss=0.000950\n",
            "Batch 1030: batch_loss=0.001772\n",
            "Batch 1040: batch_loss=0.001726\n",
            "Batch 1050: batch_loss=0.001754\n",
            "Batch 1060: batch_loss=0.001736\n",
            "Batch 1070: batch_loss=0.002520\n",
            "Batch 1080: batch_loss=0.002567\n",
            "Batch 1090: batch_loss=0.001782\n",
            "Batch 1100: batch_loss=0.000850\n",
            "Batch 1110: batch_loss=0.002548\n",
            "Batch 1120: batch_loss=0.002586\n",
            "Batch 1130: batch_loss=0.002612\n",
            "Batch 1140: batch_loss=0.000056\n",
            "Batch 1150: batch_loss=0.000873\n",
            "Batch 1160: batch_loss=0.005292\n",
            "Batch 1170: batch_loss=0.002491\n",
            "Batch 1180: batch_loss=0.000908\n",
            "Batch 1190: batch_loss=0.000044\n",
            "Batch 1200: batch_loss=0.000090\n",
            "Batch 1210: batch_loss=0.000105\n",
            "Batch 1220: batch_loss=0.000058\n",
            "Batch 1230: batch_loss=0.000876\n",
            "Batch 1240: batch_loss=0.000920\n",
            "Batch 1250: batch_loss=0.000896\n",
            "Batch 1260: batch_loss=0.001711\n",
            "Batch 1270: batch_loss=0.000114\n",
            "Batch 1280: batch_loss=0.002501\n",
            "Batch 1290: batch_loss=0.005983\n",
            "Batch 1300: batch_loss=0.000961\n",
            "Batch 1310: batch_loss=0.001011\n",
            "Batch 1320: batch_loss=0.002726\n",
            "Batch 1330: batch_loss=0.000938\n",
            "Batch 1340: batch_loss=0.000858\n",
            "Batch 1350: batch_loss=0.001715\n",
            "Batch 1360: batch_loss=0.000933\n",
            "Batch 1370: batch_loss=0.001733\n",
            "Batch 1380: batch_loss=0.000896\n",
            "Batch 1390: batch_loss=0.000866\n",
            "Batch 1400: batch_loss=0.002510\n",
            "Batch 1410: batch_loss=0.001014\n",
            "Batch 1420: batch_loss=0.002554\n",
            "Batch 1430: batch_loss=0.000952\n",
            "Batch 1440: batch_loss=0.004283\n",
            "Batch 1450: batch_loss=0.004888\n",
            "Batch 1460: batch_loss=0.000232\n",
            "Batch 1470: batch_loss=0.000986\n",
            "Batch 1480: batch_loss=0.004147\n",
            "Batch 1490: batch_loss=0.000925\n",
            "Batch 1500: batch_loss=0.001007\n",
            "Batch 1510: batch_loss=0.001757\n",
            "Batch 1520: batch_loss=0.000106\n",
            "Batch 1530: batch_loss=0.001006\n",
            "Batch 1540: batch_loss=0.001785\n",
            "Batch 1550: batch_loss=0.000062\n",
            "Batch 1560: batch_loss=0.000044\n",
            "Batch 1570: batch_loss=0.000877\n",
            "Batch 1580: batch_loss=0.010984\n",
            "Batch 1590: batch_loss=0.004117\n",
            "Batch 1600: batch_loss=0.000934\n",
            "Batch 1610: batch_loss=0.002485\n",
            "Batch 1620: batch_loss=0.000076\n",
            "Batch 1630: batch_loss=0.000082\n",
            "Batch 1640: batch_loss=0.001727\n",
            "Batch 1650: batch_loss=0.000849\n",
            "Batch 1660: batch_loss=0.002584\n",
            "Batch 1670: batch_loss=0.003349\n",
            "Batch 1680: batch_loss=0.000093\n",
            "Batch 1690: batch_loss=0.002486\n",
            "Batch 1700: batch_loss=0.000934\n",
            "Batch 1710: batch_loss=0.002779\n",
            "Batch 1720: batch_loss=0.002532\n",
            "Batch 1730: batch_loss=0.000982\n",
            "Batch 1740: batch_loss=0.002612\n",
            "Batch 1750: batch_loss=0.001014\n",
            "Batch 1760: batch_loss=0.001013\n",
            "Batch 1770: batch_loss=0.002512\n",
            "Batch 1780: batch_loss=0.000129\n",
            "Batch 1790: batch_loss=0.000981\n",
            "Batch 1800: batch_loss=0.001725\n",
            "Batch 1810: batch_loss=0.000066\n",
            "Batch 1820: batch_loss=0.000997\n",
            "Batch 1830: batch_loss=0.000865\n",
            "Batch 1840: batch_loss=0.000110\n",
            "Batch 1850: batch_loss=0.004548\n",
            "Batch 1860: batch_loss=0.001719\n",
            "Batch 1870: batch_loss=0.000040\n",
            "Batch 1880: batch_loss=0.010016\n",
            "Batch 1890: batch_loss=0.000854\n",
            "Batch 1900: batch_loss=0.001717\n",
            "Batch 1910: batch_loss=0.000861\n",
            "Batch 1920: batch_loss=0.008398\n",
            "Batch 1930: batch_loss=0.000880\n",
            "Batch 1940: batch_loss=0.001742\n",
            "Batch 1950: batch_loss=0.001685\n",
            "Batch 1960: batch_loss=0.001749\n",
            "Batch 1970: batch_loss=0.000988\n",
            "Batch 1980: batch_loss=0.000995\n",
            "Batch 1990: batch_loss=0.001732\n",
            "Batch 2000: batch_loss=0.002494\n",
            "Batch 2010: batch_loss=0.010935\n",
            "Batch 2020: batch_loss=0.000931\n",
            "Batch 2030: batch_loss=0.003295\n",
            "Batch 2040: batch_loss=0.000887\n",
            "Batch 2050: batch_loss=0.000099\n",
            "Batch 2060: batch_loss=0.002536\n",
            "Batch 2070: batch_loss=0.000869\n",
            "Batch 2080: batch_loss=0.000088\n",
            "Batch 2090: batch_loss=0.004663\n",
            "Batch 2100: batch_loss=0.000911\n",
            "Batch 2110: batch_loss=0.003324\n",
            "Batch 2120: batch_loss=0.004135\n",
            "Batch 2130: batch_loss=0.000912\n",
            "Batch 2140: batch_loss=0.001735\n",
            "Batch 2150: batch_loss=0.000064\n",
            "Batch 2160: batch_loss=0.000062\n",
            "Batch 2170: batch_loss=0.000928\n",
            "Batch 2180: batch_loss=0.000950\n",
            "Batch 2190: batch_loss=0.001768\n",
            "Batch 2200: batch_loss=0.001693\n",
            "Batch 2210: batch_loss=0.006467\n",
            "Batch 2220: batch_loss=0.000084\n",
            "Batch 2230: batch_loss=0.002505\n",
            "Batch 2240: batch_loss=0.004135\n",
            "Batch 2250: batch_loss=0.000051\n",
            "Batch 2260: batch_loss=0.000042\n",
            "Batch 2270: batch_loss=0.001754\n",
            "Batch 2280: batch_loss=0.000889\n",
            "Batch 2290: batch_loss=0.000887\n",
            "Batch 2300: batch_loss=0.000889\n",
            "Batch 2310: batch_loss=0.000103\n",
            "Batch 2320: batch_loss=0.000892\n",
            "Batch 2330: batch_loss=0.001777\n",
            "Batch 2340: batch_loss=0.001028\n",
            "Batch 2350: batch_loss=0.003358\n",
            "Batch 2360: batch_loss=0.002631\n",
            "Batch 2370: batch_loss=0.000047\n",
            "Batch 2380: batch_loss=0.000899\n",
            "Batch 2390: batch_loss=0.000847\n",
            "Batch 2400: batch_loss=0.000864\n",
            "Batch 2410: batch_loss=0.000898\n",
            "Batch 2420: batch_loss=0.000888\n",
            "Batch 2430: batch_loss=0.000895\n",
            "Batch 2440: batch_loss=0.000868\n",
            "Batch 2450: batch_loss=0.000871\n",
            "Batch 2460: batch_loss=0.002592\n",
            "Batch 2470: batch_loss=0.000920\n",
            "Batch 2480: batch_loss=0.000069\n",
            "Batch 2490: batch_loss=0.000862\n",
            "Batch 2500: batch_loss=0.000954\n",
            "Batch 2510: batch_loss=0.000190\n",
            "Batch 2520: batch_loss=0.000089\n",
            "Batch 2530: batch_loss=0.002499\n",
            "Batch 2540: batch_loss=0.000879\n",
            "Batch 2550: batch_loss=0.000876\n",
            "Batch 2560: batch_loss=0.000922\n",
            "Batch 2570: batch_loss=0.000952\n",
            "Batch 2580: batch_loss=0.001794\n",
            "Batch 2590: batch_loss=0.000952\n",
            "Batch 2600: batch_loss=0.000052\n",
            "Batch 2610: batch_loss=0.001709\n",
            "Batch 2620: batch_loss=0.000081\n",
            "Batch 2630: batch_loss=0.000901\n",
            "Batch 2640: batch_loss=0.000077\n",
            "Batch 2650: batch_loss=0.001753\n",
            "Batch 2660: batch_loss=0.000907\n",
            "Batch 2670: batch_loss=0.000189\n",
            "Batch 2680: batch_loss=0.001703\n",
            "Batch 2690: batch_loss=0.001052\n",
            "Batch 2700: batch_loss=0.002840\n",
            "Batch 2710: batch_loss=0.000992\n",
            "Batch 2720: batch_loss=0.000910\n",
            "Batch 2730: batch_loss=0.000944\n",
            "Batch 2740: batch_loss=0.000963\n",
            "Batch 2750: batch_loss=0.001735\n",
            "Batch 2760: batch_loss=0.001020\n",
            "Batch 2770: batch_loss=0.002582\n",
            "Batch 2780: batch_loss=0.001965\n",
            "Batch 2790: batch_loss=0.000892\n",
            "Batch 2800: batch_loss=0.002610\n",
            "Batch 2810: batch_loss=0.002680\n",
            "Batch 2820: batch_loss=0.003403\n",
            "Batch 2830: batch_loss=0.000942\n",
            "Batch 2840: batch_loss=0.000168\n",
            "Batch 2850: batch_loss=0.000959\n",
            "Batch 2860: batch_loss=0.000114\n",
            "Batch 2870: batch_loss=0.000038\n",
            "Batch 2880: batch_loss=0.001612\n",
            "Batch 2890: batch_loss=0.002538\n",
            "Batch 2900: batch_loss=0.000109\n",
            "Batch 2910: batch_loss=0.000903\n",
            "Batch 2920: batch_loss=0.001703\n",
            "Batch 2930: batch_loss=0.001696\n",
            "Batch 2940: batch_loss=0.001740\n",
            "Batch 2950: batch_loss=0.001836\n",
            "Batch 2960: batch_loss=0.000910\n",
            "Batch 2970: batch_loss=0.002546\n",
            "Batch 2980: batch_loss=0.001694\n",
            "Batch 2990: batch_loss=0.001811\n",
            "Batch 3000: batch_loss=0.000850\n",
            "Batch 3010: batch_loss=0.002570\n",
            "Batch 3020: batch_loss=0.005742\n",
            "Batch 3030: batch_loss=0.002556\n",
            "Batch 3040: batch_loss=0.002614\n",
            "Batch 3050: batch_loss=0.001733\n",
            "Batch 3060: batch_loss=0.002510\n",
            "Batch 3070: batch_loss=0.000082\n",
            "Batch 3080: batch_loss=0.002610\n",
            "Batch 3090: batch_loss=0.000052\n",
            "Batch 3100: batch_loss=0.000081\n",
            "Batch 3110: batch_loss=0.000927\n",
            "Batch 3120: batch_loss=0.004960\n",
            "Batch 3130: batch_loss=0.000894\n",
            "Batch 3140: batch_loss=0.002506\n",
            "Batch 3150: batch_loss=0.001720\n",
            "Batch 3160: batch_loss=0.001707\n",
            "Batch 3170: batch_loss=0.000080\n",
            "Batch 3180: batch_loss=0.000864\n",
            "Batch 3190: batch_loss=0.000030\n",
            "Batch 3200: batch_loss=0.002535\n",
            "Batch 3210: batch_loss=0.000043\n",
            "Batch 3220: batch_loss=0.002554\n",
            "Batch 3230: batch_loss=0.001741\n",
            "Batch 3240: batch_loss=0.000868\n",
            "Batch 3250: batch_loss=0.000935\n",
            "Batch 3260: batch_loss=0.000958\n",
            "Batch 3270: batch_loss=0.000996\n",
            "Batch 3280: batch_loss=0.001702\n",
            "Batch 3290: batch_loss=0.002525\n",
            "Batch 3300: batch_loss=0.000936\n",
            "Batch 3310: batch_loss=0.002562\n",
            "Batch 3320: batch_loss=0.000130\n",
            "Batch 3330: batch_loss=0.000988\n",
            "Batch 3340: batch_loss=0.001808\n",
            "Batch 3350: batch_loss=0.002679\n",
            "Batch 3360: batch_loss=0.000052\n",
            "Batch 3370: batch_loss=0.000086\n",
            "Batch 3380: batch_loss=0.005010\n",
            "Batch 3390: batch_loss=0.001747\n",
            "Batch 3400: batch_loss=0.004119\n",
            "Batch 3410: batch_loss=0.003348\n",
            "Batch 3420: batch_loss=0.001705\n",
            "Batch 3430: batch_loss=0.001690\n",
            "Batch 3440: batch_loss=0.003441\n",
            "Batch 3450: batch_loss=0.000911\n",
            "Batch 3460: batch_loss=0.002531\n",
            "Batch 3470: batch_loss=0.001771\n",
            "Batch 3480: batch_loss=0.000025\n",
            "Batch 3490: batch_loss=0.000069\n",
            "Batch 3500: batch_loss=0.003384\n",
            "Batch 3510: batch_loss=0.000860\n",
            "Batch 3520: batch_loss=0.000915\n",
            "Batch 3530: batch_loss=0.001666\n",
            "Batch 3540: batch_loss=0.002503\n",
            "Batch 3550: batch_loss=0.000130\n",
            "Batch 3560: batch_loss=0.000941\n",
            "Batch 3570: batch_loss=0.000082\n",
            "Batch 3580: batch_loss=0.000050\n",
            "Batch 3590: batch_loss=0.000085\n",
            "Batch 3600: batch_loss=0.000084\n",
            "Batch 3610: batch_loss=0.001937\n",
            "Batch 3620: batch_loss=0.001712\n",
            "Batch 3630: batch_loss=0.000933\n",
            "Batch 3640: batch_loss=0.000078\n",
            "Batch 3650: batch_loss=0.000053\n",
            "Batch 3660: batch_loss=0.000031\n",
            "Batch 3670: batch_loss=0.000901\n",
            "Batch 3680: batch_loss=0.002534\n",
            "Batch 3690: batch_loss=0.000901\n",
            "Batch 3700: batch_loss=0.001708\n",
            "Batch 3710: batch_loss=0.002510\n",
            "Batch 3720: batch_loss=0.001978\n",
            "Epoch 8/10, Train Loss: 0.001421, Val Loss: 0.001514\n",
            "Batch 0: batch_loss=0.001824\n",
            "Batch 10: batch_loss=0.001801\n",
            "Batch 20: batch_loss=0.000351\n",
            "Batch 30: batch_loss=0.002544\n",
            "Batch 40: batch_loss=0.002607\n",
            "Batch 50: batch_loss=0.002550\n",
            "Batch 60: batch_loss=0.001001\n",
            "Batch 70: batch_loss=0.000189\n",
            "Batch 80: batch_loss=0.001773\n",
            "Batch 90: batch_loss=0.004963\n",
            "Batch 100: batch_loss=0.000095\n",
            "Batch 110: batch_loss=0.000850\n",
            "Batch 120: batch_loss=0.002505\n",
            "Batch 130: batch_loss=0.000053\n",
            "Batch 140: batch_loss=0.001001\n",
            "Batch 150: batch_loss=0.000143\n",
            "Batch 160: batch_loss=0.001714\n",
            "Batch 170: batch_loss=0.003322\n",
            "Batch 180: batch_loss=0.001707\n",
            "Batch 190: batch_loss=0.001724\n",
            "Batch 200: batch_loss=0.002544\n",
            "Batch 210: batch_loss=0.000108\n",
            "Batch 220: batch_loss=0.000045\n",
            "Batch 230: batch_loss=0.003315\n",
            "Batch 240: batch_loss=0.002532\n",
            "Batch 250: batch_loss=0.000900\n",
            "Batch 260: batch_loss=0.001675\n",
            "Batch 270: batch_loss=0.000290\n",
            "Batch 280: batch_loss=0.000165\n",
            "Batch 290: batch_loss=0.001024\n",
            "Batch 300: batch_loss=0.004234\n",
            "Batch 310: batch_loss=0.002544\n",
            "Batch 320: batch_loss=0.001683\n",
            "Batch 330: batch_loss=0.002632\n",
            "Batch 340: batch_loss=0.001777\n",
            "Batch 350: batch_loss=0.000125\n",
            "Batch 360: batch_loss=0.001769\n",
            "Batch 370: batch_loss=0.003378\n",
            "Batch 380: batch_loss=0.000977\n",
            "Batch 390: batch_loss=0.002571\n",
            "Batch 400: batch_loss=0.000112\n",
            "Batch 410: batch_loss=0.001718\n",
            "Batch 420: batch_loss=0.001801\n",
            "Batch 430: batch_loss=0.000095\n",
            "Batch 440: batch_loss=0.001751\n",
            "Batch 450: batch_loss=0.001748\n",
            "Batch 460: batch_loss=0.000955\n",
            "Batch 470: batch_loss=0.000909\n",
            "Batch 480: batch_loss=0.000901\n",
            "Batch 490: batch_loss=0.000912\n",
            "Batch 500: batch_loss=0.001693\n",
            "Batch 510: batch_loss=0.000074\n",
            "Batch 520: batch_loss=0.002516\n",
            "Batch 530: batch_loss=0.000076\n",
            "Batch 540: batch_loss=0.001712\n",
            "Batch 550: batch_loss=0.000883\n",
            "Batch 560: batch_loss=0.002534\n",
            "Batch 570: batch_loss=0.004114\n",
            "Batch 580: batch_loss=0.001011\n",
            "Batch 590: batch_loss=0.000708\n",
            "Batch 600: batch_loss=0.000984\n",
            "Batch 610: batch_loss=0.000049\n",
            "Batch 620: batch_loss=0.001719\n",
            "Batch 630: batch_loss=0.003373\n",
            "Batch 640: batch_loss=0.000034\n",
            "Batch 650: batch_loss=0.001682\n",
            "Batch 660: batch_loss=0.000171\n",
            "Batch 670: batch_loss=0.000909\n",
            "Batch 680: batch_loss=0.002510\n",
            "Batch 690: batch_loss=0.000967\n",
            "Batch 700: batch_loss=0.000891\n",
            "Batch 710: batch_loss=0.001694\n",
            "Batch 720: batch_loss=0.000931\n",
            "Batch 730: batch_loss=0.001681\n",
            "Batch 740: batch_loss=0.003307\n",
            "Batch 750: batch_loss=0.002522\n",
            "Batch 760: batch_loss=0.001009\n",
            "Batch 770: batch_loss=0.000985\n",
            "Batch 780: batch_loss=0.000892\n",
            "Batch 790: batch_loss=0.000044\n",
            "Batch 800: batch_loss=0.000049\n",
            "Batch 810: batch_loss=0.000888\n",
            "Batch 820: batch_loss=0.000867\n",
            "Batch 830: batch_loss=0.001740\n",
            "Batch 840: batch_loss=0.000843\n",
            "Batch 850: batch_loss=0.000915\n",
            "Batch 860: batch_loss=0.001769\n",
            "Batch 870: batch_loss=0.000976\n",
            "Batch 880: batch_loss=0.005819\n",
            "Batch 890: batch_loss=0.001702\n",
            "Batch 900: batch_loss=0.000167\n",
            "Batch 910: batch_loss=0.001777\n",
            "Batch 920: batch_loss=0.002529\n",
            "Batch 930: batch_loss=0.002609\n",
            "Batch 940: batch_loss=0.000071\n",
            "Batch 950: batch_loss=0.000884\n",
            "Batch 960: batch_loss=0.002571\n",
            "Batch 970: batch_loss=0.000848\n",
            "Batch 980: batch_loss=0.000893\n",
            "Batch 990: batch_loss=0.000887\n",
            "Batch 1000: batch_loss=0.000894\n",
            "Batch 1010: batch_loss=0.000071\n",
            "Batch 1020: batch_loss=0.001757\n",
            "Batch 1030: batch_loss=0.000945\n",
            "Batch 1040: batch_loss=0.000905\n",
            "Batch 1050: batch_loss=0.000904\n",
            "Batch 1060: batch_loss=0.002508\n",
            "Batch 1070: batch_loss=0.000897\n",
            "Batch 1080: batch_loss=0.000927\n",
            "Batch 1090: batch_loss=0.000117\n",
            "Batch 1100: batch_loss=0.000103\n",
            "Batch 1110: batch_loss=0.000933\n",
            "Batch 1120: batch_loss=0.000863\n",
            "Batch 1130: batch_loss=0.001702\n",
            "Batch 1140: batch_loss=0.000934\n",
            "Batch 1150: batch_loss=0.001692\n",
            "Batch 1160: batch_loss=0.000048\n",
            "Batch 1170: batch_loss=0.002525\n",
            "Batch 1180: batch_loss=0.000914\n",
            "Batch 1190: batch_loss=0.000129\n",
            "Batch 1200: batch_loss=0.002497\n",
            "Batch 1210: batch_loss=0.000056\n",
            "Batch 1220: batch_loss=0.001724\n",
            "Batch 1230: batch_loss=0.000048\n",
            "Batch 1240: batch_loss=0.003353\n",
            "Batch 1250: batch_loss=0.003527\n",
            "Batch 1260: batch_loss=0.000977\n",
            "Batch 1270: batch_loss=0.001685\n",
            "Batch 1280: batch_loss=0.000084\n",
            "Batch 1290: batch_loss=0.000098\n",
            "Batch 1300: batch_loss=0.003376\n",
            "Batch 1310: batch_loss=0.002697\n",
            "Batch 1320: batch_loss=0.001798\n",
            "Batch 1330: batch_loss=0.000869\n",
            "Batch 1340: batch_loss=0.001691\n",
            "Batch 1350: batch_loss=0.000925\n",
            "Batch 1360: batch_loss=0.001906\n",
            "Batch 1370: batch_loss=0.001855\n",
            "Batch 1380: batch_loss=0.002605\n",
            "Batch 1390: batch_loss=0.000057\n",
            "Batch 1400: batch_loss=0.000124\n",
            "Batch 1410: batch_loss=0.001794\n",
            "Batch 1420: batch_loss=0.000949\n",
            "Batch 1430: batch_loss=0.000046\n",
            "Batch 1440: batch_loss=0.001675\n",
            "Batch 1450: batch_loss=0.000862\n",
            "Batch 1460: batch_loss=0.000092\n",
            "Batch 1470: batch_loss=0.001705\n",
            "Batch 1480: batch_loss=0.002487\n",
            "Batch 1490: batch_loss=0.000837\n",
            "Batch 1500: batch_loss=0.000860\n",
            "Batch 1510: batch_loss=0.000860\n",
            "Batch 1520: batch_loss=0.002510\n",
            "Batch 1530: batch_loss=0.002522\n",
            "Batch 1540: batch_loss=0.001679\n",
            "Batch 1550: batch_loss=0.000109\n",
            "Batch 1560: batch_loss=0.001704\n",
            "Batch 1570: batch_loss=0.002601\n",
            "Batch 1580: batch_loss=0.001690\n",
            "Batch 1590: batch_loss=0.000909\n",
            "Batch 1600: batch_loss=0.001718\n",
            "Batch 1610: batch_loss=0.000159\n",
            "Batch 1620: batch_loss=0.000922\n",
            "Batch 1630: batch_loss=0.000880\n",
            "Batch 1640: batch_loss=0.001676\n",
            "Batch 1650: batch_loss=0.000935\n",
            "Batch 1660: batch_loss=0.004099\n",
            "Batch 1670: batch_loss=0.000066\n",
            "Batch 1680: batch_loss=0.002629\n",
            "Batch 1690: batch_loss=0.001728\n",
            "Batch 1700: batch_loss=0.001664\n",
            "Batch 1710: batch_loss=0.002513\n",
            "Batch 1720: batch_loss=0.000897\n",
            "Batch 1730: batch_loss=0.000128\n",
            "Batch 1740: batch_loss=0.000081\n",
            "Batch 1750: batch_loss=0.000949\n",
            "Batch 1760: batch_loss=0.002545\n",
            "Batch 1770: batch_loss=0.000849\n",
            "Batch 1780: batch_loss=0.000156\n",
            "Batch 1790: batch_loss=0.000922\n",
            "Batch 1800: batch_loss=0.002529\n",
            "Batch 1810: batch_loss=0.002625\n",
            "Batch 1820: batch_loss=0.004984\n",
            "Batch 1830: batch_loss=0.002526\n",
            "Batch 1840: batch_loss=0.001159\n",
            "Batch 1850: batch_loss=0.002551\n",
            "Batch 1860: batch_loss=0.000969\n",
            "Batch 1870: batch_loss=0.000863\n",
            "Batch 1880: batch_loss=0.000046\n",
            "Batch 1890: batch_loss=0.001746\n",
            "Batch 1900: batch_loss=0.000983\n",
            "Batch 1910: batch_loss=0.002509\n",
            "Batch 1920: batch_loss=0.001713\n",
            "Batch 1930: batch_loss=0.000863\n",
            "Batch 1940: batch_loss=0.000138\n",
            "Batch 1950: batch_loss=0.000889\n",
            "Batch 1960: batch_loss=0.000067\n",
            "Batch 1970: batch_loss=0.000113\n",
            "Batch 1980: batch_loss=0.001735\n",
            "Batch 1990: batch_loss=0.000906\n",
            "Batch 2000: batch_loss=0.000926\n",
            "Batch 2010: batch_loss=0.001723\n",
            "Batch 2020: batch_loss=0.000886\n",
            "Batch 2030: batch_loss=0.001707\n",
            "Batch 2040: batch_loss=0.001683\n",
            "Batch 2050: batch_loss=0.000884\n",
            "Batch 2060: batch_loss=0.000961\n",
            "Batch 2070: batch_loss=0.001806\n",
            "Batch 2080: batch_loss=0.003348\n",
            "Batch 2090: batch_loss=0.000869\n",
            "Batch 2100: batch_loss=0.000933\n",
            "Batch 2110: batch_loss=0.000074\n",
            "Batch 2120: batch_loss=0.000896\n",
            "Batch 2130: batch_loss=0.000070\n",
            "Batch 2140: batch_loss=0.000042\n",
            "Batch 2150: batch_loss=0.000121\n",
            "Batch 2160: batch_loss=0.001736\n",
            "Batch 2170: batch_loss=0.002618\n",
            "Batch 2180: batch_loss=0.001742\n",
            "Batch 2190: batch_loss=0.000890\n",
            "Batch 2200: batch_loss=0.002513\n",
            "Batch 2210: batch_loss=0.001651\n",
            "Batch 2220: batch_loss=0.001719\n",
            "Batch 2230: batch_loss=0.003290\n",
            "Batch 2240: batch_loss=0.001693\n",
            "Batch 2250: batch_loss=0.000869\n",
            "Batch 2260: batch_loss=0.000924\n",
            "Batch 2270: batch_loss=0.000017\n",
            "Batch 2280: batch_loss=0.000089\n",
            "Batch 2290: batch_loss=0.000923\n",
            "Batch 2300: batch_loss=0.000047\n",
            "Batch 2310: batch_loss=0.000052\n",
            "Batch 2320: batch_loss=0.002508\n",
            "Batch 2330: batch_loss=0.002527\n",
            "Batch 2340: batch_loss=0.000876\n",
            "Batch 2350: batch_loss=0.002564\n",
            "Batch 2360: batch_loss=0.001728\n",
            "Batch 2370: batch_loss=0.000892\n",
            "Batch 2380: batch_loss=0.002542\n",
            "Batch 2390: batch_loss=0.000846\n",
            "Batch 2400: batch_loss=0.000909\n",
            "Batch 2410: batch_loss=0.001749\n",
            "Batch 2420: batch_loss=0.000955\n",
            "Batch 2430: batch_loss=0.000078\n",
            "Batch 2440: batch_loss=0.003410\n",
            "Batch 2450: batch_loss=0.000926\n",
            "Batch 2460: batch_loss=0.004131\n",
            "Batch 2470: batch_loss=0.001688\n",
            "Batch 2480: batch_loss=0.001772\n",
            "Batch 2490: batch_loss=0.001718\n",
            "Batch 2500: batch_loss=0.000220\n",
            "Batch 2510: batch_loss=0.002718\n",
            "Batch 2520: batch_loss=0.000089\n",
            "Batch 2530: batch_loss=0.000878\n",
            "Batch 2540: batch_loss=0.001770\n",
            "Batch 2550: batch_loss=0.000209\n",
            "Batch 2560: batch_loss=0.000306\n",
            "Batch 2570: batch_loss=0.000914\n",
            "Batch 2580: batch_loss=0.000178\n",
            "Batch 2590: batch_loss=0.000986\n",
            "Batch 2600: batch_loss=0.003447\n",
            "Batch 2610: batch_loss=0.000237\n",
            "Batch 2620: batch_loss=0.000338\n",
            "Batch 2630: batch_loss=0.002536\n",
            "Batch 2640: batch_loss=0.001884\n",
            "Batch 2650: batch_loss=0.000962\n",
            "Batch 2660: batch_loss=0.001748\n",
            "Batch 2670: batch_loss=0.000905\n",
            "Batch 2680: batch_loss=0.001711\n",
            "Batch 2690: batch_loss=0.001766\n",
            "Batch 2700: batch_loss=0.000040\n",
            "Batch 2710: batch_loss=0.002532\n",
            "Batch 2720: batch_loss=0.002690\n",
            "Batch 2730: batch_loss=0.002516\n",
            "Batch 2740: batch_loss=0.005021\n",
            "Batch 2750: batch_loss=0.003354\n",
            "Batch 2760: batch_loss=0.000883\n",
            "Batch 2770: batch_loss=0.000852\n",
            "Batch 2780: batch_loss=0.002526\n",
            "Batch 2790: batch_loss=0.002522\n",
            "Batch 2800: batch_loss=0.000857\n",
            "Batch 2810: batch_loss=0.000086\n",
            "Batch 2820: batch_loss=0.000904\n",
            "Batch 2830: batch_loss=0.002545\n",
            "Batch 2840: batch_loss=0.001724\n",
            "Batch 2850: batch_loss=0.000871\n",
            "Batch 2860: batch_loss=0.000875\n",
            "Batch 2870: batch_loss=0.000886\n",
            "Batch 2880: batch_loss=0.003319\n",
            "Batch 2890: batch_loss=0.001756\n",
            "Batch 2900: batch_loss=0.000057\n",
            "Batch 2910: batch_loss=0.000900\n",
            "Batch 2920: batch_loss=0.000079\n",
            "Batch 2930: batch_loss=0.001677\n",
            "Batch 2940: batch_loss=0.001741\n",
            "Batch 2950: batch_loss=0.000890\n",
            "Batch 2960: batch_loss=0.001698\n",
            "Batch 2970: batch_loss=0.000897\n",
            "Batch 2980: batch_loss=0.000057\n",
            "Batch 2990: batch_loss=0.000886\n",
            "Batch 3000: batch_loss=0.000133\n",
            "Batch 3010: batch_loss=0.001752\n",
            "Batch 3020: batch_loss=0.000884\n",
            "Batch 3030: batch_loss=0.002488\n",
            "Batch 3040: batch_loss=0.003308\n",
            "Batch 3050: batch_loss=0.000041\n",
            "Batch 3060: batch_loss=0.005009\n",
            "Batch 3070: batch_loss=0.000894\n",
            "Batch 3080: batch_loss=0.001696\n",
            "Batch 3090: batch_loss=0.008200\n",
            "Batch 3100: batch_loss=0.000113\n",
            "Batch 3110: batch_loss=0.002668\n",
            "Batch 3120: batch_loss=0.001673\n",
            "Batch 3130: batch_loss=0.000841\n",
            "Batch 3140: batch_loss=0.000948\n",
            "Batch 3150: batch_loss=0.002568\n",
            "Batch 3160: batch_loss=0.000864\n",
            "Batch 3170: batch_loss=0.001025\n",
            "Batch 3180: batch_loss=0.001787\n",
            "Batch 3190: batch_loss=0.000852\n",
            "Batch 3200: batch_loss=0.003385\n",
            "Batch 3210: batch_loss=0.001726\n",
            "Batch 3220: batch_loss=0.000919\n",
            "Batch 3230: batch_loss=0.001686\n",
            "Batch 3240: batch_loss=0.000849\n",
            "Batch 3250: batch_loss=0.002729\n",
            "Batch 3260: batch_loss=0.000062\n",
            "Batch 3270: batch_loss=0.001741\n",
            "Batch 3280: batch_loss=0.001745\n",
            "Batch 3290: batch_loss=0.000889\n",
            "Batch 3300: batch_loss=0.004233\n",
            "Batch 3310: batch_loss=0.000904\n",
            "Batch 3320: batch_loss=0.000922\n",
            "Batch 3330: batch_loss=0.000867\n",
            "Batch 3340: batch_loss=0.000875\n",
            "Batch 3350: batch_loss=0.000962\n",
            "Batch 3360: batch_loss=0.000905\n",
            "Batch 3370: batch_loss=0.001726\n",
            "Batch 3380: batch_loss=0.007272\n",
            "Batch 3390: batch_loss=0.002522\n",
            "Batch 3400: batch_loss=0.001685\n",
            "Batch 3410: batch_loss=0.001783\n",
            "Batch 3420: batch_loss=0.000911\n",
            "Batch 3430: batch_loss=0.001781\n",
            "Batch 3440: batch_loss=0.000966\n",
            "Batch 3450: batch_loss=0.002533\n",
            "Batch 3460: batch_loss=0.000068\n",
            "Batch 3470: batch_loss=0.000898\n",
            "Batch 3480: batch_loss=0.000916\n",
            "Batch 3490: batch_loss=0.001676\n",
            "Batch 3500: batch_loss=0.000927\n",
            "Batch 3510: batch_loss=0.002564\n",
            "Batch 3520: batch_loss=0.001022\n",
            "Batch 3530: batch_loss=0.000075\n",
            "Batch 3540: batch_loss=0.000093\n",
            "Batch 3550: batch_loss=0.002539\n",
            "Batch 3560: batch_loss=0.001721\n",
            "Batch 3570: batch_loss=0.001683\n",
            "Batch 3580: batch_loss=0.001740\n",
            "Batch 3590: batch_loss=0.000963\n",
            "Batch 3600: batch_loss=0.000184\n",
            "Batch 3610: batch_loss=0.000077\n",
            "Batch 3620: batch_loss=0.000913\n",
            "Batch 3630: batch_loss=0.000974\n",
            "Batch 3640: batch_loss=0.000941\n",
            "Batch 3650: batch_loss=0.000912\n",
            "Batch 3660: batch_loss=0.001677\n",
            "Batch 3670: batch_loss=0.000899\n",
            "Batch 3680: batch_loss=0.001166\n",
            "Batch 3690: batch_loss=0.000905\n",
            "Batch 3700: batch_loss=0.000186\n",
            "Batch 3710: batch_loss=0.005071\n",
            "Batch 3720: batch_loss=0.000152\n",
            "Epoch 9/10, Train Loss: 0.001418, Val Loss: 0.001773\n",
            "Batch 0: batch_loss=0.002312\n",
            "Batch 10: batch_loss=0.000876\n",
            "Batch 20: batch_loss=0.001077\n",
            "Batch 30: batch_loss=0.002620\n",
            "Batch 40: batch_loss=0.001736\n",
            "Batch 50: batch_loss=0.000930\n",
            "Batch 60: batch_loss=0.000919\n",
            "Batch 70: batch_loss=0.001705\n",
            "Batch 80: batch_loss=0.000880\n",
            "Batch 90: batch_loss=0.000870\n",
            "Batch 100: batch_loss=0.000876\n",
            "Batch 110: batch_loss=0.001770\n",
            "Batch 120: batch_loss=0.000037\n",
            "Batch 130: batch_loss=0.000096\n",
            "Batch 140: batch_loss=0.000054\n",
            "Batch 150: batch_loss=0.001659\n",
            "Batch 160: batch_loss=0.003367\n",
            "Batch 170: batch_loss=0.001759\n",
            "Batch 180: batch_loss=0.000080\n",
            "Batch 190: batch_loss=0.000876\n",
            "Batch 200: batch_loss=0.002525\n",
            "Batch 210: batch_loss=0.000053\n",
            "Batch 220: batch_loss=0.000049\n",
            "Batch 230: batch_loss=0.001752\n",
            "Batch 240: batch_loss=0.000038\n",
            "Batch 250: batch_loss=0.000056\n",
            "Batch 260: batch_loss=0.006029\n",
            "Batch 270: batch_loss=0.000964\n",
            "Batch 280: batch_loss=0.000886\n",
            "Batch 290: batch_loss=0.000052\n",
            "Batch 300: batch_loss=0.000095\n",
            "Batch 310: batch_loss=0.000131\n",
            "Batch 320: batch_loss=0.001779\n",
            "Batch 330: batch_loss=0.000064\n",
            "Batch 340: batch_loss=0.000050\n",
            "Batch 350: batch_loss=0.001807\n",
            "Batch 360: batch_loss=0.003350\n",
            "Batch 370: batch_loss=0.000903\n",
            "Batch 380: batch_loss=0.000864\n",
            "Batch 390: batch_loss=0.000106\n",
            "Batch 400: batch_loss=0.001723\n",
            "Batch 410: batch_loss=0.000176\n",
            "Batch 420: batch_loss=0.000913\n",
            "Batch 430: batch_loss=0.003411\n",
            "Batch 440: batch_loss=0.000055\n",
            "Batch 450: batch_loss=0.001710\n",
            "Batch 460: batch_loss=0.001022\n",
            "Batch 470: batch_loss=0.000882\n",
            "Batch 480: batch_loss=0.001678\n",
            "Batch 490: batch_loss=0.002525\n",
            "Batch 500: batch_loss=0.001744\n",
            "Batch 510: batch_loss=0.000938\n",
            "Batch 520: batch_loss=0.000843\n",
            "Batch 530: batch_loss=0.000073\n",
            "Batch 540: batch_loss=0.000132\n",
            "Batch 550: batch_loss=0.000834\n",
            "Batch 560: batch_loss=0.000831\n",
            "Batch 570: batch_loss=0.004404\n",
            "Batch 580: batch_loss=0.001659\n",
            "Batch 590: batch_loss=0.002526\n",
            "Batch 600: batch_loss=0.000076\n",
            "Batch 610: batch_loss=0.000937\n",
            "Batch 620: batch_loss=0.000933\n",
            "Batch 630: batch_loss=0.000050\n",
            "Batch 640: batch_loss=0.000078\n",
            "Batch 650: batch_loss=0.000036\n",
            "Batch 660: batch_loss=0.001712\n",
            "Batch 670: batch_loss=0.001761\n",
            "Batch 680: batch_loss=0.000882\n",
            "Batch 690: batch_loss=0.000133\n",
            "Batch 700: batch_loss=0.003379\n",
            "Batch 710: batch_loss=0.004139\n",
            "Batch 720: batch_loss=0.001702\n",
            "Batch 730: batch_loss=0.002509\n",
            "Batch 740: batch_loss=0.001689\n",
            "Batch 750: batch_loss=0.002571\n",
            "Batch 760: batch_loss=0.000077\n",
            "Batch 770: batch_loss=0.000050\n",
            "Batch 780: batch_loss=0.000892\n",
            "Batch 790: batch_loss=0.002553\n",
            "Batch 800: batch_loss=0.001690\n",
            "Batch 810: batch_loss=0.001185\n",
            "Batch 820: batch_loss=0.000898\n",
            "Batch 830: batch_loss=0.000923\n",
            "Batch 840: batch_loss=0.001683\n",
            "Batch 850: batch_loss=0.002575\n",
            "Batch 860: batch_loss=0.000956\n",
            "Batch 870: batch_loss=0.001713\n",
            "Batch 880: batch_loss=0.000067\n",
            "Batch 890: batch_loss=0.000885\n",
            "Batch 900: batch_loss=0.000163\n",
            "Batch 910: batch_loss=0.000163\n",
            "Batch 920: batch_loss=0.000897\n",
            "Batch 930: batch_loss=0.002515\n",
            "Batch 940: batch_loss=0.000865\n",
            "Batch 950: batch_loss=0.000940\n",
            "Batch 960: batch_loss=0.000139\n",
            "Batch 970: batch_loss=0.001694\n",
            "Batch 980: batch_loss=0.001754\n",
            "Batch 990: batch_loss=0.000082\n",
            "Batch 1000: batch_loss=0.001768\n",
            "Batch 1010: batch_loss=0.000870\n",
            "Batch 1020: batch_loss=0.000961\n",
            "Batch 1030: batch_loss=0.001678\n",
            "Batch 1040: batch_loss=0.000967\n",
            "Batch 1050: batch_loss=0.000931\n",
            "Batch 1060: batch_loss=0.000883\n",
            "Batch 1070: batch_loss=0.000055\n",
            "Batch 1080: batch_loss=0.001706\n",
            "Batch 1090: batch_loss=0.000864\n",
            "Batch 1100: batch_loss=0.001769\n",
            "Batch 1110: batch_loss=0.000083\n",
            "Batch 1120: batch_loss=0.002526\n",
            "Batch 1130: batch_loss=0.000036\n",
            "Batch 1140: batch_loss=0.000059\n",
            "Batch 1150: batch_loss=0.000057\n",
            "Batch 1160: batch_loss=0.000910\n",
            "Batch 1170: batch_loss=0.000923\n",
            "Batch 1180: batch_loss=0.000035\n",
            "Batch 1190: batch_loss=0.001034\n",
            "Batch 1200: batch_loss=0.007296\n",
            "Batch 1210: batch_loss=0.000906\n",
            "Batch 1220: batch_loss=0.002544\n",
            "Batch 1230: batch_loss=0.000911\n",
            "Batch 1240: batch_loss=0.000052\n",
            "Batch 1250: batch_loss=0.005006\n",
            "Batch 1260: batch_loss=0.000962\n",
            "Batch 1270: batch_loss=0.001679\n",
            "Batch 1280: batch_loss=0.001780\n",
            "Batch 1290: batch_loss=0.000088\n",
            "Batch 1300: batch_loss=0.002713\n",
            "Batch 1310: batch_loss=0.004127\n",
            "Batch 1320: batch_loss=0.001667\n",
            "Batch 1330: batch_loss=0.002506\n",
            "Batch 1340: batch_loss=0.000889\n",
            "Batch 1350: batch_loss=0.000886\n",
            "Batch 1360: batch_loss=0.000967\n",
            "Batch 1370: batch_loss=0.001764\n",
            "Batch 1380: batch_loss=0.000884\n",
            "Batch 1390: batch_loss=0.002516\n",
            "Batch 1400: batch_loss=0.002569\n",
            "Batch 1410: batch_loss=0.001799\n",
            "Batch 1420: batch_loss=0.000143\n",
            "Batch 1430: batch_loss=0.001685\n",
            "Batch 1440: batch_loss=0.001818\n",
            "Batch 1450: batch_loss=0.002568\n",
            "Batch 1460: batch_loss=0.000919\n",
            "Batch 1470: batch_loss=0.002547\n",
            "Batch 1480: batch_loss=0.000097\n",
            "Batch 1490: batch_loss=0.000050\n",
            "Batch 1500: batch_loss=0.000907\n",
            "Batch 1510: batch_loss=0.005294\n",
            "Batch 1520: batch_loss=0.003329\n",
            "Batch 1530: batch_loss=0.000075\n",
            "Batch 1540: batch_loss=0.001719\n",
            "Batch 1550: batch_loss=0.000886\n",
            "Batch 1560: batch_loss=0.002515\n",
            "Batch 1570: batch_loss=0.001733\n",
            "Batch 1580: batch_loss=0.000973\n",
            "Batch 1590: batch_loss=0.000929\n",
            "Batch 1600: batch_loss=0.000185\n",
            "Batch 1610: batch_loss=0.001707\n",
            "Batch 1620: batch_loss=0.001081\n",
            "Batch 1630: batch_loss=0.001938\n",
            "Batch 1640: batch_loss=0.002681\n",
            "Batch 1650: batch_loss=0.002549\n",
            "Batch 1660: batch_loss=0.004905\n",
            "Batch 1670: batch_loss=0.000856\n",
            "Batch 1680: batch_loss=0.000104\n",
            "Batch 1690: batch_loss=0.008816\n",
            "Batch 1700: batch_loss=0.002543\n",
            "Batch 1710: batch_loss=0.002517\n",
            "Batch 1720: batch_loss=0.000045\n",
            "Batch 1730: batch_loss=0.001789\n",
            "Batch 1740: batch_loss=0.000945\n",
            "Batch 1750: batch_loss=0.000125\n",
            "Batch 1760: batch_loss=0.002599\n",
            "Batch 1770: batch_loss=0.000088\n",
            "Batch 1780: batch_loss=0.000967\n",
            "Batch 1790: batch_loss=0.001661\n",
            "Batch 1800: batch_loss=0.000107\n",
            "Batch 1810: batch_loss=0.000855\n",
            "Batch 1820: batch_loss=0.002573\n",
            "Batch 1830: batch_loss=0.000875\n",
            "Batch 1840: batch_loss=0.001750\n",
            "Batch 1850: batch_loss=0.004222\n",
            "Batch 1860: batch_loss=0.000145\n",
            "Batch 1870: batch_loss=0.002580\n",
            "Batch 1880: batch_loss=0.000929\n",
            "Batch 1890: batch_loss=0.002521\n",
            "Batch 1900: batch_loss=0.000865\n",
            "Batch 1910: batch_loss=0.000897\n",
            "Batch 1920: batch_loss=0.000940\n",
            "Batch 1930: batch_loss=0.001756\n",
            "Batch 1940: batch_loss=0.000190\n",
            "Batch 1950: batch_loss=0.000870\n",
            "Batch 1960: batch_loss=0.000069\n",
            "Batch 1970: batch_loss=0.000931\n",
            "Batch 1980: batch_loss=0.001696\n",
            "Batch 1990: batch_loss=0.003318\n",
            "Batch 2000: batch_loss=0.000117\n",
            "Batch 2010: batch_loss=0.000920\n",
            "Batch 2020: batch_loss=0.002556\n",
            "Batch 2030: batch_loss=0.000873\n",
            "Batch 2040: batch_loss=0.003334\n",
            "Batch 2050: batch_loss=0.002495\n",
            "Batch 2060: batch_loss=0.002502\n",
            "Batch 2070: batch_loss=0.000866\n",
            "Batch 2080: batch_loss=0.000101\n",
            "Batch 2090: batch_loss=0.001037\n",
            "Batch 2100: batch_loss=0.002483\n",
            "Batch 2110: batch_loss=0.002611\n",
            "Batch 2120: batch_loss=0.001695\n",
            "Batch 2130: batch_loss=0.001030\n",
            "Batch 2140: batch_loss=0.001703\n",
            "Batch 2150: batch_loss=0.000086\n",
            "Batch 2160: batch_loss=0.003365\n",
            "Batch 2170: batch_loss=0.000871\n",
            "Batch 2180: batch_loss=0.001704\n",
            "Batch 2190: batch_loss=0.000870\n",
            "Batch 2200: batch_loss=0.000133\n",
            "Batch 2210: batch_loss=0.000056\n",
            "Batch 2220: batch_loss=0.002559\n",
            "Batch 2230: batch_loss=0.001692\n",
            "Batch 2240: batch_loss=0.000920\n",
            "Batch 2250: batch_loss=0.001735\n",
            "Batch 2260: batch_loss=0.003301\n",
            "Batch 2270: batch_loss=0.000058\n",
            "Batch 2280: batch_loss=0.000112\n",
            "Batch 2290: batch_loss=0.000155\n",
            "Batch 2300: batch_loss=0.001809\n",
            "Batch 2310: batch_loss=0.000987\n",
            "Batch 2320: batch_loss=0.001685\n",
            "Batch 2330: batch_loss=0.001673\n",
            "Batch 2340: batch_loss=0.000221\n",
            "Batch 2350: batch_loss=0.004219\n",
            "Batch 2360: batch_loss=0.001873\n",
            "Batch 2370: batch_loss=0.001740\n",
            "Batch 2380: batch_loss=0.005657\n",
            "Batch 2390: batch_loss=0.000862\n",
            "Batch 2400: batch_loss=0.002474\n",
            "Batch 2410: batch_loss=0.000904\n",
            "Batch 2420: batch_loss=0.000094\n",
            "Batch 2430: batch_loss=0.002599\n",
            "Batch 2440: batch_loss=0.000854\n",
            "Batch 2450: batch_loss=0.000105\n",
            "Batch 2460: batch_loss=0.002539\n",
            "Batch 2470: batch_loss=0.000927\n",
            "Batch 2480: batch_loss=0.000034\n",
            "Batch 2490: batch_loss=0.002532\n",
            "Batch 2500: batch_loss=0.001752\n",
            "Batch 2510: batch_loss=0.000078\n",
            "Batch 2520: batch_loss=0.001699\n",
            "Batch 2530: batch_loss=0.002531\n",
            "Batch 2540: batch_loss=0.000099\n",
            "Batch 2550: batch_loss=0.000096\n",
            "Batch 2560: batch_loss=0.000939\n",
            "Batch 2570: batch_loss=0.001758\n",
            "Batch 2580: batch_loss=0.000037\n",
            "Batch 2590: batch_loss=0.003609\n",
            "Batch 2600: batch_loss=0.000093\n",
            "Batch 2610: batch_loss=0.000944\n",
            "Batch 2620: batch_loss=0.000874\n",
            "Batch 2630: batch_loss=0.001711\n",
            "Batch 2640: batch_loss=0.000945\n",
            "Batch 2650: batch_loss=0.000081\n",
            "Batch 2660: batch_loss=0.000866\n",
            "Batch 2670: batch_loss=0.000938\n",
            "Batch 2680: batch_loss=0.002501\n",
            "Batch 2690: batch_loss=0.003358\n",
            "Batch 2700: batch_loss=0.000034\n",
            "Batch 2710: batch_loss=0.000954\n",
            "Batch 2720: batch_loss=0.004154\n",
            "Batch 2730: batch_loss=0.000879\n",
            "Batch 2740: batch_loss=0.000881\n",
            "Batch 2750: batch_loss=0.002577\n",
            "Batch 2760: batch_loss=0.003336\n",
            "Batch 2770: batch_loss=0.000875\n",
            "Batch 2780: batch_loss=0.000917\n",
            "Batch 2790: batch_loss=0.002592\n",
            "Batch 2800: batch_loss=0.000024\n",
            "Batch 2810: batch_loss=0.000907\n",
            "Batch 2820: batch_loss=0.000068\n",
            "Batch 2830: batch_loss=0.002538\n",
            "Batch 2840: batch_loss=0.000858\n",
            "Batch 2850: batch_loss=0.000872\n",
            "Batch 2860: batch_loss=0.001753\n",
            "Batch 2870: batch_loss=0.000139\n",
            "Batch 2880: batch_loss=0.000937\n",
            "Batch 2890: batch_loss=0.001728\n",
            "Batch 2900: batch_loss=0.000857\n",
            "Batch 2910: batch_loss=0.000139\n",
            "Batch 2920: batch_loss=0.002517\n",
            "Batch 2930: batch_loss=0.001681\n",
            "Batch 2940: batch_loss=0.000064\n",
            "Batch 2950: batch_loss=0.000978\n",
            "Batch 2960: batch_loss=0.000839\n",
            "Batch 2970: batch_loss=0.001950\n",
            "Batch 2980: batch_loss=0.001675\n",
            "Batch 2990: batch_loss=0.000895\n",
            "Batch 3000: batch_loss=0.000940\n",
            "Batch 3010: batch_loss=0.001664\n",
            "Batch 3020: batch_loss=0.000888\n",
            "Batch 3030: batch_loss=0.001706\n",
            "Batch 3040: batch_loss=0.000095\n",
            "Batch 3050: batch_loss=0.000870\n",
            "Batch 3060: batch_loss=0.003372\n",
            "Batch 3070: batch_loss=0.005833\n",
            "Batch 3080: batch_loss=0.000115\n",
            "Batch 3090: batch_loss=0.000879\n",
            "Batch 3100: batch_loss=0.004258\n",
            "Batch 3110: batch_loss=0.002521\n",
            "Batch 3120: batch_loss=0.000042\n",
            "Batch 3130: batch_loss=0.001660\n",
            "Batch 3140: batch_loss=0.000926\n",
            "Batch 3150: batch_loss=0.000151\n",
            "Batch 3160: batch_loss=0.000937\n",
            "Batch 3170: batch_loss=0.000900\n",
            "Batch 3180: batch_loss=0.000922\n",
            "Batch 3190: batch_loss=0.002528\n",
            "Batch 3200: batch_loss=0.001720\n",
            "Batch 3210: batch_loss=0.001708\n",
            "Batch 3220: batch_loss=0.002672\n",
            "Batch 3230: batch_loss=0.002587\n",
            "Batch 3240: batch_loss=0.001660\n",
            "Batch 3250: batch_loss=0.000110\n",
            "Batch 3260: batch_loss=0.000055\n",
            "Batch 3270: batch_loss=0.000871\n",
            "Batch 3280: batch_loss=0.000882\n",
            "Batch 3290: batch_loss=0.000065\n",
            "Batch 3300: batch_loss=0.000127\n",
            "Batch 3310: batch_loss=0.001704\n",
            "Batch 3320: batch_loss=0.001704\n",
            "Batch 3330: batch_loss=0.000877\n",
            "Batch 3340: batch_loss=0.004208\n",
            "Batch 3350: batch_loss=0.001761\n",
            "Batch 3360: batch_loss=0.005364\n",
            "Batch 3370: batch_loss=0.000042\n",
            "Batch 3380: batch_loss=0.000926\n",
            "Batch 3390: batch_loss=0.001726\n",
            "Batch 3400: batch_loss=0.000879\n",
            "Batch 3410: batch_loss=0.000894\n",
            "Batch 3420: batch_loss=0.001723\n",
            "Batch 3430: batch_loss=0.001799\n",
            "Batch 3440: batch_loss=0.001718\n",
            "Batch 3450: batch_loss=0.000077\n",
            "Batch 3460: batch_loss=0.007751\n",
            "Batch 3470: batch_loss=0.002573\n",
            "Batch 3480: batch_loss=0.000865\n",
            "Batch 3490: batch_loss=0.000079\n",
            "Batch 3500: batch_loss=0.000064\n",
            "Batch 3510: batch_loss=0.000067\n",
            "Batch 3520: batch_loss=0.001786\n",
            "Batch 3530: batch_loss=0.000931\n",
            "Batch 3540: batch_loss=0.000039\n",
            "Batch 3550: batch_loss=0.001765\n",
            "Batch 3560: batch_loss=0.003368\n",
            "Batch 3570: batch_loss=0.000971\n",
            "Batch 3580: batch_loss=0.001709\n",
            "Batch 3590: batch_loss=0.001735\n",
            "Batch 3600: batch_loss=0.000216\n",
            "Batch 3610: batch_loss=0.000061\n",
            "Batch 3620: batch_loss=0.003385\n",
            "Batch 3630: batch_loss=0.000900\n",
            "Batch 3640: batch_loss=0.002595\n",
            "Batch 3650: batch_loss=0.001660\n",
            "Batch 3660: batch_loss=0.001690\n",
            "Batch 3670: batch_loss=0.000048\n",
            "Batch 3680: batch_loss=0.000042\n",
            "Batch 3690: batch_loss=0.000131\n",
            "Batch 3700: batch_loss=0.003414\n",
            "Batch 3710: batch_loss=0.001710\n",
            "Batch 3720: batch_loss=0.001743\n",
            "Epoch 10/10, Train Loss: 0.001415, Val Loss: 0.001668\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = EGNN_Boids(in_node_nf=4, hidden_nf=64, out_node_nf=2, device=device, L=[1000, 1000])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "print(\"EGNN Model\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    p_teacher = p_teacher_schedule(epoch, num_epochs)\n",
        "\n",
        "    # ----- TRAIN -----\n",
        "    train_loss = push_forward_train_epoch(\n",
        "        model=model,\n",
        "        dataloader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        box=box,\n",
        "        radius=radius,\n",
        "        rollout_steps=3,\n",
        "        #p_teacher_fn=lambda: p_teacher,  # schedule\n",
        "        grad_clip=1.0,\n",
        "    )\n",
        "\n",
        "    # ----- VALIDATION -----\n",
        "    val_loss = 0.0\n",
        "    n_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "          init_data = batch[\"init\"].to(device)\n",
        "          gt_sequence = [gt.to(device) for gt in batch[\"gt\"]]\n",
        "\n",
        "          preds, targets = rollout_push_forward(\n",
        "              model=model,\n",
        "              init_data=init_data,\n",
        "              gt_sequence=gt_sequence,\n",
        "              rollout_steps=5,\n",
        "              radius=radius,\n",
        "              box=box,\n",
        "              device=device,\n",
        "              p_teacher=0.0,  # no teacher forcing in validation\n",
        "          )\n",
        "          val_loss += rollout_loss(preds, targets).item()\n",
        "          n_val_batches += 1\n",
        "\n",
        "    val_loss /= max(1, n_val_batches)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "JZgZpjOvrmKS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translational Equivariant Model\n",
            "Batch 0: batch_loss=0.120264\n",
            "Batch 10: batch_loss=0.104877\n",
            "Batch 20: batch_loss=0.106669\n",
            "Batch 30: batch_loss=0.156048\n",
            "Batch 40: batch_loss=0.138312\n",
            "Batch 50: batch_loss=0.138817\n",
            "Batch 60: batch_loss=0.169431\n",
            "Batch 70: batch_loss=0.101972\n",
            "Batch 80: batch_loss=0.110052\n",
            "Batch 90: batch_loss=0.109697\n",
            "Batch 100: batch_loss=0.110153\n",
            "Batch 110: batch_loss=0.119326\n",
            "Batch 120: batch_loss=0.130337\n",
            "Batch 130: batch_loss=0.129924\n",
            "Batch 140: batch_loss=0.092411\n",
            "Batch 150: batch_loss=0.137258\n",
            "Batch 160: batch_loss=0.121288\n",
            "Batch 170: batch_loss=0.120459\n",
            "Batch 180: batch_loss=0.130757\n",
            "Batch 190: batch_loss=0.099694\n",
            "Batch 200: batch_loss=0.100272\n",
            "Batch 210: batch_loss=0.110217\n",
            "Batch 220: batch_loss=0.134165\n",
            "Batch 230: batch_loss=0.119861\n",
            "Batch 240: batch_loss=0.092138\n",
            "Batch 250: batch_loss=0.116450\n",
            "Batch 260: batch_loss=0.110781\n",
            "Batch 270: batch_loss=0.078859\n",
            "Batch 280: batch_loss=0.102982\n",
            "Batch 290: batch_loss=0.085784\n",
            "Batch 300: batch_loss=0.117955\n",
            "Batch 310: batch_loss=0.110047\n",
            "Batch 320: batch_loss=0.089080\n",
            "Batch 330: batch_loss=0.106406\n",
            "Batch 340: batch_loss=0.095930\n",
            "Batch 350: batch_loss=0.104849\n",
            "Batch 360: batch_loss=0.108828\n",
            "Batch 370: batch_loss=0.098452\n",
            "Batch 380: batch_loss=0.088791\n",
            "Batch 390: batch_loss=0.096555\n",
            "Batch 400: batch_loss=0.080535\n",
            "Batch 410: batch_loss=0.091544\n",
            "Batch 420: batch_loss=0.114197\n",
            "Batch 430: batch_loss=0.101751\n",
            "Batch 440: batch_loss=0.086959\n",
            "Batch 450: batch_loss=0.082825\n",
            "Batch 460: batch_loss=0.089644\n",
            "Batch 470: batch_loss=0.113619\n",
            "Batch 480: batch_loss=0.096868\n",
            "Batch 490: batch_loss=0.100750\n",
            "Batch 500: batch_loss=0.109045\n",
            "Batch 510: batch_loss=0.075539\n",
            "Batch 520: batch_loss=0.084489\n",
            "Batch 530: batch_loss=0.083544\n",
            "Batch 540: batch_loss=0.071542\n",
            "Batch 550: batch_loss=0.088431\n",
            "Batch 560: batch_loss=0.083734\n",
            "Batch 570: batch_loss=0.095495\n",
            "Batch 580: batch_loss=0.077419\n",
            "Batch 590: batch_loss=0.085662\n",
            "Batch 600: batch_loss=0.098733\n",
            "Batch 610: batch_loss=0.087323\n",
            "Batch 620: batch_loss=0.090611\n",
            "Batch 630: batch_loss=0.088672\n",
            "Batch 640: batch_loss=0.070309\n",
            "Batch 650: batch_loss=0.069166\n",
            "Batch 660: batch_loss=0.076485\n",
            "Batch 670: batch_loss=0.075214\n",
            "Batch 680: batch_loss=0.066770\n",
            "Batch 690: batch_loss=0.063903\n",
            "Batch 700: batch_loss=0.075862\n",
            "Batch 710: batch_loss=0.078226\n",
            "Batch 720: batch_loss=0.076586\n",
            "Batch 730: batch_loss=0.057777\n",
            "Batch 740: batch_loss=0.065922\n",
            "Batch 750: batch_loss=0.068620\n",
            "Batch 760: batch_loss=0.068997\n",
            "Batch 770: batch_loss=0.062522\n",
            "Batch 780: batch_loss=0.060586\n",
            "Batch 790: batch_loss=0.071625\n",
            "Batch 800: batch_loss=0.071889\n",
            "Batch 810: batch_loss=0.067384\n",
            "Batch 820: batch_loss=0.057259\n",
            "Batch 830: batch_loss=0.057614\n",
            "Batch 840: batch_loss=0.066123\n",
            "Batch 850: batch_loss=0.072905\n",
            "Batch 860: batch_loss=0.065203\n",
            "Batch 870: batch_loss=0.083198\n",
            "Batch 880: batch_loss=0.056874\n",
            "Batch 890: batch_loss=0.086112\n",
            "Batch 900: batch_loss=0.056623\n",
            "Batch 910: batch_loss=0.067281\n",
            "Batch 920: batch_loss=0.064089\n",
            "Batch 930: batch_loss=0.060429\n",
            "Batch 940: batch_loss=0.061596\n",
            "Batch 950: batch_loss=0.060749\n",
            "Batch 960: batch_loss=0.056373\n",
            "Batch 970: batch_loss=0.049149\n",
            "Batch 980: batch_loss=0.063390\n",
            "Batch 990: batch_loss=0.071084\n",
            "Batch 1000: batch_loss=0.052340\n",
            "Batch 1010: batch_loss=0.065774\n",
            "Batch 1020: batch_loss=0.068686\n",
            "Batch 1030: batch_loss=0.046450\n",
            "Batch 1040: batch_loss=0.057381\n",
            "Batch 1050: batch_loss=0.041398\n",
            "Batch 1060: batch_loss=0.060270\n",
            "Batch 1070: batch_loss=0.050107\n",
            "Batch 1080: batch_loss=0.048895\n",
            "Batch 1090: batch_loss=0.046022\n",
            "Batch 1100: batch_loss=0.050358\n",
            "Batch 1110: batch_loss=0.049083\n",
            "Batch 1120: batch_loss=0.057101\n",
            "Batch 1130: batch_loss=0.051333\n",
            "Batch 1140: batch_loss=0.059389\n",
            "Batch 1150: batch_loss=0.050160\n",
            "Batch 1160: batch_loss=0.043506\n",
            "Batch 1170: batch_loss=0.054114\n",
            "Batch 1180: batch_loss=0.058409\n",
            "Batch 1190: batch_loss=0.040704\n",
            "Batch 1200: batch_loss=0.048995\n",
            "Batch 1210: batch_loss=0.051362\n",
            "Batch 1220: batch_loss=0.053565\n",
            "Batch 1230: batch_loss=0.049136\n",
            "Batch 1240: batch_loss=0.041912\n",
            "Batch 1250: batch_loss=0.045547\n",
            "Batch 1260: batch_loss=0.042273\n",
            "Batch 1270: batch_loss=0.040090\n",
            "Batch 1280: batch_loss=0.046808\n",
            "Batch 1290: batch_loss=0.040704\n",
            "Batch 1300: batch_loss=0.049175\n",
            "Batch 1310: batch_loss=0.045488\n",
            "Batch 1320: batch_loss=0.045637\n",
            "Batch 1330: batch_loss=0.041178\n",
            "Batch 1340: batch_loss=0.057918\n",
            "Batch 1350: batch_loss=0.038835\n",
            "Batch 1360: batch_loss=0.030882\n",
            "Batch 1370: batch_loss=0.046732\n",
            "Batch 1380: batch_loss=0.035246\n",
            "Batch 1390: batch_loss=0.040987\n",
            "Batch 1400: batch_loss=0.041881\n",
            "Batch 1410: batch_loss=0.037945\n",
            "Batch 1420: batch_loss=0.034131\n",
            "Batch 1430: batch_loss=0.040064\n",
            "Batch 1440: batch_loss=0.039071\n",
            "Batch 1450: batch_loss=0.043553\n",
            "Batch 1460: batch_loss=0.044127\n",
            "Batch 1470: batch_loss=0.047185\n",
            "Batch 1480: batch_loss=0.036922\n",
            "Batch 1490: batch_loss=0.047297\n",
            "Batch 1500: batch_loss=0.037021\n",
            "Batch 1510: batch_loss=0.034626\n",
            "Batch 1520: batch_loss=0.030502\n",
            "Batch 1530: batch_loss=0.037276\n",
            "Batch 1540: batch_loss=0.031487\n",
            "Batch 1550: batch_loss=0.027364\n",
            "Batch 1560: batch_loss=0.030016\n",
            "Batch 1570: batch_loss=0.039174\n",
            "Batch 1580: batch_loss=0.030942\n",
            "Batch 1590: batch_loss=0.038587\n",
            "Batch 1600: batch_loss=0.033446\n",
            "Batch 1610: batch_loss=0.038519\n",
            "Batch 1620: batch_loss=0.036374\n",
            "Batch 1630: batch_loss=0.038850\n",
            "Batch 1640: batch_loss=0.027657\n",
            "Batch 1650: batch_loss=0.028856\n",
            "Batch 1660: batch_loss=0.035580\n",
            "Batch 1670: batch_loss=0.034165\n",
            "Batch 1680: batch_loss=0.036406\n",
            "Batch 1690: batch_loss=0.033033\n",
            "Batch 1700: batch_loss=0.029437\n",
            "Batch 1710: batch_loss=0.033687\n",
            "Batch 1720: batch_loss=0.032210\n",
            "Batch 1730: batch_loss=0.028092\n",
            "Batch 1740: batch_loss=0.028843\n",
            "Batch 1750: batch_loss=0.032168\n",
            "Batch 1760: batch_loss=0.037208\n",
            "Batch 1770: batch_loss=0.030589\n",
            "Batch 1780: batch_loss=0.024339\n",
            "Batch 1790: batch_loss=0.036190\n",
            "Batch 1800: batch_loss=0.029027\n",
            "Batch 1810: batch_loss=0.035619\n",
            "Batch 1820: batch_loss=0.036353\n",
            "Batch 1830: batch_loss=0.036203\n",
            "Batch 1840: batch_loss=0.034197\n",
            "Batch 1850: batch_loss=0.024629\n",
            "Batch 1860: batch_loss=0.030991\n",
            "Batch 1870: batch_loss=0.029043\n",
            "Batch 1880: batch_loss=0.032337\n",
            "Batch 1890: batch_loss=0.028466\n",
            "Batch 1900: batch_loss=0.028711\n",
            "Batch 1910: batch_loss=0.028275\n",
            "Batch 1920: batch_loss=0.026945\n",
            "Batch 1930: batch_loss=0.032754\n",
            "Batch 1940: batch_loss=0.031040\n",
            "Batch 1950: batch_loss=0.027253\n",
            "Batch 1960: batch_loss=0.030416\n",
            "Batch 1970: batch_loss=0.027956\n",
            "Batch 1980: batch_loss=0.028168\n",
            "Batch 1990: batch_loss=0.023404\n",
            "Batch 2000: batch_loss=0.034858\n",
            "Batch 2010: batch_loss=0.035201\n",
            "Batch 2020: batch_loss=0.030835\n",
            "Batch 2030: batch_loss=0.024779\n",
            "Batch 2040: batch_loss=0.022890\n",
            "Batch 2050: batch_loss=0.033655\n",
            "Batch 2060: batch_loss=0.031928\n",
            "Batch 2070: batch_loss=0.022882\n",
            "Batch 2080: batch_loss=0.028620\n",
            "Batch 2090: batch_loss=0.033807\n",
            "Batch 2100: batch_loss=0.026823\n",
            "Batch 2110: batch_loss=0.029273\n",
            "Batch 2120: batch_loss=0.040299\n",
            "Batch 2130: batch_loss=0.027546\n",
            "Batch 2140: batch_loss=0.029397\n",
            "Batch 2150: batch_loss=0.028854\n",
            "Batch 2160: batch_loss=0.024895\n",
            "Batch 2170: batch_loss=0.026924\n",
            "Batch 2180: batch_loss=0.023512\n",
            "Batch 2190: batch_loss=0.028203\n",
            "Batch 2200: batch_loss=0.025330\n",
            "Batch 2210: batch_loss=0.031614\n",
            "Batch 2220: batch_loss=0.027514\n",
            "Batch 2230: batch_loss=0.030437\n",
            "Batch 2240: batch_loss=0.025289\n",
            "Batch 2250: batch_loss=0.030825\n",
            "Batch 2260: batch_loss=0.024159\n",
            "Batch 2270: batch_loss=0.031427\n",
            "Batch 2280: batch_loss=0.030914\n",
            "Batch 2290: batch_loss=0.028462\n",
            "Batch 2300: batch_loss=0.030264\n",
            "Batch 2310: batch_loss=0.022806\n",
            "Batch 2320: batch_loss=0.030125\n",
            "Batch 2330: batch_loss=0.024254\n",
            "Batch 2340: batch_loss=0.022501\n",
            "Batch 2350: batch_loss=0.029552\n",
            "Batch 2360: batch_loss=0.031083\n",
            "Batch 2370: batch_loss=0.026056\n",
            "Batch 2380: batch_loss=0.041566\n",
            "Batch 2390: batch_loss=0.024680\n",
            "Batch 2400: batch_loss=0.024455\n",
            "Batch 2410: batch_loss=0.023751\n",
            "Batch 2420: batch_loss=0.023057\n",
            "Batch 2430: batch_loss=0.025096\n",
            "Batch 2440: batch_loss=0.029845\n",
            "Batch 2450: batch_loss=0.034459\n",
            "Batch 2460: batch_loss=0.025576\n",
            "Batch 2470: batch_loss=0.026119\n",
            "Batch 2480: batch_loss=0.023844\n",
            "Batch 2490: batch_loss=0.026670\n",
            "Batch 2500: batch_loss=0.029853\n",
            "Batch 2510: batch_loss=0.023990\n",
            "Batch 2520: batch_loss=0.030812\n",
            "Batch 2530: batch_loss=0.020355\n",
            "Batch 2540: batch_loss=0.023794\n",
            "Batch 2550: batch_loss=0.024997\n",
            "Batch 2560: batch_loss=0.032335\n",
            "Batch 2570: batch_loss=0.029038\n",
            "Batch 2580: batch_loss=0.021206\n",
            "Batch 2590: batch_loss=0.024572\n",
            "Batch 2600: batch_loss=0.023275\n",
            "Batch 2610: batch_loss=0.031024\n",
            "Batch 2620: batch_loss=0.024313\n",
            "Batch 2630: batch_loss=0.024266\n",
            "Batch 2640: batch_loss=0.018608\n",
            "Batch 2650: batch_loss=0.023937\n",
            "Batch 2660: batch_loss=0.021960\n",
            "Batch 2670: batch_loss=0.027496\n",
            "Batch 2680: batch_loss=0.026104\n",
            "Batch 2690: batch_loss=0.024872\n",
            "Batch 2700: batch_loss=0.029875\n",
            "Batch 2710: batch_loss=0.024596\n",
            "Batch 2720: batch_loss=0.030037\n",
            "Batch 2730: batch_loss=0.029304\n",
            "Batch 2740: batch_loss=0.024685\n",
            "Batch 2750: batch_loss=0.023048\n",
            "Batch 2760: batch_loss=0.023627\n",
            "Batch 2770: batch_loss=0.027026\n",
            "Batch 2780: batch_loss=0.033112\n",
            "Batch 2790: batch_loss=0.035084\n",
            "Batch 2800: batch_loss=0.028740\n",
            "Batch 2810: batch_loss=0.029192\n",
            "Batch 2820: batch_loss=0.030968\n",
            "Batch 2830: batch_loss=0.030406\n",
            "Batch 2840: batch_loss=0.025512\n",
            "Batch 2850: batch_loss=0.020972\n",
            "Batch 2860: batch_loss=0.031557\n",
            "Batch 2870: batch_loss=0.025969\n",
            "Batch 2880: batch_loss=0.031131\n",
            "Batch 2890: batch_loss=0.021264\n",
            "Batch 2900: batch_loss=0.026433\n",
            "Batch 2910: batch_loss=0.025004\n",
            "Batch 2920: batch_loss=0.026808\n",
            "Batch 2930: batch_loss=0.023120\n",
            "Batch 2940: batch_loss=0.024580\n",
            "Batch 2950: batch_loss=0.021667\n",
            "Batch 2960: batch_loss=0.028422\n",
            "Batch 2970: batch_loss=0.022974\n",
            "Batch 2980: batch_loss=0.033106\n",
            "Batch 2990: batch_loss=0.022373\n",
            "Batch 3000: batch_loss=0.030091\n",
            "Batch 3010: batch_loss=0.020767\n",
            "Batch 3020: batch_loss=0.029127\n",
            "Batch 3030: batch_loss=0.018538\n",
            "Batch 3040: batch_loss=0.022508\n",
            "Batch 3050: batch_loss=0.029089\n",
            "Batch 3060: batch_loss=0.023803\n",
            "Batch 3070: batch_loss=0.039065\n",
            "Batch 3080: batch_loss=0.024972\n",
            "Batch 3090: batch_loss=0.025579\n",
            "Batch 3100: batch_loss=0.027433\n",
            "Batch 3110: batch_loss=0.028890\n",
            "Batch 3120: batch_loss=0.031165\n",
            "Batch 3130: batch_loss=0.026701\n",
            "Batch 3140: batch_loss=0.030278\n",
            "Batch 3150: batch_loss=0.025138\n",
            "Batch 3160: batch_loss=0.030621\n",
            "Batch 3170: batch_loss=0.029453\n",
            "Batch 3180: batch_loss=0.026527\n",
            "Batch 3190: batch_loss=0.024831\n",
            "Batch 3200: batch_loss=0.029156\n",
            "Batch 3210: batch_loss=0.021818\n",
            "Batch 3220: batch_loss=0.028812\n",
            "Batch 3230: batch_loss=0.024797\n",
            "Batch 3240: batch_loss=0.024261\n",
            "Batch 3250: batch_loss=0.025863\n",
            "Batch 3260: batch_loss=0.031137\n",
            "Batch 3270: batch_loss=0.024616\n",
            "Batch 3280: batch_loss=0.030179\n",
            "Batch 3290: batch_loss=0.024216\n",
            "Batch 3300: batch_loss=0.024992\n",
            "Batch 3310: batch_loss=0.023504\n",
            "Batch 3320: batch_loss=0.031366\n",
            "Batch 3330: batch_loss=0.021264\n",
            "Batch 3340: batch_loss=0.026267\n",
            "Batch 3350: batch_loss=0.026704\n",
            "Batch 3360: batch_loss=0.032115\n",
            "Batch 3370: batch_loss=0.023013\n",
            "Batch 3380: batch_loss=0.030043\n",
            "Batch 3390: batch_loss=0.026542\n",
            "Batch 3400: batch_loss=0.028102\n",
            "Batch 3410: batch_loss=0.022319\n",
            "Batch 3420: batch_loss=0.029772\n",
            "Batch 3430: batch_loss=0.022289\n",
            "Batch 3440: batch_loss=0.027974\n",
            "Batch 3450: batch_loss=0.023364\n",
            "Batch 3460: batch_loss=0.029611\n",
            "Batch 3470: batch_loss=0.032169\n",
            "Batch 3480: batch_loss=0.023798\n",
            "Batch 3490: batch_loss=0.028340\n",
            "Batch 3500: batch_loss=0.025861\n",
            "Batch 3510: batch_loss=0.024342\n",
            "Batch 3520: batch_loss=0.024759\n",
            "Batch 3530: batch_loss=0.036847\n",
            "Batch 3540: batch_loss=0.019514\n",
            "Batch 3550: batch_loss=0.028181\n",
            "Batch 3560: batch_loss=0.028715\n",
            "Batch 3570: batch_loss=0.029241\n",
            "Batch 3580: batch_loss=0.024932\n",
            "Batch 3590: batch_loss=0.025469\n",
            "Batch 3600: batch_loss=0.023793\n",
            "Batch 3610: batch_loss=0.025628\n",
            "Batch 3620: batch_loss=0.025767\n",
            "Batch 3630: batch_loss=0.030936\n",
            "Batch 3640: batch_loss=0.021394\n",
            "Batch 3650: batch_loss=0.029072\n",
            "Batch 3660: batch_loss=0.028273\n",
            "Batch 3670: batch_loss=0.037253\n",
            "Batch 3680: batch_loss=0.028862\n",
            "Batch 3690: batch_loss=0.019179\n",
            "Batch 3700: batch_loss=0.023631\n",
            "Batch 3710: batch_loss=0.025294\n",
            "Batch 3720: batch_loss=0.025389\n",
            "Epoch 1/10, Train Loss: 0.047459, Val Loss: 0.016699\n",
            "Batch 0: batch_loss=0.025105\n",
            "Batch 10: batch_loss=0.032229\n",
            "Batch 20: batch_loss=0.037351\n",
            "Batch 30: batch_loss=0.024325\n",
            "Batch 40: batch_loss=0.027802\n",
            "Batch 50: batch_loss=0.031799\n",
            "Batch 60: batch_loss=0.026537\n",
            "Batch 70: batch_loss=0.029783\n",
            "Batch 80: batch_loss=0.029416\n",
            "Batch 90: batch_loss=0.030006\n",
            "Batch 100: batch_loss=0.029240\n",
            "Batch 110: batch_loss=0.025517\n",
            "Batch 120: batch_loss=0.025520\n",
            "Batch 130: batch_loss=0.021602\n",
            "Batch 140: batch_loss=0.025468\n",
            "Batch 150: batch_loss=0.023045\n",
            "Batch 160: batch_loss=0.024725\n",
            "Batch 170: batch_loss=0.025971\n",
            "Batch 180: batch_loss=0.022394\n",
            "Batch 190: batch_loss=0.022730\n",
            "Batch 200: batch_loss=0.029646\n",
            "Batch 210: batch_loss=0.029896\n",
            "Batch 220: batch_loss=0.034420\n",
            "Batch 230: batch_loss=0.024295\n",
            "Batch 240: batch_loss=0.025587\n",
            "Batch 250: batch_loss=0.027943\n",
            "Batch 260: batch_loss=0.023672\n",
            "Batch 270: batch_loss=0.028779\n",
            "Batch 280: batch_loss=0.026158\n",
            "Batch 290: batch_loss=0.027789\n",
            "Batch 300: batch_loss=0.029605\n",
            "Batch 310: batch_loss=0.022617\n",
            "Batch 320: batch_loss=0.029546\n",
            "Batch 330: batch_loss=0.027016\n",
            "Batch 340: batch_loss=0.020952\n",
            "Batch 350: batch_loss=0.029073\n",
            "Batch 360: batch_loss=0.023476\n",
            "Batch 370: batch_loss=0.027377\n",
            "Batch 380: batch_loss=0.031151\n",
            "Batch 390: batch_loss=0.026595\n",
            "Batch 400: batch_loss=0.029516\n",
            "Batch 410: batch_loss=0.029323\n",
            "Batch 420: batch_loss=0.026039\n",
            "Batch 430: batch_loss=0.024943\n",
            "Batch 440: batch_loss=0.022414\n",
            "Batch 450: batch_loss=0.031126\n",
            "Batch 460: batch_loss=0.031491\n",
            "Batch 470: batch_loss=0.030361\n",
            "Batch 480: batch_loss=0.021286\n",
            "Batch 490: batch_loss=0.024720\n",
            "Batch 500: batch_loss=0.026873\n",
            "Batch 510: batch_loss=0.030866\n",
            "Batch 520: batch_loss=0.028903\n",
            "Batch 530: batch_loss=0.025251\n",
            "Batch 540: batch_loss=0.023957\n",
            "Batch 550: batch_loss=0.025819\n",
            "Batch 560: batch_loss=0.023035\n",
            "Batch 570: batch_loss=0.034424\n",
            "Batch 580: batch_loss=0.030033\n",
            "Batch 590: batch_loss=0.025905\n",
            "Batch 600: batch_loss=0.025028\n",
            "Batch 610: batch_loss=0.024626\n",
            "Batch 620: batch_loss=0.022614\n",
            "Batch 630: batch_loss=0.023942\n",
            "Batch 640: batch_loss=0.024900\n",
            "Batch 650: batch_loss=0.026813\n",
            "Batch 660: batch_loss=0.025122\n",
            "Batch 670: batch_loss=0.030102\n",
            "Batch 680: batch_loss=0.028829\n",
            "Batch 690: batch_loss=0.028462\n",
            "Batch 700: batch_loss=0.023708\n",
            "Batch 710: batch_loss=0.026547\n",
            "Batch 720: batch_loss=0.021287\n",
            "Batch 730: batch_loss=0.025282\n",
            "Batch 740: batch_loss=0.024957\n",
            "Batch 750: batch_loss=0.022662\n",
            "Batch 760: batch_loss=0.024712\n",
            "Batch 770: batch_loss=0.029650\n",
            "Batch 780: batch_loss=0.018658\n",
            "Batch 790: batch_loss=0.020718\n",
            "Batch 800: batch_loss=0.023655\n",
            "Batch 810: batch_loss=0.022810\n",
            "Batch 820: batch_loss=0.028021\n",
            "Batch 830: batch_loss=0.027615\n",
            "Batch 840: batch_loss=0.024826\n",
            "Batch 850: batch_loss=0.030843\n",
            "Batch 860: batch_loss=0.031952\n",
            "Batch 870: batch_loss=0.025242\n",
            "Batch 880: batch_loss=0.024978\n",
            "Batch 890: batch_loss=0.023579\n",
            "Batch 900: batch_loss=0.025179\n",
            "Batch 910: batch_loss=0.030993\n",
            "Batch 920: batch_loss=0.030037\n",
            "Batch 930: batch_loss=0.025849\n",
            "Batch 940: batch_loss=0.025705\n",
            "Batch 950: batch_loss=0.029745\n",
            "Batch 960: batch_loss=0.027256\n",
            "Batch 970: batch_loss=0.023910\n",
            "Batch 980: batch_loss=0.020763\n",
            "Batch 990: batch_loss=0.022169\n",
            "Batch 1000: batch_loss=0.029115\n",
            "Batch 1010: batch_loss=0.029208\n",
            "Batch 1020: batch_loss=0.023613\n",
            "Batch 1030: batch_loss=0.025310\n",
            "Batch 1040: batch_loss=0.023941\n",
            "Batch 1050: batch_loss=0.023841\n",
            "Batch 1060: batch_loss=0.028581\n",
            "Batch 1070: batch_loss=0.026362\n",
            "Batch 1080: batch_loss=0.026002\n",
            "Batch 1090: batch_loss=0.023993\n",
            "Batch 1100: batch_loss=0.025571\n",
            "Batch 1110: batch_loss=0.023492\n",
            "Batch 1120: batch_loss=0.022960\n",
            "Batch 1130: batch_loss=0.021416\n",
            "Batch 1140: batch_loss=0.024653\n",
            "Batch 1150: batch_loss=0.021404\n",
            "Batch 1160: batch_loss=0.023122\n",
            "Batch 1170: batch_loss=0.025332\n",
            "Batch 1180: batch_loss=0.022402\n",
            "Batch 1190: batch_loss=0.025026\n",
            "Batch 1200: batch_loss=0.025084\n",
            "Batch 1210: batch_loss=0.029885\n",
            "Batch 1220: batch_loss=0.022971\n",
            "Batch 1230: batch_loss=0.024553\n",
            "Batch 1240: batch_loss=0.024740\n",
            "Batch 1250: batch_loss=0.029293\n",
            "Batch 1260: batch_loss=0.026677\n",
            "Batch 1270: batch_loss=0.027987\n",
            "Batch 1280: batch_loss=0.025435\n",
            "Batch 1290: batch_loss=0.028376\n",
            "Batch 1300: batch_loss=0.028570\n",
            "Batch 1310: batch_loss=0.023800\n",
            "Batch 1320: batch_loss=0.028143\n",
            "Batch 1330: batch_loss=0.021597\n",
            "Batch 1340: batch_loss=0.028733\n",
            "Batch 1350: batch_loss=0.025234\n",
            "Batch 1360: batch_loss=0.022492\n",
            "Batch 1370: batch_loss=0.023750\n",
            "Batch 1380: batch_loss=0.022012\n",
            "Batch 1390: batch_loss=0.032322\n",
            "Batch 1400: batch_loss=0.026914\n",
            "Batch 1410: batch_loss=0.026550\n",
            "Batch 1420: batch_loss=0.021192\n",
            "Batch 1430: batch_loss=0.029804\n",
            "Batch 1440: batch_loss=0.019772\n",
            "Batch 1450: batch_loss=0.021310\n",
            "Batch 1460: batch_loss=0.023490\n",
            "Batch 1470: batch_loss=0.027113\n",
            "Batch 1480: batch_loss=0.027760\n",
            "Batch 1490: batch_loss=0.025366\n",
            "Batch 1500: batch_loss=0.023223\n",
            "Batch 1510: batch_loss=0.026243\n",
            "Batch 1520: batch_loss=0.023279\n",
            "Batch 1530: batch_loss=0.027462\n",
            "Batch 1540: batch_loss=0.026582\n",
            "Batch 1550: batch_loss=0.023609\n",
            "Batch 1560: batch_loss=0.023507\n",
            "Batch 1570: batch_loss=0.020594\n",
            "Batch 1580: batch_loss=0.020206\n",
            "Batch 1590: batch_loss=0.028710\n",
            "Batch 1600: batch_loss=0.026522\n",
            "Batch 1610: batch_loss=0.022433\n",
            "Batch 1620: batch_loss=0.025880\n",
            "Batch 1630: batch_loss=0.029717\n",
            "Batch 1640: batch_loss=0.021941\n",
            "Batch 1650: batch_loss=0.025078\n",
            "Batch 1660: batch_loss=0.024539\n",
            "Batch 1670: batch_loss=0.027293\n",
            "Batch 1680: batch_loss=0.027841\n",
            "Batch 1690: batch_loss=0.023930\n",
            "Batch 1700: batch_loss=0.024957\n",
            "Batch 1710: batch_loss=0.029045\n",
            "Batch 1720: batch_loss=0.026728\n",
            "Batch 1730: batch_loss=0.025053\n",
            "Batch 1740: batch_loss=0.031142\n",
            "Batch 1750: batch_loss=0.035048\n",
            "Batch 1760: batch_loss=0.022008\n",
            "Batch 1770: batch_loss=0.025419\n",
            "Batch 1780: batch_loss=0.028765\n",
            "Batch 1790: batch_loss=0.024732\n",
            "Batch 1800: batch_loss=0.020748\n",
            "Batch 1810: batch_loss=0.026297\n",
            "Batch 1820: batch_loss=0.027466\n",
            "Batch 1830: batch_loss=0.027660\n",
            "Batch 1840: batch_loss=0.027009\n",
            "Batch 1850: batch_loss=0.022177\n",
            "Batch 1860: batch_loss=0.023873\n",
            "Batch 1870: batch_loss=0.028891\n",
            "Batch 1880: batch_loss=0.023163\n",
            "Batch 1890: batch_loss=0.025151\n",
            "Batch 1900: batch_loss=0.030112\n",
            "Batch 1910: batch_loss=0.023834\n",
            "Batch 1920: batch_loss=0.028903\n",
            "Batch 1930: batch_loss=0.021847\n",
            "Batch 1940: batch_loss=0.021956\n",
            "Batch 1950: batch_loss=0.023374\n",
            "Batch 1960: batch_loss=0.030071\n",
            "Batch 1970: batch_loss=0.029354\n",
            "Batch 1980: batch_loss=0.028444\n",
            "Batch 1990: batch_loss=0.029133\n",
            "Batch 2000: batch_loss=0.028442\n",
            "Batch 2010: batch_loss=0.022880\n",
            "Batch 2020: batch_loss=0.027893\n",
            "Batch 2030: batch_loss=0.027805\n",
            "Batch 2040: batch_loss=0.024972\n",
            "Batch 2050: batch_loss=0.026778\n",
            "Batch 2060: batch_loss=0.027301\n",
            "Batch 2070: batch_loss=0.026024\n",
            "Batch 2080: batch_loss=0.023796\n",
            "Batch 2090: batch_loss=0.024405\n",
            "Batch 2100: batch_loss=0.022825\n",
            "Batch 2110: batch_loss=0.021907\n",
            "Batch 2120: batch_loss=0.020502\n",
            "Batch 2130: batch_loss=0.024354\n",
            "Batch 2140: batch_loss=0.021619\n",
            "Batch 2150: batch_loss=0.026546\n",
            "Batch 2160: batch_loss=0.029778\n",
            "Batch 2170: batch_loss=0.022703\n",
            "Batch 2180: batch_loss=0.023948\n",
            "Batch 2190: batch_loss=0.028241\n",
            "Batch 2200: batch_loss=0.029565\n",
            "Batch 2210: batch_loss=0.028312\n",
            "Batch 2220: batch_loss=0.021734\n",
            "Batch 2230: batch_loss=0.026528\n",
            "Batch 2240: batch_loss=0.023500\n",
            "Batch 2250: batch_loss=0.028459\n",
            "Batch 2260: batch_loss=0.024642\n",
            "Batch 2270: batch_loss=0.027349\n",
            "Batch 2280: batch_loss=0.021998\n",
            "Batch 2290: batch_loss=0.021299\n",
            "Batch 2300: batch_loss=0.031773\n",
            "Batch 2310: batch_loss=0.026197\n",
            "Batch 2320: batch_loss=0.021447\n",
            "Batch 2330: batch_loss=0.019886\n",
            "Batch 2340: batch_loss=0.023559\n",
            "Batch 2350: batch_loss=0.028090\n",
            "Batch 2360: batch_loss=0.024306\n",
            "Batch 2370: batch_loss=0.035025\n",
            "Batch 2380: batch_loss=0.028138\n",
            "Batch 2390: batch_loss=0.029325\n",
            "Batch 2400: batch_loss=0.025546\n",
            "Batch 2410: batch_loss=0.027260\n",
            "Batch 2420: batch_loss=0.024901\n",
            "Batch 2430: batch_loss=0.032443\n",
            "Batch 2440: batch_loss=0.024320\n",
            "Batch 2450: batch_loss=0.034775\n",
            "Batch 2460: batch_loss=0.027247\n",
            "Batch 2470: batch_loss=0.026724\n",
            "Batch 2480: batch_loss=0.022703\n",
            "Batch 2490: batch_loss=0.028635\n",
            "Batch 2500: batch_loss=0.034019\n",
            "Batch 2510: batch_loss=0.019817\n",
            "Batch 2520: batch_loss=0.025747\n",
            "Batch 2530: batch_loss=0.030882\n",
            "Batch 2540: batch_loss=0.025668\n",
            "Batch 2550: batch_loss=0.027326\n",
            "Batch 2560: batch_loss=0.029913\n",
            "Batch 2570: batch_loss=0.023269\n",
            "Batch 2580: batch_loss=0.033348\n",
            "Batch 2590: batch_loss=0.026630\n",
            "Batch 2600: batch_loss=0.027879\n",
            "Batch 2610: batch_loss=0.022681\n",
            "Batch 2620: batch_loss=0.029200\n",
            "Batch 2630: batch_loss=0.032732\n",
            "Batch 2640: batch_loss=0.024407\n",
            "Batch 2650: batch_loss=0.033539\n",
            "Batch 2660: batch_loss=0.028951\n",
            "Batch 2670: batch_loss=0.026264\n",
            "Batch 2680: batch_loss=0.026060\n",
            "Batch 2690: batch_loss=0.025487\n",
            "Batch 2700: batch_loss=0.028489\n",
            "Batch 2710: batch_loss=0.027328\n",
            "Batch 2720: batch_loss=0.025232\n",
            "Batch 2730: batch_loss=0.021604\n",
            "Batch 2740: batch_loss=0.025697\n",
            "Batch 2750: batch_loss=0.026673\n",
            "Batch 2760: batch_loss=0.024524\n",
            "Batch 2770: batch_loss=0.025670\n",
            "Batch 2780: batch_loss=0.031042\n",
            "Batch 2790: batch_loss=0.026566\n",
            "Batch 2800: batch_loss=0.028151\n",
            "Batch 2810: batch_loss=0.030627\n",
            "Batch 2820: batch_loss=0.023068\n",
            "Batch 2830: batch_loss=0.023890\n",
            "Batch 2840: batch_loss=0.023487\n",
            "Batch 2850: batch_loss=0.025695\n",
            "Batch 2860: batch_loss=0.022270\n",
            "Batch 2870: batch_loss=0.026973\n",
            "Batch 2880: batch_loss=0.027680\n",
            "Batch 2890: batch_loss=0.035632\n",
            "Batch 2900: batch_loss=0.028208\n",
            "Batch 2910: batch_loss=0.023994\n",
            "Batch 2920: batch_loss=0.023674\n",
            "Batch 2930: batch_loss=0.025829\n",
            "Batch 2940: batch_loss=0.029981\n",
            "Batch 2950: batch_loss=0.027368\n",
            "Batch 2960: batch_loss=0.024686\n",
            "Batch 2970: batch_loss=0.033807\n",
            "Batch 2980: batch_loss=0.030896\n",
            "Batch 2990: batch_loss=0.031215\n",
            "Batch 3000: batch_loss=0.028340\n",
            "Batch 3010: batch_loss=0.024771\n",
            "Batch 3020: batch_loss=0.027280\n",
            "Batch 3030: batch_loss=0.025995\n",
            "Batch 3040: batch_loss=0.026886\n",
            "Batch 3050: batch_loss=0.023606\n",
            "Batch 3060: batch_loss=0.034879\n",
            "Batch 3070: batch_loss=0.022044\n",
            "Batch 3080: batch_loss=0.031632\n",
            "Batch 3090: batch_loss=0.026706\n",
            "Batch 3100: batch_loss=0.026989\n",
            "Batch 3110: batch_loss=0.026150\n",
            "Batch 3120: batch_loss=0.024127\n",
            "Batch 3130: batch_loss=0.025780\n",
            "Batch 3140: batch_loss=0.024497\n",
            "Batch 3150: batch_loss=0.022319\n",
            "Batch 3160: batch_loss=0.023117\n",
            "Batch 3170: batch_loss=0.030016\n",
            "Batch 3180: batch_loss=0.025485\n",
            "Batch 3190: batch_loss=0.023308\n",
            "Batch 3200: batch_loss=0.024466\n",
            "Batch 3210: batch_loss=0.023372\n",
            "Batch 3220: batch_loss=0.029607\n",
            "Batch 3230: batch_loss=0.024660\n",
            "Batch 3240: batch_loss=0.023694\n",
            "Batch 3250: batch_loss=0.021211\n",
            "Batch 3260: batch_loss=0.021775\n",
            "Batch 3270: batch_loss=0.028024\n",
            "Batch 3280: batch_loss=0.025381\n",
            "Batch 3290: batch_loss=0.026858\n",
            "Batch 3300: batch_loss=0.026386\n",
            "Batch 3310: batch_loss=0.029983\n",
            "Batch 3320: batch_loss=0.026675\n",
            "Batch 3330: batch_loss=0.030619\n",
            "Batch 3340: batch_loss=0.022691\n",
            "Batch 3350: batch_loss=0.027919\n",
            "Batch 3360: batch_loss=0.023356\n",
            "Batch 3370: batch_loss=0.024713\n",
            "Batch 3380: batch_loss=0.033736\n",
            "Batch 3390: batch_loss=0.028841\n",
            "Batch 3400: batch_loss=0.024984\n",
            "Batch 3410: batch_loss=0.027824\n",
            "Batch 3420: batch_loss=0.026449\n",
            "Batch 3430: batch_loss=0.024882\n",
            "Batch 3440: batch_loss=0.021827\n",
            "Batch 3450: batch_loss=0.027305\n",
            "Batch 3460: batch_loss=0.027001\n",
            "Batch 3470: batch_loss=0.029805\n",
            "Batch 3480: batch_loss=0.029500\n",
            "Batch 3490: batch_loss=0.025909\n",
            "Batch 3500: batch_loss=0.020977\n",
            "Batch 3510: batch_loss=0.033004\n",
            "Batch 3520: batch_loss=0.026592\n",
            "Batch 3530: batch_loss=0.027067\n",
            "Batch 3540: batch_loss=0.022640\n",
            "Batch 3550: batch_loss=0.025828\n",
            "Batch 3560: batch_loss=0.021991\n",
            "Batch 3570: batch_loss=0.020370\n",
            "Batch 3580: batch_loss=0.024501\n",
            "Batch 3590: batch_loss=0.031598\n",
            "Batch 3600: batch_loss=0.028331\n",
            "Batch 3610: batch_loss=0.027206\n",
            "Batch 3620: batch_loss=0.022679\n",
            "Batch 3630: batch_loss=0.027547\n",
            "Batch 3640: batch_loss=0.027943\n",
            "Batch 3650: batch_loss=0.027953\n",
            "Batch 3660: batch_loss=0.024215\n",
            "Batch 3670: batch_loss=0.029479\n",
            "Batch 3680: batch_loss=0.026708\n",
            "Batch 3690: batch_loss=0.022046\n",
            "Batch 3700: batch_loss=0.026534\n",
            "Batch 3710: batch_loss=0.028547\n",
            "Batch 3720: batch_loss=0.037945\n",
            "Epoch 2/10, Train Loss: 0.026667, Val Loss: 0.016640\n",
            "Batch 0: batch_loss=0.022261\n",
            "Batch 10: batch_loss=0.036276\n",
            "Batch 20: batch_loss=0.029389\n",
            "Batch 30: batch_loss=0.025072\n",
            "Batch 40: batch_loss=0.022043\n",
            "Batch 50: batch_loss=0.025229\n",
            "Batch 60: batch_loss=0.032695\n",
            "Batch 70: batch_loss=0.028794\n",
            "Batch 80: batch_loss=0.029294\n",
            "Batch 90: batch_loss=0.020908\n",
            "Batch 100: batch_loss=0.026657\n",
            "Batch 110: batch_loss=0.023343\n",
            "Batch 120: batch_loss=0.020018\n",
            "Batch 130: batch_loss=0.028252\n",
            "Batch 140: batch_loss=0.027406\n",
            "Batch 150: batch_loss=0.026280\n",
            "Batch 160: batch_loss=0.033480\n",
            "Batch 170: batch_loss=0.023095\n",
            "Batch 180: batch_loss=0.031685\n",
            "Batch 190: batch_loss=0.024421\n",
            "Batch 200: batch_loss=0.021524\n",
            "Batch 210: batch_loss=0.026898\n",
            "Batch 220: batch_loss=0.027016\n",
            "Batch 230: batch_loss=0.026338\n",
            "Batch 240: batch_loss=0.020442\n",
            "Batch 250: batch_loss=0.028832\n",
            "Batch 260: batch_loss=0.024883\n",
            "Batch 270: batch_loss=0.027748\n",
            "Batch 280: batch_loss=0.025536\n",
            "Batch 290: batch_loss=0.028399\n",
            "Batch 300: batch_loss=0.024496\n",
            "Batch 310: batch_loss=0.028805\n",
            "Batch 320: batch_loss=0.023024\n",
            "Batch 330: batch_loss=0.024084\n",
            "Batch 340: batch_loss=0.021720\n",
            "Batch 350: batch_loss=0.023399\n",
            "Batch 360: batch_loss=0.028189\n",
            "Batch 370: batch_loss=0.025776\n",
            "Batch 380: batch_loss=0.025662\n",
            "Batch 390: batch_loss=0.018702\n",
            "Batch 400: batch_loss=0.028396\n",
            "Batch 410: batch_loss=0.033099\n",
            "Batch 420: batch_loss=0.023956\n",
            "Batch 430: batch_loss=0.026534\n",
            "Batch 440: batch_loss=0.021227\n",
            "Batch 450: batch_loss=0.023411\n",
            "Batch 460: batch_loss=0.020507\n",
            "Batch 470: batch_loss=0.023576\n",
            "Batch 480: batch_loss=0.020965\n",
            "Batch 490: batch_loss=0.024379\n",
            "Batch 500: batch_loss=0.027091\n",
            "Batch 510: batch_loss=0.022405\n",
            "Batch 520: batch_loss=0.033379\n",
            "Batch 530: batch_loss=0.028226\n",
            "Batch 540: batch_loss=0.032704\n",
            "Batch 550: batch_loss=0.024433\n",
            "Batch 560: batch_loss=0.026913\n",
            "Batch 570: batch_loss=0.025669\n",
            "Batch 580: batch_loss=0.024973\n",
            "Batch 590: batch_loss=0.029110\n",
            "Batch 600: batch_loss=0.028629\n",
            "Batch 610: batch_loss=0.028842\n",
            "Batch 620: batch_loss=0.031809\n",
            "Batch 630: batch_loss=0.035101\n",
            "Batch 640: batch_loss=0.027781\n",
            "Batch 650: batch_loss=0.029519\n",
            "Batch 660: batch_loss=0.022866\n",
            "Batch 670: batch_loss=0.027224\n",
            "Batch 680: batch_loss=0.024034\n",
            "Batch 690: batch_loss=0.027576\n",
            "Batch 700: batch_loss=0.031866\n",
            "Batch 710: batch_loss=0.027062\n",
            "Batch 720: batch_loss=0.032951\n",
            "Batch 730: batch_loss=0.026345\n",
            "Batch 740: batch_loss=0.028823\n",
            "Batch 750: batch_loss=0.029573\n",
            "Batch 760: batch_loss=0.024063\n",
            "Batch 770: batch_loss=0.027197\n",
            "Batch 780: batch_loss=0.025068\n",
            "Batch 790: batch_loss=0.025494\n",
            "Batch 800: batch_loss=0.022258\n",
            "Batch 810: batch_loss=0.026965\n",
            "Batch 820: batch_loss=0.028210\n",
            "Batch 830: batch_loss=0.026701\n",
            "Batch 840: batch_loss=0.029269\n",
            "Batch 850: batch_loss=0.031471\n",
            "Batch 860: batch_loss=0.022971\n",
            "Batch 870: batch_loss=0.024250\n",
            "Batch 880: batch_loss=0.029068\n",
            "Batch 890: batch_loss=0.026609\n",
            "Batch 900: batch_loss=0.021529\n",
            "Batch 910: batch_loss=0.038547\n",
            "Batch 920: batch_loss=0.021675\n",
            "Batch 930: batch_loss=0.024998\n",
            "Batch 940: batch_loss=0.024700\n",
            "Batch 950: batch_loss=0.028755\n",
            "Batch 960: batch_loss=0.028615\n",
            "Batch 970: batch_loss=0.028126\n",
            "Batch 980: batch_loss=0.024354\n",
            "Batch 990: batch_loss=0.024833\n",
            "Batch 1000: batch_loss=0.024474\n",
            "Batch 1010: batch_loss=0.031059\n",
            "Batch 1020: batch_loss=0.026384\n",
            "Batch 1030: batch_loss=0.031945\n",
            "Batch 1040: batch_loss=0.026043\n",
            "Batch 1050: batch_loss=0.021820\n",
            "Batch 1060: batch_loss=0.032342\n",
            "Batch 1070: batch_loss=0.029563\n",
            "Batch 1080: batch_loss=0.021739\n",
            "Batch 1090: batch_loss=0.029645\n",
            "Batch 1100: batch_loss=0.024230\n",
            "Batch 1110: batch_loss=0.020575\n",
            "Batch 1120: batch_loss=0.029124\n",
            "Batch 1130: batch_loss=0.027102\n",
            "Batch 1140: batch_loss=0.021473\n",
            "Batch 1150: batch_loss=0.019874\n",
            "Batch 1160: batch_loss=0.025880\n",
            "Batch 1170: batch_loss=0.030333\n",
            "Batch 1180: batch_loss=0.024820\n",
            "Batch 1190: batch_loss=0.026732\n",
            "Batch 1200: batch_loss=0.023136\n",
            "Batch 1210: batch_loss=0.030627\n",
            "Batch 1220: batch_loss=0.025221\n",
            "Batch 1230: batch_loss=0.031389\n",
            "Batch 1240: batch_loss=0.029856\n",
            "Batch 1250: batch_loss=0.025986\n",
            "Batch 1260: batch_loss=0.020657\n",
            "Batch 1270: batch_loss=0.031413\n",
            "Batch 1280: batch_loss=0.025900\n",
            "Batch 1290: batch_loss=0.020903\n",
            "Batch 1300: batch_loss=0.028715\n",
            "Batch 1310: batch_loss=0.028717\n",
            "Batch 1320: batch_loss=0.027049\n",
            "Batch 1330: batch_loss=0.022202\n",
            "Batch 1340: batch_loss=0.025325\n",
            "Batch 1350: batch_loss=0.023638\n",
            "Batch 1360: batch_loss=0.026106\n",
            "Batch 1370: batch_loss=0.021785\n",
            "Batch 1380: batch_loss=0.024377\n",
            "Batch 1390: batch_loss=0.022944\n",
            "Batch 1400: batch_loss=0.026712\n",
            "Batch 1410: batch_loss=0.032696\n",
            "Batch 1420: batch_loss=0.027493\n",
            "Batch 1430: batch_loss=0.027836\n",
            "Batch 1440: batch_loss=0.032600\n",
            "Batch 1450: batch_loss=0.034662\n",
            "Batch 1460: batch_loss=0.029152\n",
            "Batch 1470: batch_loss=0.029876\n",
            "Batch 1480: batch_loss=0.025179\n",
            "Batch 1490: batch_loss=0.027118\n",
            "Batch 1500: batch_loss=0.035553\n",
            "Batch 1510: batch_loss=0.028603\n",
            "Batch 1520: batch_loss=0.027909\n",
            "Batch 1530: batch_loss=0.031989\n",
            "Batch 1540: batch_loss=0.026972\n",
            "Batch 1550: batch_loss=0.026000\n",
            "Batch 1560: batch_loss=0.028805\n",
            "Batch 1570: batch_loss=0.028082\n",
            "Batch 1580: batch_loss=0.025505\n",
            "Batch 1590: batch_loss=0.030312\n",
            "Batch 1600: batch_loss=0.026685\n",
            "Batch 1610: batch_loss=0.025806\n",
            "Batch 1620: batch_loss=0.021942\n",
            "Batch 1630: batch_loss=0.025135\n",
            "Batch 1640: batch_loss=0.027813\n",
            "Batch 1650: batch_loss=0.030839\n",
            "Batch 1660: batch_loss=0.020739\n",
            "Batch 1670: batch_loss=0.033729\n",
            "Batch 1680: batch_loss=0.021740\n",
            "Batch 1690: batch_loss=0.031811\n",
            "Batch 1700: batch_loss=0.020182\n",
            "Batch 1710: batch_loss=0.025769\n",
            "Batch 1720: batch_loss=0.022863\n",
            "Batch 1730: batch_loss=0.020949\n",
            "Batch 1740: batch_loss=0.028691\n",
            "Batch 1750: batch_loss=0.024832\n",
            "Batch 1760: batch_loss=0.021736\n",
            "Batch 1770: batch_loss=0.027380\n",
            "Batch 1780: batch_loss=0.031795\n",
            "Batch 1790: batch_loss=0.031690\n",
            "Batch 1800: batch_loss=0.030510\n",
            "Batch 1810: batch_loss=0.022702\n",
            "Batch 1820: batch_loss=0.025064\n",
            "Batch 1830: batch_loss=0.026869\n",
            "Batch 1840: batch_loss=0.030947\n",
            "Batch 1850: batch_loss=0.027894\n",
            "Batch 1860: batch_loss=0.034946\n",
            "Batch 1870: batch_loss=0.023870\n",
            "Batch 1880: batch_loss=0.024971\n",
            "Batch 1890: batch_loss=0.028100\n",
            "Batch 1900: batch_loss=0.030822\n",
            "Batch 1910: batch_loss=0.020598\n",
            "Batch 1920: batch_loss=0.028816\n",
            "Batch 1930: batch_loss=0.025796\n",
            "Batch 1940: batch_loss=0.027962\n",
            "Batch 1950: batch_loss=0.025182\n",
            "Batch 1960: batch_loss=0.021774\n",
            "Batch 1970: batch_loss=0.020255\n",
            "Batch 1980: batch_loss=0.030514\n",
            "Batch 1990: batch_loss=0.026754\n",
            "Batch 2000: batch_loss=0.031486\n",
            "Batch 2010: batch_loss=0.029894\n",
            "Batch 2020: batch_loss=0.031463\n",
            "Batch 2030: batch_loss=0.024684\n",
            "Batch 2040: batch_loss=0.020511\n",
            "Batch 2050: batch_loss=0.020682\n",
            "Batch 2060: batch_loss=0.024333\n",
            "Batch 2070: batch_loss=0.030076\n",
            "Batch 2080: batch_loss=0.025133\n",
            "Batch 2090: batch_loss=0.025018\n",
            "Batch 2100: batch_loss=0.032108\n",
            "Batch 2110: batch_loss=0.024102\n",
            "Batch 2120: batch_loss=0.025656\n",
            "Batch 2130: batch_loss=0.023997\n",
            "Batch 2140: batch_loss=0.022744\n",
            "Batch 2150: batch_loss=0.029200\n",
            "Batch 2160: batch_loss=0.029862\n",
            "Batch 2170: batch_loss=0.027522\n",
            "Batch 2180: batch_loss=0.020086\n",
            "Batch 2190: batch_loss=0.031324\n",
            "Batch 2200: batch_loss=0.028852\n",
            "Batch 2210: batch_loss=0.026898\n",
            "Batch 2220: batch_loss=0.023237\n",
            "Batch 2230: batch_loss=0.022080\n",
            "Batch 2240: batch_loss=0.027640\n",
            "Batch 2250: batch_loss=0.026209\n",
            "Batch 2260: batch_loss=0.035250\n",
            "Batch 2270: batch_loss=0.023451\n",
            "Batch 2280: batch_loss=0.031755\n",
            "Batch 2290: batch_loss=0.022155\n",
            "Batch 2300: batch_loss=0.026450\n",
            "Batch 2310: batch_loss=0.025548\n",
            "Batch 2320: batch_loss=0.027197\n",
            "Batch 2330: batch_loss=0.030134\n",
            "Batch 2340: batch_loss=0.021273\n",
            "Batch 2350: batch_loss=0.020968\n",
            "Batch 2360: batch_loss=0.028786\n",
            "Batch 2370: batch_loss=0.020807\n",
            "Batch 2380: batch_loss=0.028145\n",
            "Batch 2390: batch_loss=0.026983\n",
            "Batch 2400: batch_loss=0.024230\n",
            "Batch 2410: batch_loss=0.022982\n",
            "Batch 2420: batch_loss=0.028214\n",
            "Batch 2430: batch_loss=0.022405\n",
            "Batch 2440: batch_loss=0.028143\n",
            "Batch 2450: batch_loss=0.023877\n",
            "Batch 2460: batch_loss=0.030325\n",
            "Batch 2470: batch_loss=0.022955\n",
            "Batch 2480: batch_loss=0.026378\n",
            "Batch 2490: batch_loss=0.021541\n",
            "Batch 2500: batch_loss=0.031421\n",
            "Batch 2510: batch_loss=0.032180\n",
            "Batch 2520: batch_loss=0.027035\n",
            "Batch 2530: batch_loss=0.022522\n",
            "Batch 2540: batch_loss=0.028358\n",
            "Batch 2550: batch_loss=0.024445\n",
            "Batch 2560: batch_loss=0.029031\n",
            "Batch 2570: batch_loss=0.027584\n",
            "Batch 2580: batch_loss=0.032037\n",
            "Batch 2590: batch_loss=0.024289\n",
            "Batch 2600: batch_loss=0.020795\n",
            "Batch 2610: batch_loss=0.029636\n",
            "Batch 2620: batch_loss=0.024624\n",
            "Batch 2630: batch_loss=0.028475\n",
            "Batch 2640: batch_loss=0.023831\n",
            "Batch 2650: batch_loss=0.032884\n",
            "Batch 2660: batch_loss=0.023552\n",
            "Batch 2670: batch_loss=0.029314\n",
            "Batch 2680: batch_loss=0.025162\n",
            "Batch 2690: batch_loss=0.023294\n",
            "Batch 2700: batch_loss=0.028302\n",
            "Batch 2710: batch_loss=0.025326\n",
            "Batch 2720: batch_loss=0.021080\n",
            "Batch 2730: batch_loss=0.027327\n",
            "Batch 2740: batch_loss=0.028063\n",
            "Batch 2750: batch_loss=0.024449\n",
            "Batch 2760: batch_loss=0.024918\n",
            "Batch 2770: batch_loss=0.027623\n",
            "Batch 2780: batch_loss=0.023953\n",
            "Batch 2790: batch_loss=0.024461\n",
            "Batch 2800: batch_loss=0.028826\n",
            "Batch 2810: batch_loss=0.022859\n",
            "Batch 2820: batch_loss=0.026963\n",
            "Batch 2830: batch_loss=0.027894\n",
            "Batch 2840: batch_loss=0.024962\n",
            "Batch 2850: batch_loss=0.025542\n",
            "Batch 2860: batch_loss=0.029411\n",
            "Batch 2870: batch_loss=0.030831\n",
            "Batch 2880: batch_loss=0.022549\n",
            "Batch 2890: batch_loss=0.028923\n",
            "Batch 2900: batch_loss=0.026379\n",
            "Batch 2910: batch_loss=0.028212\n",
            "Batch 2920: batch_loss=0.027905\n",
            "Batch 2930: batch_loss=0.028636\n",
            "Batch 2940: batch_loss=0.032388\n",
            "Batch 2950: batch_loss=0.023096\n",
            "Batch 2960: batch_loss=0.024392\n",
            "Batch 2970: batch_loss=0.020511\n",
            "Batch 2980: batch_loss=0.027692\n",
            "Batch 2990: batch_loss=0.027739\n",
            "Batch 3000: batch_loss=0.025944\n",
            "Batch 3010: batch_loss=0.024303\n",
            "Batch 3020: batch_loss=0.025617\n",
            "Batch 3030: batch_loss=0.030070\n",
            "Batch 3040: batch_loss=0.026195\n",
            "Batch 3050: batch_loss=0.022031\n",
            "Batch 3060: batch_loss=0.027803\n",
            "Batch 3070: batch_loss=0.034696\n",
            "Batch 3080: batch_loss=0.022061\n",
            "Batch 3090: batch_loss=0.030575\n",
            "Batch 3100: batch_loss=0.025385\n",
            "Batch 3110: batch_loss=0.035794\n",
            "Batch 3120: batch_loss=0.023268\n",
            "Batch 3130: batch_loss=0.031727\n",
            "Batch 3140: batch_loss=0.027143\n",
            "Batch 3150: batch_loss=0.023190\n",
            "Batch 3160: batch_loss=0.026867\n",
            "Batch 3170: batch_loss=0.025558\n",
            "Batch 3180: batch_loss=0.030101\n",
            "Batch 3190: batch_loss=0.032227\n",
            "Batch 3200: batch_loss=0.023185\n",
            "Batch 3210: batch_loss=0.020162\n",
            "Batch 3220: batch_loss=0.025668\n",
            "Batch 3230: batch_loss=0.021652\n",
            "Batch 3240: batch_loss=0.024785\n",
            "Batch 3250: batch_loss=0.029660\n",
            "Batch 3260: batch_loss=0.027044\n",
            "Batch 3270: batch_loss=0.028446\n",
            "Batch 3280: batch_loss=0.027050\n",
            "Batch 3290: batch_loss=0.020279\n",
            "Batch 3300: batch_loss=0.029029\n",
            "Batch 3310: batch_loss=0.022669\n",
            "Batch 3320: batch_loss=0.032897\n",
            "Batch 3330: batch_loss=0.026365\n",
            "Batch 3340: batch_loss=0.029997\n",
            "Batch 3350: batch_loss=0.031651\n",
            "Batch 3360: batch_loss=0.025982\n",
            "Batch 3370: batch_loss=0.021960\n",
            "Batch 3380: batch_loss=0.023255\n",
            "Batch 3390: batch_loss=0.030235\n",
            "Batch 3400: batch_loss=0.036811\n",
            "Batch 3410: batch_loss=0.022914\n",
            "Batch 3420: batch_loss=0.024965\n",
            "Batch 3430: batch_loss=0.031296\n",
            "Batch 3440: batch_loss=0.028359\n",
            "Batch 3450: batch_loss=0.023254\n",
            "Batch 3460: batch_loss=0.027817\n",
            "Batch 3470: batch_loss=0.024209\n",
            "Batch 3480: batch_loss=0.026037\n",
            "Batch 3490: batch_loss=0.033578\n",
            "Batch 3500: batch_loss=0.028568\n",
            "Batch 3510: batch_loss=0.021944\n",
            "Batch 3520: batch_loss=0.024056\n",
            "Batch 3530: batch_loss=0.027932\n",
            "Batch 3540: batch_loss=0.031369\n",
            "Batch 3550: batch_loss=0.025075\n",
            "Batch 3560: batch_loss=0.033391\n",
            "Batch 3570: batch_loss=0.024962\n",
            "Batch 3580: batch_loss=0.023384\n",
            "Batch 3590: batch_loss=0.026946\n",
            "Batch 3600: batch_loss=0.021987\n",
            "Batch 3610: batch_loss=0.031953\n",
            "Batch 3620: batch_loss=0.030685\n",
            "Batch 3630: batch_loss=0.023474\n",
            "Batch 3640: batch_loss=0.021973\n",
            "Batch 3650: batch_loss=0.025583\n",
            "Batch 3660: batch_loss=0.023310\n",
            "Batch 3670: batch_loss=0.028041\n",
            "Batch 3680: batch_loss=0.022537\n",
            "Batch 3690: batch_loss=0.024985\n",
            "Batch 3700: batch_loss=0.022719\n",
            "Batch 3710: batch_loss=0.021787\n",
            "Batch 3720: batch_loss=0.026471\n",
            "Epoch 3/10, Train Loss: 0.026656, Val Loss: 0.016634\n",
            "Batch 0: batch_loss=0.030050\n",
            "Batch 10: batch_loss=0.024541\n",
            "Batch 20: batch_loss=0.025258\n",
            "Batch 30: batch_loss=0.024298\n",
            "Batch 40: batch_loss=0.028147\n",
            "Batch 50: batch_loss=0.022698\n",
            "Batch 60: batch_loss=0.029645\n",
            "Batch 70: batch_loss=0.022926\n",
            "Batch 80: batch_loss=0.032088\n",
            "Batch 90: batch_loss=0.029740\n",
            "Batch 100: batch_loss=0.032358\n",
            "Batch 110: batch_loss=0.020479\n",
            "Batch 120: batch_loss=0.028563\n",
            "Batch 130: batch_loss=0.024611\n",
            "Batch 140: batch_loss=0.029737\n",
            "Batch 150: batch_loss=0.024876\n",
            "Batch 160: batch_loss=0.027292\n",
            "Batch 170: batch_loss=0.028651\n",
            "Batch 180: batch_loss=0.026884\n",
            "Batch 190: batch_loss=0.030297\n",
            "Batch 200: batch_loss=0.028325\n",
            "Batch 210: batch_loss=0.023281\n",
            "Batch 220: batch_loss=0.025791\n",
            "Batch 230: batch_loss=0.027948\n",
            "Batch 240: batch_loss=0.025267\n",
            "Batch 250: batch_loss=0.021995\n",
            "Batch 260: batch_loss=0.024882\n",
            "Batch 270: batch_loss=0.027420\n",
            "Batch 280: batch_loss=0.028039\n",
            "Batch 290: batch_loss=0.029282\n",
            "Batch 300: batch_loss=0.026432\n",
            "Batch 310: batch_loss=0.032495\n",
            "Batch 320: batch_loss=0.026530\n",
            "Batch 330: batch_loss=0.028180\n",
            "Batch 340: batch_loss=0.021585\n",
            "Batch 350: batch_loss=0.020366\n",
            "Batch 360: batch_loss=0.026567\n",
            "Batch 370: batch_loss=0.030405\n",
            "Batch 380: batch_loss=0.026599\n",
            "Batch 390: batch_loss=0.028708\n",
            "Batch 400: batch_loss=0.025335\n",
            "Batch 410: batch_loss=0.022363\n",
            "Batch 420: batch_loss=0.027416\n",
            "Batch 430: batch_loss=0.037114\n",
            "Batch 440: batch_loss=0.029136\n",
            "Batch 450: batch_loss=0.025638\n",
            "Batch 460: batch_loss=0.025248\n",
            "Batch 470: batch_loss=0.019579\n",
            "Batch 480: batch_loss=0.022576\n",
            "Batch 490: batch_loss=0.029620\n",
            "Batch 500: batch_loss=0.034440\n",
            "Batch 510: batch_loss=0.023257\n",
            "Batch 520: batch_loss=0.026673\n",
            "Batch 530: batch_loss=0.026619\n",
            "Batch 540: batch_loss=0.024118\n",
            "Batch 550: batch_loss=0.028512\n",
            "Batch 560: batch_loss=0.030777\n",
            "Batch 570: batch_loss=0.024748\n",
            "Batch 580: batch_loss=0.025742\n",
            "Batch 590: batch_loss=0.020978\n",
            "Batch 600: batch_loss=0.027760\n",
            "Batch 610: batch_loss=0.023395\n",
            "Batch 620: batch_loss=0.026094\n",
            "Batch 630: batch_loss=0.022396\n",
            "Batch 640: batch_loss=0.025223\n",
            "Batch 650: batch_loss=0.030743\n",
            "Batch 660: batch_loss=0.027872\n",
            "Batch 670: batch_loss=0.026372\n",
            "Batch 680: batch_loss=0.031437\n",
            "Batch 690: batch_loss=0.023169\n",
            "Batch 700: batch_loss=0.026011\n",
            "Batch 710: batch_loss=0.027146\n",
            "Batch 720: batch_loss=0.026799\n",
            "Batch 730: batch_loss=0.029151\n",
            "Batch 740: batch_loss=0.028192\n",
            "Batch 750: batch_loss=0.032536\n",
            "Batch 760: batch_loss=0.030605\n",
            "Batch 770: batch_loss=0.030748\n",
            "Batch 780: batch_loss=0.026150\n",
            "Batch 790: batch_loss=0.024016\n",
            "Batch 800: batch_loss=0.026071\n",
            "Batch 810: batch_loss=0.026537\n",
            "Batch 820: batch_loss=0.021693\n",
            "Batch 830: batch_loss=0.026596\n",
            "Batch 840: batch_loss=0.021665\n",
            "Batch 850: batch_loss=0.020413\n",
            "Batch 860: batch_loss=0.026202\n",
            "Batch 870: batch_loss=0.022892\n",
            "Batch 880: batch_loss=0.030655\n",
            "Batch 890: batch_loss=0.029903\n",
            "Batch 900: batch_loss=0.022140\n",
            "Batch 910: batch_loss=0.026042\n",
            "Batch 920: batch_loss=0.022825\n",
            "Batch 930: batch_loss=0.033323\n",
            "Batch 940: batch_loss=0.028322\n",
            "Batch 950: batch_loss=0.027371\n",
            "Batch 960: batch_loss=0.025927\n",
            "Batch 970: batch_loss=0.027068\n",
            "Batch 980: batch_loss=0.024216\n",
            "Batch 990: batch_loss=0.029181\n",
            "Batch 1000: batch_loss=0.025257\n",
            "Batch 1010: batch_loss=0.026225\n",
            "Batch 1020: batch_loss=0.029362\n",
            "Batch 1030: batch_loss=0.021362\n",
            "Batch 1040: batch_loss=0.025054\n",
            "Batch 1050: batch_loss=0.031011\n",
            "Batch 1060: batch_loss=0.021450\n",
            "Batch 1070: batch_loss=0.022024\n",
            "Batch 1080: batch_loss=0.034807\n",
            "Batch 1090: batch_loss=0.025500\n",
            "Batch 1100: batch_loss=0.025298\n",
            "Batch 1110: batch_loss=0.026182\n",
            "Batch 1120: batch_loss=0.023763\n",
            "Batch 1130: batch_loss=0.031535\n",
            "Batch 1140: batch_loss=0.029808\n",
            "Batch 1150: batch_loss=0.027500\n",
            "Batch 1160: batch_loss=0.032193\n",
            "Batch 1170: batch_loss=0.029966\n",
            "Batch 1180: batch_loss=0.025838\n",
            "Batch 1190: batch_loss=0.026807\n",
            "Batch 1200: batch_loss=0.026752\n",
            "Batch 1210: batch_loss=0.023840\n",
            "Batch 1220: batch_loss=0.023588\n",
            "Batch 1230: batch_loss=0.025898\n",
            "Batch 1240: batch_loss=0.021320\n",
            "Batch 1250: batch_loss=0.028388\n",
            "Batch 1260: batch_loss=0.027255\n",
            "Batch 1270: batch_loss=0.026513\n",
            "Batch 1280: batch_loss=0.029206\n",
            "Batch 1290: batch_loss=0.023315\n",
            "Batch 1300: batch_loss=0.021528\n",
            "Batch 1310: batch_loss=0.020806\n",
            "Batch 1320: batch_loss=0.022972\n",
            "Batch 1330: batch_loss=0.028612\n",
            "Batch 1340: batch_loss=0.028384\n",
            "Batch 1350: batch_loss=0.024835\n",
            "Batch 1360: batch_loss=0.024616\n",
            "Batch 1370: batch_loss=0.026206\n",
            "Batch 1380: batch_loss=0.027099\n",
            "Batch 1390: batch_loss=0.029098\n",
            "Batch 1400: batch_loss=0.030580\n",
            "Batch 1410: batch_loss=0.027070\n",
            "Batch 1420: batch_loss=0.029781\n",
            "Batch 1430: batch_loss=0.023025\n",
            "Batch 1440: batch_loss=0.023023\n",
            "Batch 1450: batch_loss=0.024770\n",
            "Batch 1460: batch_loss=0.033232\n",
            "Batch 1470: batch_loss=0.020519\n",
            "Batch 1480: batch_loss=0.023649\n",
            "Batch 1490: batch_loss=0.023560\n",
            "Batch 1500: batch_loss=0.023615\n",
            "Batch 1510: batch_loss=0.023833\n",
            "Batch 1520: batch_loss=0.032376\n",
            "Batch 1530: batch_loss=0.027791\n",
            "Batch 1540: batch_loss=0.024883\n",
            "Batch 1550: batch_loss=0.024460\n",
            "Batch 1560: batch_loss=0.026873\n",
            "Batch 1570: batch_loss=0.020633\n",
            "Batch 1580: batch_loss=0.026466\n",
            "Batch 1590: batch_loss=0.032606\n",
            "Batch 1600: batch_loss=0.025672\n",
            "Batch 1610: batch_loss=0.026182\n",
            "Batch 1620: batch_loss=0.026112\n",
            "Batch 1630: batch_loss=0.030067\n",
            "Batch 1640: batch_loss=0.027218\n",
            "Batch 1650: batch_loss=0.027548\n",
            "Batch 1660: batch_loss=0.024162\n",
            "Batch 1670: batch_loss=0.027320\n",
            "Batch 1680: batch_loss=0.025418\n",
            "Batch 1690: batch_loss=0.024545\n",
            "Batch 1700: batch_loss=0.025396\n",
            "Batch 1710: batch_loss=0.023224\n",
            "Batch 1720: batch_loss=0.023262\n",
            "Batch 1730: batch_loss=0.022149\n",
            "Batch 1740: batch_loss=0.028622\n",
            "Batch 1750: batch_loss=0.027223\n",
            "Batch 1760: batch_loss=0.036108\n",
            "Batch 1770: batch_loss=0.021660\n",
            "Batch 1780: batch_loss=0.021804\n",
            "Batch 1790: batch_loss=0.023601\n",
            "Batch 1800: batch_loss=0.027718\n",
            "Batch 1810: batch_loss=0.028726\n",
            "Batch 1820: batch_loss=0.024867\n",
            "Batch 1830: batch_loss=0.033512\n",
            "Batch 1840: batch_loss=0.033483\n",
            "Batch 1850: batch_loss=0.028723\n",
            "Batch 1860: batch_loss=0.026172\n",
            "Batch 1870: batch_loss=0.026818\n",
            "Batch 1880: batch_loss=0.022053\n",
            "Batch 1890: batch_loss=0.025589\n",
            "Batch 1900: batch_loss=0.022830\n",
            "Batch 1910: batch_loss=0.023483\n",
            "Batch 1920: batch_loss=0.031212\n",
            "Batch 1930: batch_loss=0.026335\n",
            "Batch 1940: batch_loss=0.032554\n",
            "Batch 1950: batch_loss=0.026799\n",
            "Batch 1960: batch_loss=0.027844\n",
            "Batch 1970: batch_loss=0.033463\n",
            "Batch 1980: batch_loss=0.026445\n",
            "Batch 1990: batch_loss=0.032336\n",
            "Batch 2000: batch_loss=0.022902\n",
            "Batch 2010: batch_loss=0.033955\n",
            "Batch 2020: batch_loss=0.029108\n",
            "Batch 2030: batch_loss=0.026067\n",
            "Batch 2040: batch_loss=0.024683\n",
            "Batch 2050: batch_loss=0.028774\n",
            "Batch 2060: batch_loss=0.032113\n",
            "Batch 2070: batch_loss=0.023802\n",
            "Batch 2080: batch_loss=0.028780\n",
            "Batch 2090: batch_loss=0.028615\n",
            "Batch 2100: batch_loss=0.032108\n",
            "Batch 2110: batch_loss=0.025949\n",
            "Batch 2120: batch_loss=0.020690\n",
            "Batch 2130: batch_loss=0.038589\n",
            "Batch 2140: batch_loss=0.023126\n",
            "Batch 2150: batch_loss=0.025147\n",
            "Batch 2160: batch_loss=0.023469\n",
            "Batch 2170: batch_loss=0.024550\n",
            "Batch 2180: batch_loss=0.021687\n",
            "Batch 2190: batch_loss=0.033135\n",
            "Batch 2200: batch_loss=0.023704\n",
            "Batch 2210: batch_loss=0.031167\n",
            "Batch 2220: batch_loss=0.030836\n",
            "Batch 2230: batch_loss=0.023416\n",
            "Batch 2240: batch_loss=0.030001\n",
            "Batch 2250: batch_loss=0.028275\n",
            "Batch 2260: batch_loss=0.025311\n",
            "Batch 2270: batch_loss=0.026603\n",
            "Batch 2280: batch_loss=0.030530\n",
            "Batch 2290: batch_loss=0.031320\n",
            "Batch 2300: batch_loss=0.024000\n",
            "Batch 2310: batch_loss=0.028535\n",
            "Batch 2320: batch_loss=0.023207\n",
            "Batch 2330: batch_loss=0.032592\n",
            "Batch 2340: batch_loss=0.024265\n",
            "Batch 2350: batch_loss=0.023570\n",
            "Batch 2360: batch_loss=0.026407\n",
            "Batch 2370: batch_loss=0.025699\n",
            "Batch 2380: batch_loss=0.030818\n",
            "Batch 2390: batch_loss=0.023940\n",
            "Batch 2400: batch_loss=0.030105\n",
            "Batch 2410: batch_loss=0.022868\n",
            "Batch 2420: batch_loss=0.023504\n",
            "Batch 2430: batch_loss=0.028595\n",
            "Batch 2440: batch_loss=0.019264\n",
            "Batch 2450: batch_loss=0.026892\n",
            "Batch 2460: batch_loss=0.024275\n",
            "Batch 2470: batch_loss=0.029048\n",
            "Batch 2480: batch_loss=0.021952\n",
            "Batch 2490: batch_loss=0.021929\n",
            "Batch 2500: batch_loss=0.026095\n",
            "Batch 2510: batch_loss=0.026644\n",
            "Batch 2520: batch_loss=0.025450\n",
            "Batch 2530: batch_loss=0.030063\n",
            "Batch 2540: batch_loss=0.022382\n",
            "Batch 2550: batch_loss=0.023658\n",
            "Batch 2560: batch_loss=0.019788\n",
            "Batch 2570: batch_loss=0.034143\n",
            "Batch 2580: batch_loss=0.028606\n",
            "Batch 2590: batch_loss=0.027577\n",
            "Batch 2600: batch_loss=0.021594\n",
            "Batch 2610: batch_loss=0.024041\n",
            "Batch 2620: batch_loss=0.029087\n",
            "Batch 2630: batch_loss=0.023224\n",
            "Batch 2640: batch_loss=0.035230\n",
            "Batch 2650: batch_loss=0.022146\n",
            "Batch 2660: batch_loss=0.034824\n",
            "Batch 2670: batch_loss=0.026236\n",
            "Batch 2680: batch_loss=0.032204\n",
            "Batch 2690: batch_loss=0.024552\n",
            "Batch 2700: batch_loss=0.028025\n",
            "Batch 2710: batch_loss=0.019335\n",
            "Batch 2720: batch_loss=0.022601\n",
            "Batch 2730: batch_loss=0.033016\n",
            "Batch 2740: batch_loss=0.029831\n",
            "Batch 2750: batch_loss=0.026001\n",
            "Batch 2760: batch_loss=0.022462\n",
            "Batch 2770: batch_loss=0.022996\n",
            "Batch 2780: batch_loss=0.025765\n",
            "Batch 2790: batch_loss=0.032383\n",
            "Batch 2800: batch_loss=0.028951\n",
            "Batch 2810: batch_loss=0.025360\n",
            "Batch 2820: batch_loss=0.025072\n",
            "Batch 2830: batch_loss=0.036148\n",
            "Batch 2840: batch_loss=0.023087\n",
            "Batch 2850: batch_loss=0.028585\n",
            "Batch 2860: batch_loss=0.023802\n",
            "Batch 2870: batch_loss=0.029006\n",
            "Batch 2880: batch_loss=0.027922\n",
            "Batch 2890: batch_loss=0.028121\n",
            "Batch 2900: batch_loss=0.023255\n",
            "Batch 2910: batch_loss=0.021974\n",
            "Batch 2920: batch_loss=0.023338\n",
            "Batch 2930: batch_loss=0.027747\n",
            "Batch 2940: batch_loss=0.027688\n",
            "Batch 2950: batch_loss=0.028799\n",
            "Batch 2960: batch_loss=0.026058\n",
            "Batch 2970: batch_loss=0.024848\n",
            "Batch 2980: batch_loss=0.028735\n",
            "Batch 2990: batch_loss=0.024021\n",
            "Batch 3000: batch_loss=0.027853\n",
            "Batch 3010: batch_loss=0.022703\n",
            "Batch 3020: batch_loss=0.028995\n",
            "Batch 3030: batch_loss=0.032775\n",
            "Batch 3040: batch_loss=0.026378\n",
            "Batch 3050: batch_loss=0.020008\n",
            "Batch 3060: batch_loss=0.031583\n",
            "Batch 3070: batch_loss=0.033724\n",
            "Batch 3080: batch_loss=0.027942\n",
            "Batch 3090: batch_loss=0.028981\n",
            "Batch 3100: batch_loss=0.026287\n",
            "Batch 3110: batch_loss=0.021079\n",
            "Batch 3120: batch_loss=0.032711\n",
            "Batch 3130: batch_loss=0.030372\n",
            "Batch 3140: batch_loss=0.023616\n",
            "Batch 3150: batch_loss=0.023290\n",
            "Batch 3160: batch_loss=0.023405\n",
            "Batch 3170: batch_loss=0.022972\n",
            "Batch 3180: batch_loss=0.023264\n",
            "Batch 3190: batch_loss=0.023895\n",
            "Batch 3200: batch_loss=0.024158\n",
            "Batch 3210: batch_loss=0.022169\n",
            "Batch 3220: batch_loss=0.021734\n",
            "Batch 3230: batch_loss=0.025250\n",
            "Batch 3240: batch_loss=0.031290\n",
            "Batch 3250: batch_loss=0.022932\n",
            "Batch 3260: batch_loss=0.022748\n",
            "Batch 3270: batch_loss=0.023482\n",
            "Batch 3280: batch_loss=0.029201\n",
            "Batch 3290: batch_loss=0.030609\n",
            "Batch 3300: batch_loss=0.026987\n",
            "Batch 3310: batch_loss=0.020941\n",
            "Batch 3320: batch_loss=0.028373\n",
            "Batch 3330: batch_loss=0.038513\n",
            "Batch 3340: batch_loss=0.025961\n",
            "Batch 3350: batch_loss=0.027159\n",
            "Batch 3360: batch_loss=0.027980\n",
            "Batch 3370: batch_loss=0.023448\n",
            "Batch 3380: batch_loss=0.032769\n",
            "Batch 3390: batch_loss=0.032214\n",
            "Batch 3400: batch_loss=0.023916\n",
            "Batch 3410: batch_loss=0.022424\n",
            "Batch 3420: batch_loss=0.028191\n",
            "Batch 3430: batch_loss=0.026766\n",
            "Batch 3440: batch_loss=0.021956\n",
            "Batch 3450: batch_loss=0.023288\n",
            "Batch 3460: batch_loss=0.025355\n",
            "Batch 3470: batch_loss=0.022555\n",
            "Batch 3480: batch_loss=0.026939\n",
            "Batch 3490: batch_loss=0.020549\n",
            "Batch 3500: batch_loss=0.024844\n",
            "Batch 3510: batch_loss=0.024914\n",
            "Batch 3520: batch_loss=0.034009\n",
            "Batch 3530: batch_loss=0.029797\n",
            "Batch 3540: batch_loss=0.028906\n",
            "Batch 3550: batch_loss=0.019870\n",
            "Batch 3560: batch_loss=0.030373\n",
            "Batch 3570: batch_loss=0.027691\n",
            "Batch 3580: batch_loss=0.032039\n",
            "Batch 3590: batch_loss=0.029599\n",
            "Batch 3600: batch_loss=0.026228\n",
            "Batch 3610: batch_loss=0.025810\n",
            "Batch 3620: batch_loss=0.030221\n",
            "Batch 3630: batch_loss=0.022044\n",
            "Batch 3640: batch_loss=0.032192\n",
            "Batch 3650: batch_loss=0.024321\n",
            "Batch 3660: batch_loss=0.023854\n",
            "Batch 3670: batch_loss=0.022381\n",
            "Batch 3680: batch_loss=0.028486\n",
            "Batch 3690: batch_loss=0.029976\n",
            "Batch 3700: batch_loss=0.036246\n",
            "Batch 3710: batch_loss=0.029299\n",
            "Batch 3720: batch_loss=0.029045\n",
            "Epoch 4/10, Train Loss: 0.026652, Val Loss: 0.016632\n",
            "Batch 0: batch_loss=0.031354\n",
            "Batch 10: batch_loss=0.028557\n",
            "Batch 20: batch_loss=0.023777\n",
            "Batch 30: batch_loss=0.023415\n",
            "Batch 40: batch_loss=0.030365\n",
            "Batch 50: batch_loss=0.029145\n",
            "Batch 60: batch_loss=0.028684\n",
            "Batch 70: batch_loss=0.035587\n",
            "Batch 80: batch_loss=0.025053\n",
            "Batch 90: batch_loss=0.030326\n",
            "Batch 100: batch_loss=0.024986\n",
            "Batch 110: batch_loss=0.027801\n",
            "Batch 120: batch_loss=0.025021\n",
            "Batch 130: batch_loss=0.023468\n",
            "Batch 140: batch_loss=0.028165\n",
            "Batch 150: batch_loss=0.023299\n",
            "Batch 160: batch_loss=0.032103\n",
            "Batch 170: batch_loss=0.023724\n",
            "Batch 180: batch_loss=0.025341\n",
            "Batch 190: batch_loss=0.030294\n",
            "Batch 200: batch_loss=0.026714\n",
            "Batch 210: batch_loss=0.034298\n",
            "Batch 220: batch_loss=0.027971\n",
            "Batch 230: batch_loss=0.024490\n",
            "Batch 240: batch_loss=0.026302\n",
            "Batch 250: batch_loss=0.034089\n",
            "Batch 260: batch_loss=0.028814\n",
            "Batch 270: batch_loss=0.023122\n",
            "Batch 280: batch_loss=0.024568\n",
            "Batch 290: batch_loss=0.026606\n",
            "Batch 300: batch_loss=0.028328\n",
            "Batch 310: batch_loss=0.042972\n",
            "Batch 320: batch_loss=0.021597\n",
            "Batch 330: batch_loss=0.027379\n",
            "Batch 340: batch_loss=0.023587\n",
            "Batch 350: batch_loss=0.029522\n",
            "Batch 360: batch_loss=0.023668\n",
            "Batch 370: batch_loss=0.029922\n",
            "Batch 380: batch_loss=0.022168\n",
            "Batch 390: batch_loss=0.029497\n",
            "Batch 400: batch_loss=0.026430\n",
            "Batch 410: batch_loss=0.028065\n",
            "Batch 420: batch_loss=0.029950\n",
            "Batch 430: batch_loss=0.027804\n",
            "Batch 440: batch_loss=0.023476\n",
            "Batch 450: batch_loss=0.028285\n",
            "Batch 460: batch_loss=0.030981\n",
            "Batch 470: batch_loss=0.023739\n",
            "Batch 480: batch_loss=0.020880\n",
            "Batch 490: batch_loss=0.032162\n",
            "Batch 500: batch_loss=0.024113\n",
            "Batch 510: batch_loss=0.029935\n",
            "Batch 520: batch_loss=0.027066\n",
            "Batch 530: batch_loss=0.027310\n",
            "Batch 540: batch_loss=0.033201\n",
            "Batch 550: batch_loss=0.027594\n",
            "Batch 560: batch_loss=0.027498\n",
            "Batch 570: batch_loss=0.026117\n",
            "Batch 580: batch_loss=0.027886\n",
            "Batch 590: batch_loss=0.022863\n",
            "Batch 600: batch_loss=0.024948\n",
            "Batch 610: batch_loss=0.030181\n",
            "Batch 620: batch_loss=0.024842\n",
            "Batch 630: batch_loss=0.029235\n",
            "Batch 640: batch_loss=0.030012\n",
            "Batch 650: batch_loss=0.028649\n",
            "Batch 660: batch_loss=0.034329\n",
            "Batch 670: batch_loss=0.029042\n",
            "Batch 680: batch_loss=0.033153\n",
            "Batch 690: batch_loss=0.028834\n",
            "Batch 700: batch_loss=0.024419\n",
            "Batch 710: batch_loss=0.023777\n",
            "Batch 720: batch_loss=0.025148\n",
            "Batch 730: batch_loss=0.030113\n",
            "Batch 740: batch_loss=0.026052\n",
            "Batch 750: batch_loss=0.026159\n",
            "Batch 760: batch_loss=0.018804\n",
            "Batch 770: batch_loss=0.022545\n",
            "Batch 780: batch_loss=0.024418\n",
            "Batch 790: batch_loss=0.027144\n",
            "Batch 800: batch_loss=0.020525\n",
            "Batch 810: batch_loss=0.025444\n",
            "Batch 820: batch_loss=0.027079\n",
            "Batch 830: batch_loss=0.023631\n",
            "Batch 840: batch_loss=0.023900\n",
            "Batch 850: batch_loss=0.023499\n",
            "Batch 860: batch_loss=0.031907\n",
            "Batch 870: batch_loss=0.028247\n",
            "Batch 880: batch_loss=0.032622\n",
            "Batch 890: batch_loss=0.028674\n",
            "Batch 900: batch_loss=0.030470\n",
            "Batch 910: batch_loss=0.029391\n",
            "Batch 920: batch_loss=0.025696\n",
            "Batch 930: batch_loss=0.022110\n",
            "Batch 940: batch_loss=0.028717\n",
            "Batch 950: batch_loss=0.023982\n",
            "Batch 960: batch_loss=0.032280\n",
            "Batch 970: batch_loss=0.025347\n",
            "Batch 980: batch_loss=0.027111\n",
            "Batch 990: batch_loss=0.024304\n",
            "Batch 1000: batch_loss=0.029727\n",
            "Batch 1010: batch_loss=0.026010\n",
            "Batch 1020: batch_loss=0.022618\n",
            "Batch 1030: batch_loss=0.022276\n",
            "Batch 1040: batch_loss=0.027718\n",
            "Batch 1050: batch_loss=0.030258\n",
            "Batch 1060: batch_loss=0.028679\n",
            "Batch 1070: batch_loss=0.022147\n",
            "Batch 1080: batch_loss=0.022173\n",
            "Batch 1090: batch_loss=0.027866\n",
            "Batch 1100: batch_loss=0.028395\n",
            "Batch 1110: batch_loss=0.029071\n",
            "Batch 1120: batch_loss=0.026124\n",
            "Batch 1130: batch_loss=0.027829\n",
            "Batch 1140: batch_loss=0.026404\n",
            "Batch 1150: batch_loss=0.036038\n",
            "Batch 1160: batch_loss=0.024089\n",
            "Batch 1170: batch_loss=0.027723\n",
            "Batch 1180: batch_loss=0.038060\n",
            "Batch 1190: batch_loss=0.029040\n",
            "Batch 1200: batch_loss=0.024284\n",
            "Batch 1210: batch_loss=0.028828\n",
            "Batch 1220: batch_loss=0.033519\n",
            "Batch 1230: batch_loss=0.028011\n",
            "Batch 1240: batch_loss=0.023728\n",
            "Batch 1250: batch_loss=0.023549\n",
            "Batch 1260: batch_loss=0.026827\n",
            "Batch 1270: batch_loss=0.024547\n",
            "Batch 1280: batch_loss=0.034840\n",
            "Batch 1290: batch_loss=0.036722\n",
            "Batch 1300: batch_loss=0.036099\n",
            "Batch 1310: batch_loss=0.029974\n",
            "Batch 1320: batch_loss=0.026008\n",
            "Batch 1330: batch_loss=0.022158\n",
            "Batch 1340: batch_loss=0.027118\n",
            "Batch 1350: batch_loss=0.028034\n",
            "Batch 1360: batch_loss=0.023081\n",
            "Batch 1370: batch_loss=0.026916\n",
            "Batch 1380: batch_loss=0.022333\n",
            "Batch 1390: batch_loss=0.022979\n",
            "Batch 1400: batch_loss=0.020669\n",
            "Batch 1410: batch_loss=0.027196\n",
            "Batch 1420: batch_loss=0.025294\n",
            "Batch 1430: batch_loss=0.028493\n",
            "Batch 1440: batch_loss=0.031206\n",
            "Batch 1450: batch_loss=0.037976\n",
            "Batch 1460: batch_loss=0.025629\n",
            "Batch 1470: batch_loss=0.025004\n",
            "Batch 1480: batch_loss=0.035149\n",
            "Batch 1490: batch_loss=0.029485\n",
            "Batch 1500: batch_loss=0.029535\n",
            "Batch 1510: batch_loss=0.023229\n",
            "Batch 1520: batch_loss=0.024570\n",
            "Batch 1530: batch_loss=0.024445\n",
            "Batch 1540: batch_loss=0.027768\n",
            "Batch 1550: batch_loss=0.023547\n",
            "Batch 1560: batch_loss=0.027862\n",
            "Batch 1570: batch_loss=0.023851\n",
            "Batch 1580: batch_loss=0.028070\n",
            "Batch 1590: batch_loss=0.023108\n",
            "Batch 1600: batch_loss=0.033622\n",
            "Batch 1610: batch_loss=0.024964\n",
            "Batch 1620: batch_loss=0.020443\n",
            "Batch 1630: batch_loss=0.023294\n",
            "Batch 1640: batch_loss=0.024489\n",
            "Batch 1650: batch_loss=0.028318\n",
            "Batch 1660: batch_loss=0.028755\n",
            "Batch 1670: batch_loss=0.026386\n",
            "Batch 1680: batch_loss=0.023638\n",
            "Batch 1690: batch_loss=0.026618\n",
            "Batch 1700: batch_loss=0.021940\n",
            "Batch 1710: batch_loss=0.027692\n",
            "Batch 1720: batch_loss=0.030413\n",
            "Batch 1730: batch_loss=0.025776\n",
            "Batch 1740: batch_loss=0.026393\n",
            "Batch 1750: batch_loss=0.027138\n",
            "Batch 1760: batch_loss=0.023760\n",
            "Batch 1770: batch_loss=0.030044\n",
            "Batch 1780: batch_loss=0.031041\n",
            "Batch 1790: batch_loss=0.029656\n",
            "Batch 1800: batch_loss=0.031762\n",
            "Batch 1810: batch_loss=0.027030\n",
            "Batch 1820: batch_loss=0.028465\n",
            "Batch 1830: batch_loss=0.025583\n",
            "Batch 1840: batch_loss=0.021704\n",
            "Batch 1850: batch_loss=0.025408\n",
            "Batch 1860: batch_loss=0.026923\n",
            "Batch 1870: batch_loss=0.030299\n",
            "Batch 1880: batch_loss=0.027335\n",
            "Batch 1890: batch_loss=0.023914\n",
            "Batch 1900: batch_loss=0.024783\n",
            "Batch 1910: batch_loss=0.022640\n",
            "Batch 1920: batch_loss=0.035178\n",
            "Batch 1930: batch_loss=0.021291\n",
            "Batch 1940: batch_loss=0.025066\n",
            "Batch 1950: batch_loss=0.030486\n",
            "Batch 1960: batch_loss=0.026541\n",
            "Batch 1970: batch_loss=0.027998\n",
            "Batch 1980: batch_loss=0.023937\n",
            "Batch 1990: batch_loss=0.024796\n",
            "Batch 2000: batch_loss=0.030579\n",
            "Batch 2010: batch_loss=0.020816\n",
            "Batch 2020: batch_loss=0.022480\n",
            "Batch 2030: batch_loss=0.027333\n",
            "Batch 2040: batch_loss=0.027332\n",
            "Batch 2050: batch_loss=0.029946\n",
            "Batch 2060: batch_loss=0.025322\n",
            "Batch 2070: batch_loss=0.030548\n",
            "Batch 2080: batch_loss=0.027540\n",
            "Batch 2090: batch_loss=0.025042\n",
            "Batch 2100: batch_loss=0.020931\n",
            "Batch 2110: batch_loss=0.021689\n",
            "Batch 2120: batch_loss=0.022272\n",
            "Batch 2130: batch_loss=0.031230\n",
            "Batch 2140: batch_loss=0.020457\n",
            "Batch 2150: batch_loss=0.033396\n",
            "Batch 2160: batch_loss=0.031830\n",
            "Batch 2170: batch_loss=0.029398\n",
            "Batch 2180: batch_loss=0.027677\n",
            "Batch 2190: batch_loss=0.021355\n",
            "Batch 2200: batch_loss=0.026625\n",
            "Batch 2210: batch_loss=0.027350\n",
            "Batch 2220: batch_loss=0.026156\n",
            "Batch 2230: batch_loss=0.026462\n",
            "Batch 2240: batch_loss=0.024442\n",
            "Batch 2250: batch_loss=0.029199\n",
            "Batch 2260: batch_loss=0.025513\n",
            "Batch 2270: batch_loss=0.028314\n",
            "Batch 2280: batch_loss=0.028837\n",
            "Batch 2290: batch_loss=0.022475\n",
            "Batch 2300: batch_loss=0.031651\n",
            "Batch 2310: batch_loss=0.020357\n",
            "Batch 2320: batch_loss=0.021488\n",
            "Batch 2330: batch_loss=0.031399\n",
            "Batch 2340: batch_loss=0.022392\n",
            "Batch 2350: batch_loss=0.027447\n",
            "Batch 2360: batch_loss=0.025619\n",
            "Batch 2370: batch_loss=0.024342\n",
            "Batch 2380: batch_loss=0.026673\n",
            "Batch 2390: batch_loss=0.024313\n",
            "Batch 2400: batch_loss=0.026487\n",
            "Batch 2410: batch_loss=0.025769\n",
            "Batch 2420: batch_loss=0.024835\n",
            "Batch 2430: batch_loss=0.021828\n",
            "Batch 2440: batch_loss=0.021348\n",
            "Batch 2450: batch_loss=0.029754\n",
            "Batch 2460: batch_loss=0.027724\n",
            "Batch 2470: batch_loss=0.028127\n",
            "Batch 2480: batch_loss=0.020702\n",
            "Batch 2490: batch_loss=0.025401\n",
            "Batch 2500: batch_loss=0.024802\n",
            "Batch 2510: batch_loss=0.029943\n",
            "Batch 2520: batch_loss=0.026166\n",
            "Batch 2530: batch_loss=0.024014\n",
            "Batch 2540: batch_loss=0.025578\n",
            "Batch 2550: batch_loss=0.025157\n",
            "Batch 2560: batch_loss=0.027440\n",
            "Batch 2570: batch_loss=0.022753\n",
            "Batch 2580: batch_loss=0.025375\n",
            "Batch 2590: batch_loss=0.027738\n",
            "Batch 2600: batch_loss=0.026552\n",
            "Batch 2610: batch_loss=0.029637\n",
            "Batch 2620: batch_loss=0.030305\n",
            "Batch 2630: batch_loss=0.022369\n",
            "Batch 2640: batch_loss=0.027742\n",
            "Batch 2650: batch_loss=0.031445\n",
            "Batch 2660: batch_loss=0.019098\n",
            "Batch 2670: batch_loss=0.025300\n",
            "Batch 2680: batch_loss=0.024587\n",
            "Batch 2690: batch_loss=0.023314\n",
            "Batch 2700: batch_loss=0.021145\n",
            "Batch 2710: batch_loss=0.031474\n",
            "Batch 2720: batch_loss=0.026186\n",
            "Batch 2730: batch_loss=0.032770\n",
            "Batch 2740: batch_loss=0.030120\n",
            "Batch 2750: batch_loss=0.031728\n",
            "Batch 2760: batch_loss=0.027127\n",
            "Batch 2770: batch_loss=0.024568\n",
            "Batch 2780: batch_loss=0.024701\n",
            "Batch 2790: batch_loss=0.027834\n",
            "Batch 2800: batch_loss=0.028106\n",
            "Batch 2810: batch_loss=0.022519\n",
            "Batch 2820: batch_loss=0.023364\n",
            "Batch 2830: batch_loss=0.027489\n",
            "Batch 2840: batch_loss=0.028386\n",
            "Batch 2850: batch_loss=0.025437\n",
            "Batch 2860: batch_loss=0.027403\n",
            "Batch 2870: batch_loss=0.027928\n",
            "Batch 2880: batch_loss=0.028377\n",
            "Batch 2890: batch_loss=0.026142\n",
            "Batch 2900: batch_loss=0.023753\n",
            "Batch 2910: batch_loss=0.030849\n",
            "Batch 2920: batch_loss=0.022122\n",
            "Batch 2930: batch_loss=0.026808\n",
            "Batch 2940: batch_loss=0.029865\n",
            "Batch 2950: batch_loss=0.028517\n",
            "Batch 2960: batch_loss=0.031540\n",
            "Batch 2970: batch_loss=0.024218\n",
            "Batch 2980: batch_loss=0.023541\n",
            "Batch 2990: batch_loss=0.023375\n",
            "Batch 3000: batch_loss=0.022322\n",
            "Batch 3010: batch_loss=0.027932\n",
            "Batch 3020: batch_loss=0.027676\n",
            "Batch 3030: batch_loss=0.027834\n",
            "Batch 3040: batch_loss=0.026747\n",
            "Batch 3050: batch_loss=0.020837\n",
            "Batch 3060: batch_loss=0.031338\n",
            "Batch 3070: batch_loss=0.028614\n",
            "Batch 3080: batch_loss=0.020558\n",
            "Batch 3090: batch_loss=0.036251\n",
            "Batch 3100: batch_loss=0.022906\n",
            "Batch 3110: batch_loss=0.033678\n",
            "Batch 3120: batch_loss=0.024581\n",
            "Batch 3130: batch_loss=0.022336\n",
            "Batch 3140: batch_loss=0.024442\n",
            "Batch 3150: batch_loss=0.030110\n",
            "Batch 3160: batch_loss=0.026061\n",
            "Batch 3170: batch_loss=0.032877\n",
            "Batch 3180: batch_loss=0.028860\n",
            "Batch 3190: batch_loss=0.025005\n",
            "Batch 3200: batch_loss=0.032481\n",
            "Batch 3210: batch_loss=0.028754\n",
            "Batch 3220: batch_loss=0.027140\n",
            "Batch 3230: batch_loss=0.031119\n",
            "Batch 3240: batch_loss=0.026730\n",
            "Batch 3250: batch_loss=0.022897\n",
            "Batch 3260: batch_loss=0.023642\n",
            "Batch 3270: batch_loss=0.033743\n",
            "Batch 3280: batch_loss=0.030683\n",
            "Batch 3290: batch_loss=0.026471\n",
            "Batch 3300: batch_loss=0.023386\n",
            "Batch 3310: batch_loss=0.032101\n",
            "Batch 3320: batch_loss=0.039691\n",
            "Batch 3330: batch_loss=0.032895\n",
            "Batch 3340: batch_loss=0.026783\n",
            "Batch 3350: batch_loss=0.026982\n",
            "Batch 3360: batch_loss=0.027228\n",
            "Batch 3370: batch_loss=0.020680\n",
            "Batch 3380: batch_loss=0.031465\n",
            "Batch 3390: batch_loss=0.027071\n",
            "Batch 3400: batch_loss=0.030530\n",
            "Batch 3410: batch_loss=0.030778\n",
            "Batch 3420: batch_loss=0.023261\n",
            "Batch 3430: batch_loss=0.024074\n",
            "Batch 3440: batch_loss=0.025128\n",
            "Batch 3450: batch_loss=0.031048\n",
            "Batch 3460: batch_loss=0.025119\n",
            "Batch 3470: batch_loss=0.030711\n",
            "Batch 3480: batch_loss=0.022132\n",
            "Batch 3490: batch_loss=0.025904\n",
            "Batch 3500: batch_loss=0.023918\n",
            "Batch 3510: batch_loss=0.032032\n",
            "Batch 3520: batch_loss=0.028452\n",
            "Batch 3530: batch_loss=0.021450\n",
            "Batch 3540: batch_loss=0.028573\n",
            "Batch 3550: batch_loss=0.031753\n",
            "Batch 3560: batch_loss=0.026200\n",
            "Batch 3570: batch_loss=0.031718\n",
            "Batch 3580: batch_loss=0.026385\n",
            "Batch 3590: batch_loss=0.025634\n",
            "Batch 3600: batch_loss=0.027687\n",
            "Batch 3610: batch_loss=0.019859\n",
            "Batch 3620: batch_loss=0.030829\n",
            "Batch 3630: batch_loss=0.024242\n",
            "Batch 3640: batch_loss=0.026768\n",
            "Batch 3650: batch_loss=0.020613\n",
            "Batch 3660: batch_loss=0.026828\n",
            "Batch 3670: batch_loss=0.027896\n",
            "Batch 3680: batch_loss=0.019474\n",
            "Batch 3690: batch_loss=0.024131\n",
            "Batch 3700: batch_loss=0.029108\n",
            "Batch 3710: batch_loss=0.024705\n",
            "Batch 3720: batch_loss=0.022026\n",
            "Epoch 5/10, Train Loss: 0.026651, Val Loss: 0.016632\n",
            "Batch 0: batch_loss=0.028923\n",
            "Batch 10: batch_loss=0.029000\n",
            "Batch 20: batch_loss=0.023866\n",
            "Batch 30: batch_loss=0.024799\n",
            "Batch 40: batch_loss=0.023866\n",
            "Batch 50: batch_loss=0.025141\n",
            "Batch 60: batch_loss=0.027566\n",
            "Batch 70: batch_loss=0.022474\n",
            "Batch 80: batch_loss=0.031345\n",
            "Batch 90: batch_loss=0.026492\n",
            "Batch 100: batch_loss=0.021383\n",
            "Batch 110: batch_loss=0.025464\n",
            "Batch 120: batch_loss=0.032729\n",
            "Batch 130: batch_loss=0.020064\n",
            "Batch 140: batch_loss=0.022011\n",
            "Batch 150: batch_loss=0.033869\n",
            "Batch 160: batch_loss=0.026362\n",
            "Batch 170: batch_loss=0.029330\n",
            "Batch 180: batch_loss=0.028495\n",
            "Batch 190: batch_loss=0.027155\n",
            "Batch 200: batch_loss=0.024242\n",
            "Batch 210: batch_loss=0.025046\n",
            "Batch 220: batch_loss=0.027269\n",
            "Batch 230: batch_loss=0.025573\n",
            "Batch 240: batch_loss=0.024440\n",
            "Batch 250: batch_loss=0.028344\n",
            "Batch 260: batch_loss=0.024602\n",
            "Batch 270: batch_loss=0.033340\n",
            "Batch 280: batch_loss=0.022175\n",
            "Batch 290: batch_loss=0.030241\n",
            "Batch 300: batch_loss=0.036631\n",
            "Batch 310: batch_loss=0.028470\n",
            "Batch 320: batch_loss=0.028252\n",
            "Batch 330: batch_loss=0.019374\n",
            "Batch 340: batch_loss=0.026620\n",
            "Batch 350: batch_loss=0.025027\n",
            "Batch 360: batch_loss=0.026840\n",
            "Batch 370: batch_loss=0.021209\n",
            "Batch 380: batch_loss=0.025638\n",
            "Batch 390: batch_loss=0.035482\n",
            "Batch 400: batch_loss=0.022731\n",
            "Batch 410: batch_loss=0.025590\n",
            "Batch 420: batch_loss=0.023443\n",
            "Batch 430: batch_loss=0.029555\n",
            "Batch 440: batch_loss=0.027903\n",
            "Batch 450: batch_loss=0.021151\n",
            "Batch 460: batch_loss=0.021859\n",
            "Batch 470: batch_loss=0.032656\n",
            "Batch 480: batch_loss=0.027009\n",
            "Batch 490: batch_loss=0.029101\n",
            "Batch 500: batch_loss=0.030339\n",
            "Batch 510: batch_loss=0.026596\n",
            "Batch 520: batch_loss=0.030204\n",
            "Batch 530: batch_loss=0.028491\n",
            "Batch 540: batch_loss=0.026781\n",
            "Batch 550: batch_loss=0.021467\n",
            "Batch 560: batch_loss=0.033072\n",
            "Batch 570: batch_loss=0.022881\n",
            "Batch 580: batch_loss=0.023595\n",
            "Batch 590: batch_loss=0.034490\n",
            "Batch 600: batch_loss=0.024790\n",
            "Batch 610: batch_loss=0.021690\n",
            "Batch 620: batch_loss=0.019398\n",
            "Batch 630: batch_loss=0.025568\n",
            "Batch 640: batch_loss=0.024797\n",
            "Batch 650: batch_loss=0.021300\n",
            "Batch 660: batch_loss=0.026215\n",
            "Batch 670: batch_loss=0.026359\n",
            "Batch 680: batch_loss=0.024779\n",
            "Batch 690: batch_loss=0.028615\n",
            "Batch 700: batch_loss=0.029608\n",
            "Batch 710: batch_loss=0.023629\n",
            "Batch 720: batch_loss=0.028036\n",
            "Batch 730: batch_loss=0.021110\n",
            "Batch 740: batch_loss=0.028506\n",
            "Batch 750: batch_loss=0.031577\n",
            "Batch 760: batch_loss=0.028838\n",
            "Batch 770: batch_loss=0.025340\n",
            "Batch 780: batch_loss=0.023258\n",
            "Batch 790: batch_loss=0.026413\n",
            "Batch 800: batch_loss=0.036427\n",
            "Batch 810: batch_loss=0.027014\n",
            "Batch 820: batch_loss=0.023814\n",
            "Batch 830: batch_loss=0.023165\n",
            "Batch 840: batch_loss=0.023332\n",
            "Batch 850: batch_loss=0.026770\n",
            "Batch 860: batch_loss=0.025482\n",
            "Batch 870: batch_loss=0.026153\n",
            "Batch 880: batch_loss=0.024389\n",
            "Batch 890: batch_loss=0.024614\n",
            "Batch 900: batch_loss=0.025055\n",
            "Batch 910: batch_loss=0.021702\n",
            "Batch 920: batch_loss=0.026869\n",
            "Batch 930: batch_loss=0.033240\n",
            "Batch 940: batch_loss=0.029826\n",
            "Batch 950: batch_loss=0.024052\n",
            "Batch 960: batch_loss=0.030397\n",
            "Batch 970: batch_loss=0.026028\n",
            "Batch 980: batch_loss=0.021216\n",
            "Batch 990: batch_loss=0.022902\n",
            "Batch 1000: batch_loss=0.022106\n",
            "Batch 1010: batch_loss=0.026681\n",
            "Batch 1020: batch_loss=0.030034\n",
            "Batch 1030: batch_loss=0.029470\n",
            "Batch 1040: batch_loss=0.027199\n",
            "Batch 1050: batch_loss=0.025917\n",
            "Batch 1060: batch_loss=0.028040\n",
            "Batch 1070: batch_loss=0.026097\n",
            "Batch 1080: batch_loss=0.027061\n",
            "Batch 1090: batch_loss=0.030038\n",
            "Batch 1100: batch_loss=0.021664\n",
            "Batch 1110: batch_loss=0.022377\n",
            "Batch 1120: batch_loss=0.031563\n",
            "Batch 1130: batch_loss=0.024904\n",
            "Batch 1140: batch_loss=0.022908\n",
            "Batch 1150: batch_loss=0.028084\n",
            "Batch 1160: batch_loss=0.022425\n",
            "Batch 1170: batch_loss=0.026794\n",
            "Batch 1180: batch_loss=0.027096\n",
            "Batch 1190: batch_loss=0.031731\n",
            "Batch 1200: batch_loss=0.031125\n",
            "Batch 1210: batch_loss=0.025236\n",
            "Batch 1220: batch_loss=0.021488\n",
            "Batch 1230: batch_loss=0.033532\n",
            "Batch 1240: batch_loss=0.024443\n",
            "Batch 1250: batch_loss=0.027450\n",
            "Batch 1260: batch_loss=0.029064\n",
            "Batch 1270: batch_loss=0.022302\n",
            "Batch 1280: batch_loss=0.027229\n",
            "Batch 1290: batch_loss=0.032364\n",
            "Batch 1300: batch_loss=0.026256\n",
            "Batch 1310: batch_loss=0.025821\n",
            "Batch 1320: batch_loss=0.019849\n",
            "Batch 1330: batch_loss=0.027657\n",
            "Batch 1340: batch_loss=0.028766\n",
            "Batch 1350: batch_loss=0.027799\n",
            "Batch 1360: batch_loss=0.022429\n",
            "Batch 1370: batch_loss=0.027504\n",
            "Batch 1380: batch_loss=0.030805\n",
            "Batch 1390: batch_loss=0.028165\n",
            "Batch 1400: batch_loss=0.023783\n",
            "Batch 1410: batch_loss=0.026756\n",
            "Batch 1420: batch_loss=0.028166\n",
            "Batch 1430: batch_loss=0.028388\n",
            "Batch 1440: batch_loss=0.031185\n",
            "Batch 1450: batch_loss=0.021871\n",
            "Batch 1460: batch_loss=0.024828\n",
            "Batch 1470: batch_loss=0.026186\n",
            "Batch 1480: batch_loss=0.021524\n",
            "Batch 1490: batch_loss=0.029259\n",
            "Batch 1500: batch_loss=0.029225\n",
            "Batch 1510: batch_loss=0.024725\n",
            "Batch 1520: batch_loss=0.029952\n",
            "Batch 1530: batch_loss=0.023428\n",
            "Batch 1540: batch_loss=0.025055\n",
            "Batch 1550: batch_loss=0.027858\n",
            "Batch 1560: batch_loss=0.028457\n",
            "Batch 1570: batch_loss=0.023078\n",
            "Batch 1580: batch_loss=0.026311\n",
            "Batch 1590: batch_loss=0.031393\n",
            "Batch 1600: batch_loss=0.026049\n",
            "Batch 1610: batch_loss=0.034600\n",
            "Batch 1620: batch_loss=0.033481\n",
            "Batch 1630: batch_loss=0.026018\n",
            "Batch 1640: batch_loss=0.030840\n",
            "Batch 1650: batch_loss=0.020809\n",
            "Batch 1660: batch_loss=0.023305\n",
            "Batch 1670: batch_loss=0.023678\n",
            "Batch 1680: batch_loss=0.032050\n",
            "Batch 1690: batch_loss=0.026920\n",
            "Batch 1700: batch_loss=0.022207\n",
            "Batch 1710: batch_loss=0.024555\n",
            "Batch 1720: batch_loss=0.026951\n",
            "Batch 1730: batch_loss=0.025427\n",
            "Batch 1740: batch_loss=0.024109\n",
            "Batch 1750: batch_loss=0.025316\n",
            "Batch 1760: batch_loss=0.029861\n",
            "Batch 1770: batch_loss=0.025244\n",
            "Batch 1780: batch_loss=0.026010\n",
            "Batch 1790: batch_loss=0.034156\n",
            "Batch 1800: batch_loss=0.025902\n",
            "Batch 1810: batch_loss=0.028656\n",
            "Batch 1820: batch_loss=0.031250\n",
            "Batch 1830: batch_loss=0.019498\n",
            "Batch 1840: batch_loss=0.023580\n",
            "Batch 1850: batch_loss=0.029647\n",
            "Batch 1860: batch_loss=0.026434\n",
            "Batch 1870: batch_loss=0.022774\n",
            "Batch 1880: batch_loss=0.030589\n",
            "Batch 1890: batch_loss=0.024075\n",
            "Batch 1900: batch_loss=0.024801\n",
            "Batch 1910: batch_loss=0.028938\n",
            "Batch 1920: batch_loss=0.022917\n",
            "Batch 1930: batch_loss=0.032784\n",
            "Batch 1940: batch_loss=0.020693\n",
            "Batch 1950: batch_loss=0.025198\n",
            "Batch 1960: batch_loss=0.029349\n",
            "Batch 1970: batch_loss=0.024018\n",
            "Batch 1980: batch_loss=0.028943\n",
            "Batch 1990: batch_loss=0.028259\n",
            "Batch 2000: batch_loss=0.025652\n",
            "Batch 2010: batch_loss=0.021802\n",
            "Batch 2020: batch_loss=0.027586\n",
            "Batch 2030: batch_loss=0.029063\n",
            "Batch 2040: batch_loss=0.022049\n",
            "Batch 2050: batch_loss=0.020310\n",
            "Batch 2060: batch_loss=0.036058\n",
            "Batch 2070: batch_loss=0.023517\n",
            "Batch 2080: batch_loss=0.028761\n",
            "Batch 2090: batch_loss=0.024659\n",
            "Batch 2100: batch_loss=0.028292\n",
            "Batch 2110: batch_loss=0.022125\n",
            "Batch 2120: batch_loss=0.029398\n",
            "Batch 2130: batch_loss=0.027480\n",
            "Batch 2140: batch_loss=0.030633\n",
            "Batch 2150: batch_loss=0.026786\n",
            "Batch 2160: batch_loss=0.028281\n",
            "Batch 2170: batch_loss=0.025006\n",
            "Batch 2180: batch_loss=0.021411\n",
            "Batch 2190: batch_loss=0.021532\n",
            "Batch 2200: batch_loss=0.025702\n",
            "Batch 2210: batch_loss=0.029370\n",
            "Batch 2220: batch_loss=0.029219\n",
            "Batch 2230: batch_loss=0.024488\n",
            "Batch 2240: batch_loss=0.021078\n",
            "Batch 2250: batch_loss=0.031462\n",
            "Batch 2260: batch_loss=0.025762\n",
            "Batch 2270: batch_loss=0.022215\n",
            "Batch 2280: batch_loss=0.026379\n",
            "Batch 2290: batch_loss=0.031078\n",
            "Batch 2300: batch_loss=0.026616\n",
            "Batch 2310: batch_loss=0.030454\n",
            "Batch 2320: batch_loss=0.027926\n",
            "Batch 2330: batch_loss=0.019324\n",
            "Batch 2340: batch_loss=0.021087\n",
            "Batch 2350: batch_loss=0.023490\n",
            "Batch 2360: batch_loss=0.021728\n",
            "Batch 2370: batch_loss=0.026120\n",
            "Batch 2380: batch_loss=0.024738\n",
            "Batch 2390: batch_loss=0.030736\n",
            "Batch 2400: batch_loss=0.029298\n",
            "Batch 2410: batch_loss=0.028085\n",
            "Batch 2420: batch_loss=0.030614\n",
            "Batch 2430: batch_loss=0.024891\n",
            "Batch 2440: batch_loss=0.031521\n",
            "Batch 2450: batch_loss=0.024048\n",
            "Batch 2460: batch_loss=0.025093\n",
            "Batch 2470: batch_loss=0.033348\n",
            "Batch 2480: batch_loss=0.026264\n",
            "Batch 2490: batch_loss=0.027464\n",
            "Batch 2500: batch_loss=0.023617\n",
            "Batch 2510: batch_loss=0.027817\n",
            "Batch 2520: batch_loss=0.019272\n",
            "Batch 2530: batch_loss=0.024648\n",
            "Batch 2540: batch_loss=0.026257\n",
            "Batch 2550: batch_loss=0.029118\n",
            "Batch 2560: batch_loss=0.021673\n",
            "Batch 2570: batch_loss=0.026747\n",
            "Batch 2580: batch_loss=0.026765\n",
            "Batch 2590: batch_loss=0.022709\n",
            "Batch 2600: batch_loss=0.019315\n",
            "Batch 2610: batch_loss=0.022619\n",
            "Batch 2620: batch_loss=0.031926\n",
            "Batch 2630: batch_loss=0.024288\n",
            "Batch 2640: batch_loss=0.028623\n",
            "Batch 2650: batch_loss=0.024057\n",
            "Batch 2660: batch_loss=0.023624\n",
            "Batch 2670: batch_loss=0.028502\n",
            "Batch 2680: batch_loss=0.031997\n",
            "Batch 2690: batch_loss=0.035994\n",
            "Batch 2700: batch_loss=0.026568\n",
            "Batch 2710: batch_loss=0.022917\n",
            "Batch 2720: batch_loss=0.020590\n",
            "Batch 2730: batch_loss=0.026720\n",
            "Batch 2740: batch_loss=0.028236\n",
            "Batch 2750: batch_loss=0.031187\n",
            "Batch 2760: batch_loss=0.027496\n",
            "Batch 2770: batch_loss=0.034804\n",
            "Batch 2780: batch_loss=0.026962\n",
            "Batch 2790: batch_loss=0.027684\n",
            "Batch 2800: batch_loss=0.024226\n",
            "Batch 2810: batch_loss=0.024147\n",
            "Batch 2820: batch_loss=0.025190\n",
            "Batch 2830: batch_loss=0.029611\n",
            "Batch 2840: batch_loss=0.030464\n",
            "Batch 2850: batch_loss=0.026711\n",
            "Batch 2860: batch_loss=0.025432\n",
            "Batch 2870: batch_loss=0.025307\n",
            "Batch 2880: batch_loss=0.028623\n",
            "Batch 2890: batch_loss=0.031281\n",
            "Batch 2900: batch_loss=0.029413\n",
            "Batch 2910: batch_loss=0.022550\n",
            "Batch 2920: batch_loss=0.024603\n",
            "Batch 2930: batch_loss=0.025975\n",
            "Batch 2940: batch_loss=0.024823\n",
            "Batch 2950: batch_loss=0.023955\n",
            "Batch 2960: batch_loss=0.026628\n",
            "Batch 2970: batch_loss=0.024821\n",
            "Batch 2980: batch_loss=0.021481\n",
            "Batch 2990: batch_loss=0.023806\n",
            "Batch 3000: batch_loss=0.038027\n",
            "Batch 3010: batch_loss=0.025228\n",
            "Batch 3020: batch_loss=0.029737\n",
            "Batch 3030: batch_loss=0.029426\n",
            "Batch 3040: batch_loss=0.025200\n",
            "Batch 3050: batch_loss=0.024720\n",
            "Batch 3060: batch_loss=0.026611\n",
            "Batch 3070: batch_loss=0.041102\n",
            "Batch 3080: batch_loss=0.025895\n",
            "Batch 3090: batch_loss=0.031344\n",
            "Batch 3100: batch_loss=0.033635\n",
            "Batch 3110: batch_loss=0.036899\n",
            "Batch 3120: batch_loss=0.021347\n",
            "Batch 3130: batch_loss=0.027837\n",
            "Batch 3140: batch_loss=0.024713\n",
            "Batch 3150: batch_loss=0.030451\n",
            "Batch 3160: batch_loss=0.019805\n",
            "Batch 3170: batch_loss=0.030012\n",
            "Batch 3180: batch_loss=0.037755\n",
            "Batch 3190: batch_loss=0.030475\n",
            "Batch 3200: batch_loss=0.028211\n",
            "Batch 3210: batch_loss=0.033327\n",
            "Batch 3220: batch_loss=0.024634\n",
            "Batch 3230: batch_loss=0.027810\n",
            "Batch 3240: batch_loss=0.024245\n",
            "Batch 3250: batch_loss=0.025259\n",
            "Batch 3260: batch_loss=0.028374\n",
            "Batch 3270: batch_loss=0.029029\n",
            "Batch 3280: batch_loss=0.026754\n",
            "Batch 3290: batch_loss=0.024842\n",
            "Batch 3300: batch_loss=0.029498\n",
            "Batch 3310: batch_loss=0.026318\n",
            "Batch 3320: batch_loss=0.038577\n",
            "Batch 3330: batch_loss=0.025879\n",
            "Batch 3340: batch_loss=0.023991\n",
            "Batch 3350: batch_loss=0.024086\n",
            "Batch 3360: batch_loss=0.025832\n",
            "Batch 3370: batch_loss=0.024233\n",
            "Batch 3380: batch_loss=0.032135\n",
            "Batch 3390: batch_loss=0.028030\n",
            "Batch 3400: batch_loss=0.023122\n",
            "Batch 3410: batch_loss=0.019967\n",
            "Batch 3420: batch_loss=0.031972\n",
            "Batch 3430: batch_loss=0.020336\n",
            "Batch 3440: batch_loss=0.030402\n",
            "Batch 3450: batch_loss=0.029857\n",
            "Batch 3460: batch_loss=0.024099\n",
            "Batch 3470: batch_loss=0.020196\n",
            "Batch 3480: batch_loss=0.025680\n",
            "Batch 3490: batch_loss=0.022200\n",
            "Batch 3500: batch_loss=0.029004\n",
            "Batch 3510: batch_loss=0.020771\n",
            "Batch 3520: batch_loss=0.026263\n",
            "Batch 3530: batch_loss=0.029109\n",
            "Batch 3540: batch_loss=0.030882\n",
            "Batch 3550: batch_loss=0.031664\n",
            "Batch 3560: batch_loss=0.022307\n",
            "Batch 3570: batch_loss=0.023412\n",
            "Batch 3580: batch_loss=0.023551\n",
            "Batch 3590: batch_loss=0.025257\n",
            "Batch 3600: batch_loss=0.025624\n",
            "Batch 3610: batch_loss=0.034679\n",
            "Batch 3620: batch_loss=0.025788\n",
            "Batch 3630: batch_loss=0.020561\n",
            "Batch 3640: batch_loss=0.026152\n",
            "Batch 3650: batch_loss=0.029604\n",
            "Batch 3660: batch_loss=0.029945\n",
            "Batch 3670: batch_loss=0.024715\n",
            "Batch 3680: batch_loss=0.026409\n",
            "Batch 3690: batch_loss=0.025010\n",
            "Batch 3700: batch_loss=0.023038\n",
            "Batch 3710: batch_loss=0.022213\n",
            "Batch 3720: batch_loss=0.024779\n",
            "Epoch 6/10, Train Loss: 0.026649, Val Loss: 0.016631\n",
            "Batch 0: batch_loss=0.038999\n",
            "Batch 10: batch_loss=0.023620\n",
            "Batch 20: batch_loss=0.027320\n",
            "Batch 30: batch_loss=0.034409\n",
            "Batch 40: batch_loss=0.032690\n",
            "Batch 50: batch_loss=0.027115\n",
            "Batch 60: batch_loss=0.020836\n",
            "Batch 70: batch_loss=0.029011\n",
            "Batch 80: batch_loss=0.029271\n",
            "Batch 90: batch_loss=0.025421\n",
            "Batch 100: batch_loss=0.028455\n",
            "Batch 110: batch_loss=0.029786\n",
            "Batch 120: batch_loss=0.019914\n",
            "Batch 130: batch_loss=0.026069\n",
            "Batch 140: batch_loss=0.023923\n",
            "Batch 150: batch_loss=0.028339\n",
            "Batch 160: batch_loss=0.025998\n",
            "Batch 170: batch_loss=0.030688\n",
            "Batch 180: batch_loss=0.034375\n",
            "Batch 190: batch_loss=0.023128\n",
            "Batch 200: batch_loss=0.019351\n",
            "Batch 210: batch_loss=0.025239\n",
            "Batch 220: batch_loss=0.023723\n",
            "Batch 230: batch_loss=0.032684\n",
            "Batch 240: batch_loss=0.024823\n",
            "Batch 250: batch_loss=0.029632\n",
            "Batch 260: batch_loss=0.030495\n",
            "Batch 270: batch_loss=0.028303\n",
            "Batch 280: batch_loss=0.028568\n",
            "Batch 290: batch_loss=0.024733\n",
            "Batch 300: batch_loss=0.030665\n",
            "Batch 310: batch_loss=0.025766\n",
            "Batch 320: batch_loss=0.032776\n",
            "Batch 330: batch_loss=0.027382\n",
            "Batch 340: batch_loss=0.021565\n",
            "Batch 350: batch_loss=0.028259\n",
            "Batch 360: batch_loss=0.034972\n",
            "Batch 370: batch_loss=0.022334\n",
            "Batch 380: batch_loss=0.024995\n",
            "Batch 390: batch_loss=0.023475\n",
            "Batch 400: batch_loss=0.033370\n",
            "Batch 410: batch_loss=0.023714\n",
            "Batch 420: batch_loss=0.023208\n",
            "Batch 430: batch_loss=0.020799\n",
            "Batch 440: batch_loss=0.020497\n",
            "Batch 450: batch_loss=0.024994\n",
            "Batch 460: batch_loss=0.025090\n",
            "Batch 470: batch_loss=0.027883\n",
            "Batch 480: batch_loss=0.026802\n",
            "Batch 490: batch_loss=0.020795\n",
            "Batch 500: batch_loss=0.020477\n",
            "Batch 510: batch_loss=0.023864\n",
            "Batch 520: batch_loss=0.020615\n",
            "Batch 530: batch_loss=0.027788\n",
            "Batch 540: batch_loss=0.027219\n",
            "Batch 550: batch_loss=0.026915\n",
            "Batch 560: batch_loss=0.027983\n",
            "Batch 570: batch_loss=0.026361\n",
            "Batch 580: batch_loss=0.024414\n",
            "Batch 590: batch_loss=0.028752\n",
            "Batch 600: batch_loss=0.026496\n",
            "Batch 610: batch_loss=0.024344\n",
            "Batch 620: batch_loss=0.024760\n",
            "Batch 630: batch_loss=0.032187\n",
            "Batch 640: batch_loss=0.028124\n",
            "Batch 650: batch_loss=0.028594\n",
            "Batch 660: batch_loss=0.027615\n",
            "Batch 670: batch_loss=0.033093\n",
            "Batch 680: batch_loss=0.029139\n",
            "Batch 690: batch_loss=0.019445\n",
            "Batch 700: batch_loss=0.021205\n",
            "Batch 710: batch_loss=0.023879\n",
            "Batch 720: batch_loss=0.024458\n",
            "Batch 730: batch_loss=0.023624\n",
            "Batch 740: batch_loss=0.023958\n",
            "Batch 750: batch_loss=0.027745\n",
            "Batch 760: batch_loss=0.025648\n",
            "Batch 770: batch_loss=0.020666\n",
            "Batch 780: batch_loss=0.029619\n",
            "Batch 790: batch_loss=0.021680\n",
            "Batch 800: batch_loss=0.025954\n",
            "Batch 810: batch_loss=0.026696\n",
            "Batch 820: batch_loss=0.022138\n",
            "Batch 830: batch_loss=0.019852\n",
            "Batch 840: batch_loss=0.021039\n",
            "Batch 850: batch_loss=0.027123\n",
            "Batch 860: batch_loss=0.027430\n",
            "Batch 870: batch_loss=0.024168\n",
            "Batch 880: batch_loss=0.034956\n",
            "Batch 890: batch_loss=0.035638\n",
            "Batch 900: batch_loss=0.023518\n",
            "Batch 910: batch_loss=0.025280\n",
            "Batch 920: batch_loss=0.021110\n",
            "Batch 930: batch_loss=0.026386\n",
            "Batch 940: batch_loss=0.024163\n",
            "Batch 950: batch_loss=0.033945\n",
            "Batch 960: batch_loss=0.031168\n",
            "Batch 970: batch_loss=0.029370\n",
            "Batch 980: batch_loss=0.025716\n",
            "Batch 990: batch_loss=0.026329\n",
            "Batch 1000: batch_loss=0.030153\n",
            "Batch 1010: batch_loss=0.026924\n",
            "Batch 1020: batch_loss=0.025979\n",
            "Batch 1030: batch_loss=0.022473\n",
            "Batch 1040: batch_loss=0.021435\n",
            "Batch 1050: batch_loss=0.025063\n",
            "Batch 1060: batch_loss=0.025586\n",
            "Batch 1070: batch_loss=0.029473\n",
            "Batch 1080: batch_loss=0.025938\n",
            "Batch 1090: batch_loss=0.028493\n",
            "Batch 1100: batch_loss=0.030538\n",
            "Batch 1110: batch_loss=0.022063\n",
            "Batch 1120: batch_loss=0.030228\n",
            "Batch 1130: batch_loss=0.023570\n",
            "Batch 1140: batch_loss=0.033678\n",
            "Batch 1150: batch_loss=0.021847\n",
            "Batch 1160: batch_loss=0.028739\n",
            "Batch 1170: batch_loss=0.024490\n",
            "Batch 1180: batch_loss=0.023391\n",
            "Batch 1190: batch_loss=0.025219\n",
            "Batch 1200: batch_loss=0.029534\n",
            "Batch 1210: batch_loss=0.031058\n",
            "Batch 1220: batch_loss=0.028799\n",
            "Batch 1230: batch_loss=0.029917\n",
            "Batch 1240: batch_loss=0.027339\n",
            "Batch 1250: batch_loss=0.030585\n",
            "Batch 1260: batch_loss=0.026850\n",
            "Batch 1270: batch_loss=0.021642\n",
            "Batch 1280: batch_loss=0.026735\n",
            "Batch 1290: batch_loss=0.025822\n",
            "Batch 1300: batch_loss=0.026873\n",
            "Batch 1310: batch_loss=0.029906\n",
            "Batch 1320: batch_loss=0.025939\n",
            "Batch 1330: batch_loss=0.024934\n",
            "Batch 1340: batch_loss=0.026864\n",
            "Batch 1350: batch_loss=0.025468\n",
            "Batch 1360: batch_loss=0.021896\n",
            "Batch 1370: batch_loss=0.022336\n",
            "Batch 1380: batch_loss=0.030613\n",
            "Batch 1390: batch_loss=0.024870\n",
            "Batch 1400: batch_loss=0.029903\n",
            "Batch 1410: batch_loss=0.020782\n",
            "Batch 1420: batch_loss=0.025680\n",
            "Batch 1430: batch_loss=0.024492\n",
            "Batch 1440: batch_loss=0.023388\n",
            "Batch 1450: batch_loss=0.022953\n",
            "Batch 1460: batch_loss=0.026655\n",
            "Batch 1470: batch_loss=0.024364\n",
            "Batch 1480: batch_loss=0.027600\n",
            "Batch 1490: batch_loss=0.031115\n",
            "Batch 1500: batch_loss=0.030166\n",
            "Batch 1510: batch_loss=0.020995\n",
            "Batch 1520: batch_loss=0.027634\n",
            "Batch 1530: batch_loss=0.025352\n",
            "Batch 1540: batch_loss=0.024071\n",
            "Batch 1550: batch_loss=0.026813\n",
            "Batch 1560: batch_loss=0.022459\n",
            "Batch 1570: batch_loss=0.025953\n",
            "Batch 1580: batch_loss=0.025207\n",
            "Batch 1590: batch_loss=0.030943\n",
            "Batch 1600: batch_loss=0.022770\n",
            "Batch 1610: batch_loss=0.029735\n",
            "Batch 1620: batch_loss=0.024226\n",
            "Batch 1630: batch_loss=0.022661\n",
            "Batch 1640: batch_loss=0.026091\n",
            "Batch 1650: batch_loss=0.027196\n",
            "Batch 1660: batch_loss=0.027221\n",
            "Batch 1670: batch_loss=0.030370\n",
            "Batch 1680: batch_loss=0.027105\n",
            "Batch 1690: batch_loss=0.021138\n",
            "Batch 1700: batch_loss=0.031668\n",
            "Batch 1710: batch_loss=0.027233\n",
            "Batch 1720: batch_loss=0.023470\n",
            "Batch 1730: batch_loss=0.025754\n",
            "Batch 1740: batch_loss=0.022306\n",
            "Batch 1750: batch_loss=0.032886\n",
            "Batch 1760: batch_loss=0.029398\n",
            "Batch 1770: batch_loss=0.028557\n",
            "Batch 1780: batch_loss=0.033219\n",
            "Batch 1790: batch_loss=0.024832\n",
            "Batch 1800: batch_loss=0.022839\n",
            "Batch 1810: batch_loss=0.026191\n",
            "Batch 1820: batch_loss=0.027848\n",
            "Batch 1830: batch_loss=0.021958\n",
            "Batch 1840: batch_loss=0.021294\n",
            "Batch 1850: batch_loss=0.027270\n",
            "Batch 1860: batch_loss=0.025064\n",
            "Batch 1870: batch_loss=0.029131\n",
            "Batch 1880: batch_loss=0.028232\n",
            "Batch 1890: batch_loss=0.027591\n",
            "Batch 1900: batch_loss=0.023690\n",
            "Batch 1910: batch_loss=0.022648\n",
            "Batch 1920: batch_loss=0.029086\n",
            "Batch 1930: batch_loss=0.028188\n",
            "Batch 1940: batch_loss=0.030283\n",
            "Batch 1950: batch_loss=0.035794\n",
            "Batch 1960: batch_loss=0.020379\n",
            "Batch 1970: batch_loss=0.030428\n",
            "Batch 1980: batch_loss=0.026527\n",
            "Batch 1990: batch_loss=0.031008\n",
            "Batch 2000: batch_loss=0.025862\n",
            "Batch 2010: batch_loss=0.021826\n",
            "Batch 2020: batch_loss=0.022235\n",
            "Batch 2030: batch_loss=0.023092\n",
            "Batch 2040: batch_loss=0.021374\n",
            "Batch 2050: batch_loss=0.023332\n",
            "Batch 2060: batch_loss=0.029348\n",
            "Batch 2070: batch_loss=0.027088\n",
            "Batch 2080: batch_loss=0.018763\n",
            "Batch 2090: batch_loss=0.027529\n",
            "Batch 2100: batch_loss=0.030039\n",
            "Batch 2110: batch_loss=0.025055\n",
            "Batch 2120: batch_loss=0.025267\n",
            "Batch 2130: batch_loss=0.022596\n",
            "Batch 2140: batch_loss=0.025241\n",
            "Batch 2150: batch_loss=0.024535\n",
            "Batch 2160: batch_loss=0.022076\n",
            "Batch 2170: batch_loss=0.020644\n",
            "Batch 2180: batch_loss=0.027324\n",
            "Batch 2190: batch_loss=0.033270\n",
            "Batch 2200: batch_loss=0.033846\n",
            "Batch 2210: batch_loss=0.039482\n",
            "Batch 2220: batch_loss=0.028261\n",
            "Batch 2230: batch_loss=0.027154\n",
            "Batch 2240: batch_loss=0.022532\n",
            "Batch 2250: batch_loss=0.025896\n",
            "Batch 2260: batch_loss=0.031868\n",
            "Batch 2270: batch_loss=0.020355\n",
            "Batch 2280: batch_loss=0.023886\n",
            "Batch 2290: batch_loss=0.020011\n",
            "Batch 2300: batch_loss=0.023671\n",
            "Batch 2310: batch_loss=0.024946\n",
            "Batch 2320: batch_loss=0.026138\n",
            "Batch 2330: batch_loss=0.028016\n",
            "Batch 2340: batch_loss=0.021707\n",
            "Batch 2350: batch_loss=0.026052\n",
            "Batch 2360: batch_loss=0.026702\n",
            "Batch 2370: batch_loss=0.023571\n",
            "Batch 2380: batch_loss=0.024821\n",
            "Batch 2390: batch_loss=0.024174\n",
            "Batch 2400: batch_loss=0.024217\n",
            "Batch 2410: batch_loss=0.028272\n",
            "Batch 2420: batch_loss=0.026742\n",
            "Batch 2430: batch_loss=0.033770\n",
            "Batch 2440: batch_loss=0.023412\n",
            "Batch 2450: batch_loss=0.020091\n",
            "Batch 2460: batch_loss=0.026369\n",
            "Batch 2470: batch_loss=0.026622\n",
            "Batch 2480: batch_loss=0.026790\n",
            "Batch 2490: batch_loss=0.029046\n",
            "Batch 2500: batch_loss=0.021973\n",
            "Batch 2510: batch_loss=0.023670\n",
            "Batch 2520: batch_loss=0.024115\n",
            "Batch 2530: batch_loss=0.027772\n",
            "Batch 2540: batch_loss=0.027180\n",
            "Batch 2550: batch_loss=0.025723\n",
            "Batch 2560: batch_loss=0.025280\n",
            "Batch 2570: batch_loss=0.030443\n",
            "Batch 2580: batch_loss=0.027606\n",
            "Batch 2590: batch_loss=0.021338\n",
            "Batch 2600: batch_loss=0.027939\n",
            "Batch 2610: batch_loss=0.025925\n",
            "Batch 2620: batch_loss=0.024417\n",
            "Batch 2630: batch_loss=0.029053\n",
            "Batch 2640: batch_loss=0.027826\n",
            "Batch 2650: batch_loss=0.026460\n",
            "Batch 2660: batch_loss=0.021066\n",
            "Batch 2670: batch_loss=0.027502\n",
            "Batch 2680: batch_loss=0.023752\n",
            "Batch 2690: batch_loss=0.022524\n",
            "Batch 2700: batch_loss=0.026999\n",
            "Batch 2710: batch_loss=0.023458\n",
            "Batch 2720: batch_loss=0.026204\n",
            "Batch 2730: batch_loss=0.021159\n",
            "Batch 2740: batch_loss=0.028070\n",
            "Batch 2750: batch_loss=0.025117\n",
            "Batch 2760: batch_loss=0.024294\n",
            "Batch 2770: batch_loss=0.027865\n",
            "Batch 2780: batch_loss=0.030784\n",
            "Batch 2790: batch_loss=0.027515\n",
            "Batch 2800: batch_loss=0.025110\n",
            "Batch 2810: batch_loss=0.027646\n",
            "Batch 2820: batch_loss=0.025810\n",
            "Batch 2830: batch_loss=0.031404\n",
            "Batch 2840: batch_loss=0.036073\n",
            "Batch 2850: batch_loss=0.028123\n",
            "Batch 2860: batch_loss=0.034649\n",
            "Batch 2870: batch_loss=0.020759\n",
            "Batch 2880: batch_loss=0.023761\n",
            "Batch 2890: batch_loss=0.031370\n",
            "Batch 2900: batch_loss=0.027600\n",
            "Batch 2910: batch_loss=0.025605\n",
            "Batch 2920: batch_loss=0.028569\n",
            "Batch 2930: batch_loss=0.024883\n",
            "Batch 2940: batch_loss=0.021396\n",
            "Batch 2950: batch_loss=0.022586\n",
            "Batch 2960: batch_loss=0.025841\n",
            "Batch 2970: batch_loss=0.026874\n",
            "Batch 2980: batch_loss=0.025935\n",
            "Batch 2990: batch_loss=0.025850\n",
            "Batch 3000: batch_loss=0.026860\n",
            "Batch 3010: batch_loss=0.025987\n",
            "Batch 3020: batch_loss=0.021252\n",
            "Batch 3030: batch_loss=0.032244\n",
            "Batch 3040: batch_loss=0.024954\n",
            "Batch 3050: batch_loss=0.025484\n",
            "Batch 3060: batch_loss=0.033140\n",
            "Batch 3070: batch_loss=0.024635\n",
            "Batch 3080: batch_loss=0.022583\n",
            "Batch 3090: batch_loss=0.027698\n",
            "Batch 3100: batch_loss=0.028607\n",
            "Batch 3110: batch_loss=0.031231\n",
            "Batch 3120: batch_loss=0.025315\n",
            "Batch 3130: batch_loss=0.022473\n",
            "Batch 3140: batch_loss=0.034823\n",
            "Batch 3150: batch_loss=0.025488\n",
            "Batch 3160: batch_loss=0.026744\n",
            "Batch 3170: batch_loss=0.026155\n",
            "Batch 3180: batch_loss=0.022505\n",
            "Batch 3190: batch_loss=0.024947\n",
            "Batch 3200: batch_loss=0.026645\n",
            "Batch 3210: batch_loss=0.032151\n",
            "Batch 3220: batch_loss=0.026301\n",
            "Batch 3230: batch_loss=0.030438\n",
            "Batch 3240: batch_loss=0.025594\n",
            "Batch 3250: batch_loss=0.027224\n",
            "Batch 3260: batch_loss=0.024464\n",
            "Batch 3270: batch_loss=0.025600\n",
            "Batch 3280: batch_loss=0.020913\n",
            "Batch 3290: batch_loss=0.023800\n",
            "Batch 3300: batch_loss=0.031772\n",
            "Batch 3310: batch_loss=0.023990\n",
            "Batch 3320: batch_loss=0.030347\n",
            "Batch 3330: batch_loss=0.026452\n",
            "Batch 3340: batch_loss=0.031917\n",
            "Batch 3350: batch_loss=0.025282\n",
            "Batch 3360: batch_loss=0.023281\n",
            "Batch 3370: batch_loss=0.027452\n",
            "Batch 3380: batch_loss=0.022845\n",
            "Batch 3390: batch_loss=0.020396\n",
            "Batch 3400: batch_loss=0.024576\n",
            "Batch 3410: batch_loss=0.025980\n",
            "Batch 3420: batch_loss=0.023850\n",
            "Batch 3430: batch_loss=0.029577\n",
            "Batch 3440: batch_loss=0.026638\n",
            "Batch 3450: batch_loss=0.028313\n",
            "Batch 3460: batch_loss=0.031196\n",
            "Batch 3470: batch_loss=0.028647\n",
            "Batch 3480: batch_loss=0.025989\n",
            "Batch 3490: batch_loss=0.024709\n",
            "Batch 3500: batch_loss=0.023178\n",
            "Batch 3510: batch_loss=0.024364\n",
            "Batch 3520: batch_loss=0.030652\n",
            "Batch 3530: batch_loss=0.027862\n",
            "Batch 3540: batch_loss=0.025360\n",
            "Batch 3550: batch_loss=0.026373\n",
            "Batch 3560: batch_loss=0.029950\n",
            "Batch 3570: batch_loss=0.030780\n",
            "Batch 3580: batch_loss=0.026653\n",
            "Batch 3590: batch_loss=0.022714\n",
            "Batch 3600: batch_loss=0.029377\n",
            "Batch 3610: batch_loss=0.022021\n",
            "Batch 3620: batch_loss=0.034994\n",
            "Batch 3630: batch_loss=0.030601\n",
            "Batch 3640: batch_loss=0.026448\n",
            "Batch 3650: batch_loss=0.027368\n",
            "Batch 3660: batch_loss=0.027384\n",
            "Batch 3670: batch_loss=0.025646\n",
            "Batch 3680: batch_loss=0.027901\n",
            "Batch 3690: batch_loss=0.022800\n",
            "Batch 3700: batch_loss=0.033656\n",
            "Batch 3710: batch_loss=0.036994\n",
            "Batch 3720: batch_loss=0.032944\n",
            "Epoch 7/10, Train Loss: 0.026648, Val Loss: 0.016631\n",
            "Batch 0: batch_loss=0.024674\n",
            "Batch 10: batch_loss=0.024560\n",
            "Batch 20: batch_loss=0.022258\n",
            "Batch 30: batch_loss=0.024281\n",
            "Batch 40: batch_loss=0.021472\n",
            "Batch 50: batch_loss=0.025289\n",
            "Batch 60: batch_loss=0.023119\n",
            "Batch 70: batch_loss=0.027985\n",
            "Batch 80: batch_loss=0.022895\n",
            "Batch 90: batch_loss=0.029331\n",
            "Batch 100: batch_loss=0.021546\n",
            "Batch 110: batch_loss=0.028991\n",
            "Batch 120: batch_loss=0.034330\n",
            "Batch 130: batch_loss=0.025298\n",
            "Batch 140: batch_loss=0.029525\n",
            "Batch 150: batch_loss=0.026294\n",
            "Batch 160: batch_loss=0.027865\n",
            "Batch 170: batch_loss=0.031387\n",
            "Batch 180: batch_loss=0.023141\n",
            "Batch 190: batch_loss=0.025005\n",
            "Batch 200: batch_loss=0.027383\n",
            "Batch 210: batch_loss=0.018058\n",
            "Batch 220: batch_loss=0.023567\n",
            "Batch 230: batch_loss=0.027718\n",
            "Batch 240: batch_loss=0.031278\n",
            "Batch 250: batch_loss=0.027115\n",
            "Batch 260: batch_loss=0.022586\n",
            "Batch 270: batch_loss=0.023955\n",
            "Batch 280: batch_loss=0.027074\n",
            "Batch 290: batch_loss=0.026710\n",
            "Batch 300: batch_loss=0.023840\n",
            "Batch 310: batch_loss=0.027104\n",
            "Batch 320: batch_loss=0.034344\n",
            "Batch 330: batch_loss=0.025981\n",
            "Batch 340: batch_loss=0.027693\n",
            "Batch 350: batch_loss=0.028260\n",
            "Batch 360: batch_loss=0.026577\n",
            "Batch 370: batch_loss=0.026942\n",
            "Batch 380: batch_loss=0.030143\n",
            "Batch 390: batch_loss=0.030093\n",
            "Batch 400: batch_loss=0.024058\n",
            "Batch 410: batch_loss=0.029886\n",
            "Batch 420: batch_loss=0.024978\n",
            "Batch 430: batch_loss=0.020281\n",
            "Batch 440: batch_loss=0.026517\n",
            "Batch 450: batch_loss=0.028591\n",
            "Batch 460: batch_loss=0.025594\n",
            "Batch 470: batch_loss=0.029546\n",
            "Batch 480: batch_loss=0.027441\n",
            "Batch 490: batch_loss=0.025295\n",
            "Batch 500: batch_loss=0.023798\n",
            "Batch 510: batch_loss=0.028784\n",
            "Batch 520: batch_loss=0.027723\n",
            "Batch 530: batch_loss=0.028787\n",
            "Batch 540: batch_loss=0.025174\n",
            "Batch 550: batch_loss=0.028289\n",
            "Batch 560: batch_loss=0.028214\n",
            "Batch 570: batch_loss=0.028184\n",
            "Batch 580: batch_loss=0.030522\n",
            "Batch 590: batch_loss=0.026266\n",
            "Batch 600: batch_loss=0.023884\n",
            "Batch 610: batch_loss=0.029564\n",
            "Batch 620: batch_loss=0.024953\n",
            "Batch 630: batch_loss=0.025963\n",
            "Batch 640: batch_loss=0.025777\n",
            "Batch 650: batch_loss=0.031425\n",
            "Batch 660: batch_loss=0.027832\n",
            "Batch 670: batch_loss=0.022598\n",
            "Batch 680: batch_loss=0.027236\n",
            "Batch 690: batch_loss=0.022140\n",
            "Batch 700: batch_loss=0.031901\n",
            "Batch 710: batch_loss=0.022916\n",
            "Batch 720: batch_loss=0.038167\n",
            "Batch 730: batch_loss=0.026907\n",
            "Batch 740: batch_loss=0.029292\n",
            "Batch 750: batch_loss=0.027043\n",
            "Batch 760: batch_loss=0.025650\n",
            "Batch 770: batch_loss=0.022734\n",
            "Batch 780: batch_loss=0.029476\n",
            "Batch 790: batch_loss=0.026788\n",
            "Batch 800: batch_loss=0.020198\n",
            "Batch 810: batch_loss=0.028128\n",
            "Batch 820: batch_loss=0.025529\n",
            "Batch 830: batch_loss=0.024916\n",
            "Batch 840: batch_loss=0.027016\n",
            "Batch 850: batch_loss=0.023753\n",
            "Batch 860: batch_loss=0.024159\n",
            "Batch 870: batch_loss=0.026549\n",
            "Batch 880: batch_loss=0.022490\n",
            "Batch 890: batch_loss=0.028134\n",
            "Batch 900: batch_loss=0.030475\n",
            "Batch 910: batch_loss=0.027106\n",
            "Batch 920: batch_loss=0.030409\n",
            "Batch 930: batch_loss=0.029188\n",
            "Batch 940: batch_loss=0.030848\n",
            "Batch 950: batch_loss=0.026961\n",
            "Batch 960: batch_loss=0.028182\n",
            "Batch 970: batch_loss=0.026684\n",
            "Batch 980: batch_loss=0.031525\n",
            "Batch 990: batch_loss=0.025412\n",
            "Batch 1000: batch_loss=0.022242\n",
            "Batch 1010: batch_loss=0.031511\n",
            "Batch 1020: batch_loss=0.025458\n",
            "Batch 1030: batch_loss=0.027759\n",
            "Batch 1040: batch_loss=0.018905\n",
            "Batch 1050: batch_loss=0.025166\n",
            "Batch 1060: batch_loss=0.026168\n",
            "Batch 1070: batch_loss=0.029856\n",
            "Batch 1080: batch_loss=0.019083\n",
            "Batch 1090: batch_loss=0.026662\n",
            "Batch 1100: batch_loss=0.026025\n",
            "Batch 1110: batch_loss=0.026901\n",
            "Batch 1120: batch_loss=0.024160\n",
            "Batch 1130: batch_loss=0.024264\n",
            "Batch 1140: batch_loss=0.021480\n",
            "Batch 1150: batch_loss=0.032977\n",
            "Batch 1160: batch_loss=0.028731\n",
            "Batch 1170: batch_loss=0.025382\n",
            "Batch 1180: batch_loss=0.028434\n",
            "Batch 1190: batch_loss=0.020863\n",
            "Batch 1200: batch_loss=0.021259\n",
            "Batch 1210: batch_loss=0.022260\n",
            "Batch 1220: batch_loss=0.025358\n",
            "Batch 1230: batch_loss=0.025836\n",
            "Batch 1240: batch_loss=0.026013\n",
            "Batch 1250: batch_loss=0.030841\n",
            "Batch 1260: batch_loss=0.031701\n",
            "Batch 1270: batch_loss=0.030108\n",
            "Batch 1280: batch_loss=0.027769\n",
            "Batch 1290: batch_loss=0.026197\n",
            "Batch 1300: batch_loss=0.028810\n",
            "Batch 1310: batch_loss=0.023174\n",
            "Batch 1320: batch_loss=0.026221\n",
            "Batch 1330: batch_loss=0.025453\n",
            "Batch 1340: batch_loss=0.023000\n",
            "Batch 1350: batch_loss=0.024275\n",
            "Batch 1360: batch_loss=0.022519\n",
            "Batch 1370: batch_loss=0.026122\n",
            "Batch 1380: batch_loss=0.024749\n",
            "Batch 1390: batch_loss=0.032595\n",
            "Batch 1400: batch_loss=0.028404\n",
            "Batch 1410: batch_loss=0.031145\n",
            "Batch 1420: batch_loss=0.024839\n",
            "Batch 1430: batch_loss=0.027581\n",
            "Batch 1440: batch_loss=0.022146\n",
            "Batch 1450: batch_loss=0.021317\n",
            "Batch 1460: batch_loss=0.030635\n",
            "Batch 1470: batch_loss=0.031358\n",
            "Batch 1480: batch_loss=0.026668\n",
            "Batch 1490: batch_loss=0.022786\n",
            "Batch 1500: batch_loss=0.024813\n",
            "Batch 1510: batch_loss=0.024981\n",
            "Batch 1520: batch_loss=0.029266\n",
            "Batch 1530: batch_loss=0.022936\n",
            "Batch 1540: batch_loss=0.036419\n",
            "Batch 1550: batch_loss=0.029046\n",
            "Batch 1560: batch_loss=0.022789\n",
            "Batch 1570: batch_loss=0.026974\n",
            "Batch 1580: batch_loss=0.023742\n",
            "Batch 1590: batch_loss=0.020931\n",
            "Batch 1600: batch_loss=0.026808\n",
            "Batch 1610: batch_loss=0.024170\n",
            "Batch 1620: batch_loss=0.032324\n",
            "Batch 1630: batch_loss=0.028377\n",
            "Batch 1640: batch_loss=0.028715\n",
            "Batch 1650: batch_loss=0.025611\n",
            "Batch 1660: batch_loss=0.030908\n",
            "Batch 1670: batch_loss=0.019818\n",
            "Batch 1680: batch_loss=0.028767\n",
            "Batch 1690: batch_loss=0.025809\n",
            "Batch 1700: batch_loss=0.028353\n",
            "Batch 1710: batch_loss=0.025754\n",
            "Batch 1720: batch_loss=0.020595\n",
            "Batch 1730: batch_loss=0.021226\n",
            "Batch 1740: batch_loss=0.022480\n",
            "Batch 1750: batch_loss=0.029628\n",
            "Batch 1760: batch_loss=0.024825\n",
            "Batch 1770: batch_loss=0.028118\n",
            "Batch 1780: batch_loss=0.028063\n",
            "Batch 1790: batch_loss=0.025217\n",
            "Batch 1800: batch_loss=0.022355\n",
            "Batch 1810: batch_loss=0.025499\n",
            "Batch 1820: batch_loss=0.028531\n",
            "Batch 1830: batch_loss=0.024658\n",
            "Batch 1840: batch_loss=0.027443\n",
            "Batch 1850: batch_loss=0.025682\n",
            "Batch 1860: batch_loss=0.024684\n",
            "Batch 1870: batch_loss=0.026178\n",
            "Batch 1880: batch_loss=0.022891\n",
            "Batch 1890: batch_loss=0.020024\n",
            "Batch 1900: batch_loss=0.027890\n",
            "Batch 1910: batch_loss=0.023596\n",
            "Batch 1920: batch_loss=0.025659\n",
            "Batch 1930: batch_loss=0.027969\n",
            "Batch 1940: batch_loss=0.032040\n",
            "Batch 1950: batch_loss=0.023856\n",
            "Batch 1960: batch_loss=0.035380\n",
            "Batch 1970: batch_loss=0.030022\n",
            "Batch 1980: batch_loss=0.029019\n",
            "Batch 1990: batch_loss=0.025963\n",
            "Batch 2000: batch_loss=0.025718\n",
            "Batch 2010: batch_loss=0.021232\n",
            "Batch 2020: batch_loss=0.029705\n",
            "Batch 2030: batch_loss=0.031789\n",
            "Batch 2040: batch_loss=0.030627\n",
            "Batch 2050: batch_loss=0.022215\n",
            "Batch 2060: batch_loss=0.024399\n",
            "Batch 2070: batch_loss=0.042685\n",
            "Batch 2080: batch_loss=0.026370\n",
            "Batch 2090: batch_loss=0.031192\n",
            "Batch 2100: batch_loss=0.022661\n",
            "Batch 2110: batch_loss=0.027434\n",
            "Batch 2120: batch_loss=0.022758\n",
            "Batch 2130: batch_loss=0.033493\n",
            "Batch 2140: batch_loss=0.025885\n",
            "Batch 2150: batch_loss=0.022147\n",
            "Batch 2160: batch_loss=0.024360\n",
            "Batch 2170: batch_loss=0.031038\n",
            "Batch 2180: batch_loss=0.023726\n",
            "Batch 2190: batch_loss=0.023655\n",
            "Batch 2200: batch_loss=0.026096\n",
            "Batch 2210: batch_loss=0.023593\n",
            "Batch 2220: batch_loss=0.028147\n",
            "Batch 2230: batch_loss=0.025653\n",
            "Batch 2240: batch_loss=0.022155\n",
            "Batch 2250: batch_loss=0.028302\n",
            "Batch 2260: batch_loss=0.028591\n",
            "Batch 2270: batch_loss=0.035619\n",
            "Batch 2280: batch_loss=0.024549\n",
            "Batch 2290: batch_loss=0.032353\n",
            "Batch 2300: batch_loss=0.026130\n",
            "Batch 2310: batch_loss=0.027393\n",
            "Batch 2320: batch_loss=0.028324\n",
            "Batch 2330: batch_loss=0.023121\n",
            "Batch 2340: batch_loss=0.025607\n",
            "Batch 2350: batch_loss=0.030469\n",
            "Batch 2360: batch_loss=0.025199\n",
            "Batch 2370: batch_loss=0.026228\n",
            "Batch 2380: batch_loss=0.035972\n",
            "Batch 2390: batch_loss=0.025665\n",
            "Batch 2400: batch_loss=0.028421\n",
            "Batch 2410: batch_loss=0.023356\n",
            "Batch 2420: batch_loss=0.030237\n",
            "Batch 2430: batch_loss=0.025955\n",
            "Batch 2440: batch_loss=0.029301\n",
            "Batch 2450: batch_loss=0.025706\n",
            "Batch 2460: batch_loss=0.030518\n",
            "Batch 2470: batch_loss=0.022212\n",
            "Batch 2480: batch_loss=0.021254\n",
            "Batch 2490: batch_loss=0.020556\n",
            "Batch 2500: batch_loss=0.030102\n",
            "Batch 2510: batch_loss=0.033228\n",
            "Batch 2520: batch_loss=0.024849\n",
            "Batch 2530: batch_loss=0.021752\n",
            "Batch 2540: batch_loss=0.027555\n",
            "Batch 2550: batch_loss=0.021060\n",
            "Batch 2560: batch_loss=0.029241\n",
            "Batch 2570: batch_loss=0.026945\n",
            "Batch 2580: batch_loss=0.028748\n",
            "Batch 2590: batch_loss=0.026308\n",
            "Batch 2600: batch_loss=0.020472\n",
            "Batch 2610: batch_loss=0.030439\n",
            "Batch 2620: batch_loss=0.025726\n",
            "Batch 2630: batch_loss=0.021968\n",
            "Batch 2640: batch_loss=0.036582\n",
            "Batch 2650: batch_loss=0.026509\n",
            "Batch 2660: batch_loss=0.027935\n",
            "Batch 2670: batch_loss=0.029102\n",
            "Batch 2680: batch_loss=0.026555\n",
            "Batch 2690: batch_loss=0.024652\n",
            "Batch 2700: batch_loss=0.026576\n",
            "Batch 2710: batch_loss=0.023719\n",
            "Batch 2720: batch_loss=0.021981\n",
            "Batch 2730: batch_loss=0.026794\n",
            "Batch 2740: batch_loss=0.031558\n",
            "Batch 2750: batch_loss=0.034434\n",
            "Batch 2760: batch_loss=0.027742\n",
            "Batch 2770: batch_loss=0.033917\n",
            "Batch 2780: batch_loss=0.022318\n",
            "Batch 2790: batch_loss=0.021264\n",
            "Batch 2800: batch_loss=0.027738\n",
            "Batch 2810: batch_loss=0.029991\n",
            "Batch 2820: batch_loss=0.029079\n",
            "Batch 2830: batch_loss=0.030977\n",
            "Batch 2840: batch_loss=0.029420\n",
            "Batch 2850: batch_loss=0.022529\n",
            "Batch 2860: batch_loss=0.023112\n",
            "Batch 2870: batch_loss=0.030896\n",
            "Batch 2880: batch_loss=0.029821\n",
            "Batch 2890: batch_loss=0.024938\n",
            "Batch 2900: batch_loss=0.024112\n",
            "Batch 2910: batch_loss=0.027523\n",
            "Batch 2920: batch_loss=0.026871\n",
            "Batch 2930: batch_loss=0.024592\n",
            "Batch 2940: batch_loss=0.024201\n",
            "Batch 2950: batch_loss=0.033238\n",
            "Batch 2960: batch_loss=0.024108\n",
            "Batch 2970: batch_loss=0.028307\n",
            "Batch 2980: batch_loss=0.029473\n",
            "Batch 2990: batch_loss=0.023636\n",
            "Batch 3000: batch_loss=0.025728\n",
            "Batch 3010: batch_loss=0.023248\n",
            "Batch 3020: batch_loss=0.025041\n",
            "Batch 3030: batch_loss=0.032116\n",
            "Batch 3040: batch_loss=0.022911\n",
            "Batch 3050: batch_loss=0.028298\n",
            "Batch 3060: batch_loss=0.024004\n",
            "Batch 3070: batch_loss=0.026444\n",
            "Batch 3080: batch_loss=0.023673\n",
            "Batch 3090: batch_loss=0.025461\n",
            "Batch 3100: batch_loss=0.029063\n",
            "Batch 3110: batch_loss=0.026426\n",
            "Batch 3120: batch_loss=0.035886\n",
            "Batch 3130: batch_loss=0.028750\n",
            "Batch 3140: batch_loss=0.023502\n",
            "Batch 3150: batch_loss=0.021915\n",
            "Batch 3160: batch_loss=0.024868\n",
            "Batch 3170: batch_loss=0.021085\n",
            "Batch 3180: batch_loss=0.026566\n",
            "Batch 3190: batch_loss=0.026458\n",
            "Batch 3200: batch_loss=0.029629\n",
            "Batch 3210: batch_loss=0.022372\n",
            "Batch 3220: batch_loss=0.021423\n",
            "Batch 3230: batch_loss=0.028899\n",
            "Batch 3240: batch_loss=0.021985\n",
            "Batch 3250: batch_loss=0.024358\n",
            "Batch 3260: batch_loss=0.023583\n",
            "Batch 3270: batch_loss=0.022108\n",
            "Batch 3280: batch_loss=0.023783\n",
            "Batch 3290: batch_loss=0.025717\n",
            "Batch 3300: batch_loss=0.031825\n",
            "Batch 3310: batch_loss=0.025800\n",
            "Batch 3320: batch_loss=0.023007\n",
            "Batch 3330: batch_loss=0.029307\n",
            "Batch 3340: batch_loss=0.026209\n",
            "Batch 3350: batch_loss=0.027665\n",
            "Batch 3360: batch_loss=0.023107\n",
            "Batch 3370: batch_loss=0.024620\n",
            "Batch 3380: batch_loss=0.034415\n",
            "Batch 3390: batch_loss=0.027718\n",
            "Batch 3400: batch_loss=0.026293\n",
            "Batch 3410: batch_loss=0.028183\n",
            "Batch 3420: batch_loss=0.027791\n",
            "Batch 3430: batch_loss=0.028903\n",
            "Batch 3440: batch_loss=0.030234\n",
            "Batch 3450: batch_loss=0.024732\n",
            "Batch 3460: batch_loss=0.026575\n",
            "Batch 3470: batch_loss=0.024332\n",
            "Batch 3480: batch_loss=0.027406\n",
            "Batch 3490: batch_loss=0.027123\n",
            "Batch 3500: batch_loss=0.025808\n",
            "Batch 3510: batch_loss=0.029905\n",
            "Batch 3520: batch_loss=0.022571\n",
            "Batch 3530: batch_loss=0.022922\n",
            "Batch 3540: batch_loss=0.025508\n",
            "Batch 3550: batch_loss=0.026019\n",
            "Batch 3560: batch_loss=0.024824\n",
            "Batch 3570: batch_loss=0.029593\n",
            "Batch 3580: batch_loss=0.020552\n",
            "Batch 3590: batch_loss=0.031942\n",
            "Batch 3600: batch_loss=0.026093\n",
            "Batch 3610: batch_loss=0.025145\n",
            "Batch 3620: batch_loss=0.021319\n",
            "Batch 3630: batch_loss=0.021521\n",
            "Batch 3640: batch_loss=0.026756\n",
            "Batch 3650: batch_loss=0.027534\n",
            "Batch 3660: batch_loss=0.030802\n",
            "Batch 3670: batch_loss=0.026113\n",
            "Batch 3680: batch_loss=0.027917\n",
            "Batch 3690: batch_loss=0.023027\n",
            "Batch 3700: batch_loss=0.024520\n",
            "Batch 3710: batch_loss=0.024355\n",
            "Batch 3720: batch_loss=0.034223\n",
            "Epoch 8/10, Train Loss: 0.026648, Val Loss: 0.016631\n",
            "Batch 0: batch_loss=0.028065\n",
            "Batch 10: batch_loss=0.023786\n",
            "Batch 20: batch_loss=0.021972\n",
            "Batch 30: batch_loss=0.021904\n",
            "Batch 40: batch_loss=0.022951\n",
            "Batch 50: batch_loss=0.026900\n",
            "Batch 60: batch_loss=0.025098\n",
            "Batch 70: batch_loss=0.029023\n",
            "Batch 80: batch_loss=0.022899\n",
            "Batch 90: batch_loss=0.022073\n",
            "Batch 100: batch_loss=0.024024\n",
            "Batch 110: batch_loss=0.026824\n",
            "Batch 120: batch_loss=0.027547\n",
            "Batch 130: batch_loss=0.028583\n",
            "Batch 140: batch_loss=0.028100\n",
            "Batch 150: batch_loss=0.026097\n",
            "Batch 160: batch_loss=0.032607\n",
            "Batch 170: batch_loss=0.032161\n",
            "Batch 180: batch_loss=0.031095\n",
            "Batch 190: batch_loss=0.039034\n",
            "Batch 200: batch_loss=0.027178\n",
            "Batch 210: batch_loss=0.027411\n",
            "Batch 220: batch_loss=0.025477\n",
            "Batch 230: batch_loss=0.033708\n",
            "Batch 240: batch_loss=0.021464\n",
            "Batch 250: batch_loss=0.024575\n",
            "Batch 260: batch_loss=0.022742\n",
            "Batch 270: batch_loss=0.030855\n",
            "Batch 280: batch_loss=0.027740\n",
            "Batch 290: batch_loss=0.028684\n",
            "Batch 300: batch_loss=0.024125\n",
            "Batch 310: batch_loss=0.026966\n",
            "Batch 320: batch_loss=0.028850\n",
            "Batch 330: batch_loss=0.024635\n",
            "Batch 340: batch_loss=0.026644\n",
            "Batch 350: batch_loss=0.024369\n",
            "Batch 360: batch_loss=0.037057\n",
            "Batch 370: batch_loss=0.032807\n",
            "Batch 380: batch_loss=0.023567\n",
            "Batch 390: batch_loss=0.028542\n",
            "Batch 400: batch_loss=0.023471\n",
            "Batch 410: batch_loss=0.022110\n",
            "Batch 420: batch_loss=0.029227\n",
            "Batch 430: batch_loss=0.024241\n",
            "Batch 440: batch_loss=0.028683\n",
            "Batch 450: batch_loss=0.026974\n",
            "Batch 460: batch_loss=0.024208\n",
            "Batch 470: batch_loss=0.022621\n",
            "Batch 480: batch_loss=0.024229\n",
            "Batch 490: batch_loss=0.027003\n",
            "Batch 500: batch_loss=0.023628\n",
            "Batch 510: batch_loss=0.024299\n",
            "Batch 520: batch_loss=0.032238\n",
            "Batch 530: batch_loss=0.021172\n",
            "Batch 540: batch_loss=0.028340\n",
            "Batch 550: batch_loss=0.028776\n",
            "Batch 560: batch_loss=0.020753\n",
            "Batch 570: batch_loss=0.032284\n",
            "Batch 580: batch_loss=0.023391\n",
            "Batch 590: batch_loss=0.034872\n",
            "Batch 600: batch_loss=0.022498\n",
            "Batch 610: batch_loss=0.024687\n",
            "Batch 620: batch_loss=0.026010\n",
            "Batch 630: batch_loss=0.032138\n",
            "Batch 640: batch_loss=0.022941\n",
            "Batch 650: batch_loss=0.020321\n",
            "Batch 660: batch_loss=0.034340\n",
            "Batch 670: batch_loss=0.027044\n",
            "Batch 680: batch_loss=0.031942\n",
            "Batch 690: batch_loss=0.026025\n",
            "Batch 700: batch_loss=0.025064\n",
            "Batch 710: batch_loss=0.028716\n",
            "Batch 720: batch_loss=0.025411\n",
            "Batch 730: batch_loss=0.027081\n",
            "Batch 740: batch_loss=0.023900\n",
            "Batch 750: batch_loss=0.027554\n",
            "Batch 760: batch_loss=0.020030\n",
            "Batch 770: batch_loss=0.028288\n",
            "Batch 780: batch_loss=0.026807\n",
            "Batch 790: batch_loss=0.024493\n",
            "Batch 800: batch_loss=0.020336\n",
            "Batch 810: batch_loss=0.033546\n",
            "Batch 820: batch_loss=0.025431\n",
            "Batch 830: batch_loss=0.026819\n",
            "Batch 840: batch_loss=0.028245\n",
            "Batch 850: batch_loss=0.020285\n",
            "Batch 860: batch_loss=0.022124\n",
            "Batch 870: batch_loss=0.026802\n",
            "Batch 880: batch_loss=0.028058\n",
            "Batch 890: batch_loss=0.022135\n",
            "Batch 900: batch_loss=0.023882\n",
            "Batch 910: batch_loss=0.024606\n",
            "Batch 920: batch_loss=0.029772\n",
            "Batch 930: batch_loss=0.025062\n",
            "Batch 940: batch_loss=0.021891\n",
            "Batch 950: batch_loss=0.026341\n",
            "Batch 960: batch_loss=0.032230\n",
            "Batch 970: batch_loss=0.021482\n",
            "Batch 980: batch_loss=0.025372\n",
            "Batch 990: batch_loss=0.027794\n",
            "Batch 1000: batch_loss=0.031125\n",
            "Batch 1010: batch_loss=0.021020\n",
            "Batch 1020: batch_loss=0.020040\n",
            "Batch 1030: batch_loss=0.026790\n",
            "Batch 1040: batch_loss=0.024496\n",
            "Batch 1050: batch_loss=0.034603\n",
            "Batch 1060: batch_loss=0.027958\n",
            "Batch 1070: batch_loss=0.027391\n",
            "Batch 1080: batch_loss=0.026653\n",
            "Batch 1090: batch_loss=0.026671\n",
            "Batch 1100: batch_loss=0.025562\n",
            "Batch 1110: batch_loss=0.029537\n",
            "Batch 1120: batch_loss=0.023250\n",
            "Batch 1130: batch_loss=0.023348\n",
            "Batch 1140: batch_loss=0.023668\n",
            "Batch 1150: batch_loss=0.029563\n",
            "Batch 1160: batch_loss=0.023830\n",
            "Batch 1170: batch_loss=0.028668\n",
            "Batch 1180: batch_loss=0.026580\n",
            "Batch 1190: batch_loss=0.026775\n",
            "Batch 1200: batch_loss=0.024194\n",
            "Batch 1210: batch_loss=0.025951\n",
            "Batch 1220: batch_loss=0.026858\n",
            "Batch 1230: batch_loss=0.028583\n",
            "Batch 1240: batch_loss=0.025642\n",
            "Batch 1250: batch_loss=0.031628\n",
            "Batch 1260: batch_loss=0.019530\n",
            "Batch 1270: batch_loss=0.023889\n",
            "Batch 1280: batch_loss=0.029479\n",
            "Batch 1290: batch_loss=0.025276\n",
            "Batch 1300: batch_loss=0.028006\n",
            "Batch 1310: batch_loss=0.031328\n",
            "Batch 1320: batch_loss=0.030491\n",
            "Batch 1330: batch_loss=0.021875\n",
            "Batch 1340: batch_loss=0.028654\n",
            "Batch 1350: batch_loss=0.028813\n",
            "Batch 1360: batch_loss=0.021522\n",
            "Batch 1370: batch_loss=0.032736\n",
            "Batch 1380: batch_loss=0.035496\n",
            "Batch 1390: batch_loss=0.025471\n",
            "Batch 1400: batch_loss=0.025278\n",
            "Batch 1410: batch_loss=0.022687\n",
            "Batch 1420: batch_loss=0.031118\n",
            "Batch 1430: batch_loss=0.030732\n",
            "Batch 1440: batch_loss=0.022578\n",
            "Batch 1450: batch_loss=0.032847\n",
            "Batch 1460: batch_loss=0.026688\n",
            "Batch 1470: batch_loss=0.029293\n",
            "Batch 1480: batch_loss=0.032325\n",
            "Batch 1490: batch_loss=0.024503\n",
            "Batch 1500: batch_loss=0.023775\n",
            "Batch 1510: batch_loss=0.025404\n",
            "Batch 1520: batch_loss=0.026040\n",
            "Batch 1530: batch_loss=0.033679\n",
            "Batch 1540: batch_loss=0.032907\n",
            "Batch 1550: batch_loss=0.032175\n",
            "Batch 1560: batch_loss=0.032770\n",
            "Batch 1570: batch_loss=0.025500\n",
            "Batch 1580: batch_loss=0.023905\n",
            "Batch 1590: batch_loss=0.021798\n",
            "Batch 1600: batch_loss=0.029277\n",
            "Batch 1610: batch_loss=0.027359\n",
            "Batch 1620: batch_loss=0.021993\n",
            "Batch 1630: batch_loss=0.022961\n",
            "Batch 1640: batch_loss=0.033943\n",
            "Batch 1650: batch_loss=0.026048\n",
            "Batch 1660: batch_loss=0.035121\n",
            "Batch 1670: batch_loss=0.026569\n",
            "Batch 1680: batch_loss=0.026308\n",
            "Batch 1690: batch_loss=0.025340\n",
            "Batch 1700: batch_loss=0.038339\n",
            "Batch 1710: batch_loss=0.019858\n",
            "Batch 1720: batch_loss=0.026467\n",
            "Batch 1730: batch_loss=0.023377\n",
            "Batch 1740: batch_loss=0.022817\n",
            "Batch 1750: batch_loss=0.029497\n",
            "Batch 1760: batch_loss=0.028914\n",
            "Batch 1770: batch_loss=0.022855\n",
            "Batch 1780: batch_loss=0.031013\n",
            "Batch 1790: batch_loss=0.027338\n",
            "Batch 1800: batch_loss=0.028351\n",
            "Batch 1810: batch_loss=0.030935\n",
            "Batch 1820: batch_loss=0.025988\n",
            "Batch 1830: batch_loss=0.025072\n",
            "Batch 1840: batch_loss=0.033687\n",
            "Batch 1850: batch_loss=0.033609\n",
            "Batch 1860: batch_loss=0.023441\n",
            "Batch 1870: batch_loss=0.023747\n",
            "Batch 1880: batch_loss=0.029634\n",
            "Batch 1890: batch_loss=0.025347\n",
            "Batch 1900: batch_loss=0.027144\n",
            "Batch 1910: batch_loss=0.022766\n",
            "Batch 1920: batch_loss=0.030936\n",
            "Batch 1930: batch_loss=0.026475\n",
            "Batch 1940: batch_loss=0.024567\n",
            "Batch 1950: batch_loss=0.025790\n",
            "Batch 1960: batch_loss=0.029615\n",
            "Batch 1970: batch_loss=0.028362\n",
            "Batch 1980: batch_loss=0.030453\n",
            "Batch 1990: batch_loss=0.025706\n",
            "Batch 2000: batch_loss=0.020116\n",
            "Batch 2010: batch_loss=0.022138\n",
            "Batch 2020: batch_loss=0.024091\n",
            "Batch 2030: batch_loss=0.030846\n",
            "Batch 2040: batch_loss=0.023808\n",
            "Batch 2050: batch_loss=0.027161\n",
            "Batch 2060: batch_loss=0.025787\n",
            "Batch 2070: batch_loss=0.024865\n",
            "Batch 2080: batch_loss=0.028984\n",
            "Batch 2090: batch_loss=0.023466\n",
            "Batch 2100: batch_loss=0.022446\n",
            "Batch 2110: batch_loss=0.027256\n",
            "Batch 2120: batch_loss=0.022940\n",
            "Batch 2130: batch_loss=0.029566\n",
            "Batch 2140: batch_loss=0.027552\n",
            "Batch 2150: batch_loss=0.025708\n",
            "Batch 2160: batch_loss=0.023362\n",
            "Batch 2170: batch_loss=0.028008\n",
            "Batch 2180: batch_loss=0.021932\n",
            "Batch 2190: batch_loss=0.024109\n",
            "Batch 2200: batch_loss=0.024146\n",
            "Batch 2210: batch_loss=0.026648\n",
            "Batch 2220: batch_loss=0.021928\n",
            "Batch 2230: batch_loss=0.023396\n",
            "Batch 2240: batch_loss=0.028506\n",
            "Batch 2250: batch_loss=0.023913\n",
            "Batch 2260: batch_loss=0.027365\n",
            "Batch 2270: batch_loss=0.024466\n",
            "Batch 2280: batch_loss=0.035821\n",
            "Batch 2290: batch_loss=0.025788\n",
            "Batch 2300: batch_loss=0.029015\n",
            "Batch 2310: batch_loss=0.022190\n",
            "Batch 2320: batch_loss=0.025938\n",
            "Batch 2330: batch_loss=0.024554\n",
            "Batch 2340: batch_loss=0.023767\n",
            "Batch 2350: batch_loss=0.028025\n",
            "Batch 2360: batch_loss=0.027593\n",
            "Batch 2370: batch_loss=0.026548\n",
            "Batch 2380: batch_loss=0.028627\n",
            "Batch 2390: batch_loss=0.027604\n",
            "Batch 2400: batch_loss=0.025711\n",
            "Batch 2410: batch_loss=0.019256\n",
            "Batch 2420: batch_loss=0.024555\n",
            "Batch 2430: batch_loss=0.031698\n",
            "Batch 2440: batch_loss=0.026030\n",
            "Batch 2450: batch_loss=0.024802\n",
            "Batch 2460: batch_loss=0.025176\n",
            "Batch 2470: batch_loss=0.021541\n",
            "Batch 2480: batch_loss=0.026457\n",
            "Batch 2490: batch_loss=0.025082\n",
            "Batch 2500: batch_loss=0.031598\n",
            "Batch 2510: batch_loss=0.024706\n",
            "Batch 2520: batch_loss=0.028298\n",
            "Batch 2530: batch_loss=0.030471\n",
            "Batch 2540: batch_loss=0.027952\n",
            "Batch 2550: batch_loss=0.032562\n",
            "Batch 2560: batch_loss=0.019025\n",
            "Batch 2570: batch_loss=0.031672\n",
            "Batch 2580: batch_loss=0.022195\n",
            "Batch 2590: batch_loss=0.028355\n",
            "Batch 2600: batch_loss=0.036187\n",
            "Batch 2610: batch_loss=0.022077\n",
            "Batch 2620: batch_loss=0.030260\n",
            "Batch 2630: batch_loss=0.024401\n",
            "Batch 2640: batch_loss=0.030181\n",
            "Batch 2650: batch_loss=0.028407\n",
            "Batch 2660: batch_loss=0.028271\n",
            "Batch 2670: batch_loss=0.022585\n",
            "Batch 2680: batch_loss=0.026114\n",
            "Batch 2690: batch_loss=0.027603\n",
            "Batch 2700: batch_loss=0.028354\n",
            "Batch 2710: batch_loss=0.031348\n",
            "Batch 2720: batch_loss=0.027730\n",
            "Batch 2730: batch_loss=0.025200\n",
            "Batch 2740: batch_loss=0.020363\n",
            "Batch 2750: batch_loss=0.030246\n",
            "Batch 2760: batch_loss=0.031410\n",
            "Batch 2770: batch_loss=0.023892\n",
            "Batch 2780: batch_loss=0.023416\n",
            "Batch 2790: batch_loss=0.030449\n",
            "Batch 2800: batch_loss=0.030896\n",
            "Batch 2810: batch_loss=0.029206\n",
            "Batch 2820: batch_loss=0.025666\n",
            "Batch 2830: batch_loss=0.022534\n",
            "Batch 2840: batch_loss=0.023772\n",
            "Batch 2850: batch_loss=0.024668\n",
            "Batch 2860: batch_loss=0.032150\n",
            "Batch 2870: batch_loss=0.024844\n",
            "Batch 2880: batch_loss=0.023012\n",
            "Batch 2890: batch_loss=0.031668\n",
            "Batch 2900: batch_loss=0.030432\n",
            "Batch 2910: batch_loss=0.026826\n",
            "Batch 2920: batch_loss=0.027169\n",
            "Batch 2930: batch_loss=0.025066\n",
            "Batch 2940: batch_loss=0.026442\n",
            "Batch 2950: batch_loss=0.023426\n",
            "Batch 2960: batch_loss=0.026340\n",
            "Batch 2970: batch_loss=0.020893\n",
            "Batch 2980: batch_loss=0.024046\n",
            "Batch 2990: batch_loss=0.027257\n",
            "Batch 3000: batch_loss=0.029703\n",
            "Batch 3010: batch_loss=0.027442\n",
            "Batch 3020: batch_loss=0.025708\n",
            "Batch 3030: batch_loss=0.030489\n",
            "Batch 3040: batch_loss=0.024772\n",
            "Batch 3050: batch_loss=0.021739\n",
            "Batch 3060: batch_loss=0.024712\n",
            "Batch 3070: batch_loss=0.026554\n",
            "Batch 3080: batch_loss=0.037398\n",
            "Batch 3090: batch_loss=0.026113\n",
            "Batch 3100: batch_loss=0.023276\n",
            "Batch 3110: batch_loss=0.030050\n",
            "Batch 3120: batch_loss=0.025751\n",
            "Batch 3130: batch_loss=0.029352\n",
            "Batch 3140: batch_loss=0.028512\n",
            "Batch 3150: batch_loss=0.025297\n",
            "Batch 3160: batch_loss=0.022003\n",
            "Batch 3170: batch_loss=0.020826\n",
            "Batch 3180: batch_loss=0.024719\n",
            "Batch 3190: batch_loss=0.026676\n",
            "Batch 3200: batch_loss=0.025185\n",
            "Batch 3210: batch_loss=0.025168\n",
            "Batch 3220: batch_loss=0.027769\n",
            "Batch 3230: batch_loss=0.024024\n",
            "Batch 3240: batch_loss=0.026823\n",
            "Batch 3250: batch_loss=0.028455\n",
            "Batch 3260: batch_loss=0.030020\n",
            "Batch 3270: batch_loss=0.027807\n",
            "Batch 3280: batch_loss=0.033392\n",
            "Batch 3290: batch_loss=0.028270\n",
            "Batch 3300: batch_loss=0.024704\n",
            "Batch 3310: batch_loss=0.022219\n",
            "Batch 3320: batch_loss=0.027836\n",
            "Batch 3330: batch_loss=0.019967\n",
            "Batch 3340: batch_loss=0.031897\n",
            "Batch 3350: batch_loss=0.022840\n",
            "Batch 3360: batch_loss=0.031029\n",
            "Batch 3370: batch_loss=0.026334\n",
            "Batch 3380: batch_loss=0.025406\n",
            "Batch 3390: batch_loss=0.027298\n",
            "Batch 3400: batch_loss=0.021464\n",
            "Batch 3410: batch_loss=0.022455\n",
            "Batch 3420: batch_loss=0.032052\n",
            "Batch 3430: batch_loss=0.026821\n",
            "Batch 3440: batch_loss=0.025357\n",
            "Batch 3450: batch_loss=0.028073\n",
            "Batch 3460: batch_loss=0.019262\n",
            "Batch 3470: batch_loss=0.025643\n",
            "Batch 3480: batch_loss=0.026108\n",
            "Batch 3490: batch_loss=0.027202\n",
            "Batch 3500: batch_loss=0.021109\n",
            "Batch 3510: batch_loss=0.019775\n",
            "Batch 3520: batch_loss=0.023898\n",
            "Batch 3530: batch_loss=0.023156\n",
            "Batch 3540: batch_loss=0.026484\n",
            "Batch 3550: batch_loss=0.027923\n",
            "Batch 3560: batch_loss=0.026724\n",
            "Batch 3570: batch_loss=0.024248\n",
            "Batch 3580: batch_loss=0.023334\n",
            "Batch 3590: batch_loss=0.032442\n",
            "Batch 3600: batch_loss=0.027400\n",
            "Batch 3610: batch_loss=0.026426\n",
            "Batch 3620: batch_loss=0.024555\n",
            "Batch 3630: batch_loss=0.023145\n",
            "Batch 3640: batch_loss=0.025782\n",
            "Batch 3650: batch_loss=0.034758\n",
            "Batch 3660: batch_loss=0.029868\n",
            "Batch 3670: batch_loss=0.027809\n",
            "Batch 3680: batch_loss=0.022261\n",
            "Batch 3690: batch_loss=0.032011\n",
            "Batch 3700: batch_loss=0.025592\n",
            "Batch 3710: batch_loss=0.023066\n",
            "Batch 3720: batch_loss=0.023805\n",
            "Epoch 9/10, Train Loss: 0.026649, Val Loss: 0.016629\n",
            "Batch 0: batch_loss=0.026845\n",
            "Batch 10: batch_loss=0.023927\n",
            "Batch 20: batch_loss=0.021683\n",
            "Batch 30: batch_loss=0.027197\n",
            "Batch 40: batch_loss=0.022996\n",
            "Batch 50: batch_loss=0.027206\n",
            "Batch 60: batch_loss=0.030219\n",
            "Batch 70: batch_loss=0.022261\n",
            "Batch 80: batch_loss=0.026427\n",
            "Batch 90: batch_loss=0.023162\n",
            "Batch 100: batch_loss=0.033444\n",
            "Batch 110: batch_loss=0.026417\n",
            "Batch 120: batch_loss=0.027361\n",
            "Batch 130: batch_loss=0.026695\n",
            "Batch 140: batch_loss=0.027023\n",
            "Batch 150: batch_loss=0.026496\n",
            "Batch 160: batch_loss=0.024503\n",
            "Batch 170: batch_loss=0.026784\n",
            "Batch 180: batch_loss=0.028444\n",
            "Batch 190: batch_loss=0.022735\n",
            "Batch 200: batch_loss=0.027921\n",
            "Batch 210: batch_loss=0.024918\n",
            "Batch 220: batch_loss=0.022558\n",
            "Batch 230: batch_loss=0.021927\n",
            "Batch 240: batch_loss=0.025461\n",
            "Batch 250: batch_loss=0.025052\n",
            "Batch 260: batch_loss=0.031334\n",
            "Batch 270: batch_loss=0.024573\n",
            "Batch 280: batch_loss=0.038386\n",
            "Batch 290: batch_loss=0.026199\n",
            "Batch 300: batch_loss=0.024418\n",
            "Batch 310: batch_loss=0.026108\n",
            "Batch 320: batch_loss=0.023932\n",
            "Batch 330: batch_loss=0.026836\n",
            "Batch 340: batch_loss=0.025152\n",
            "Batch 350: batch_loss=0.031771\n",
            "Batch 360: batch_loss=0.023963\n",
            "Batch 370: batch_loss=0.031082\n",
            "Batch 380: batch_loss=0.029013\n",
            "Batch 390: batch_loss=0.024650\n",
            "Batch 400: batch_loss=0.020728\n",
            "Batch 410: batch_loss=0.029286\n",
            "Batch 420: batch_loss=0.027409\n",
            "Batch 430: batch_loss=0.024421\n",
            "Batch 440: batch_loss=0.021120\n",
            "Batch 450: batch_loss=0.024470\n",
            "Batch 460: batch_loss=0.028692\n",
            "Batch 470: batch_loss=0.023568\n",
            "Batch 480: batch_loss=0.027439\n",
            "Batch 490: batch_loss=0.024930\n",
            "Batch 500: batch_loss=0.023374\n",
            "Batch 510: batch_loss=0.019782\n",
            "Batch 520: batch_loss=0.036584\n",
            "Batch 530: batch_loss=0.025996\n",
            "Batch 540: batch_loss=0.027583\n",
            "Batch 550: batch_loss=0.031533\n",
            "Batch 560: batch_loss=0.024316\n",
            "Batch 570: batch_loss=0.025678\n",
            "Batch 580: batch_loss=0.033015\n",
            "Batch 590: batch_loss=0.021857\n",
            "Batch 600: batch_loss=0.024836\n",
            "Batch 610: batch_loss=0.033470\n",
            "Batch 620: batch_loss=0.029246\n",
            "Batch 630: batch_loss=0.027214\n",
            "Batch 640: batch_loss=0.027076\n",
            "Batch 650: batch_loss=0.030213\n",
            "Batch 660: batch_loss=0.024955\n",
            "Batch 670: batch_loss=0.025878\n",
            "Batch 680: batch_loss=0.025048\n",
            "Batch 690: batch_loss=0.026259\n",
            "Batch 700: batch_loss=0.024290\n",
            "Batch 710: batch_loss=0.027686\n",
            "Batch 720: batch_loss=0.029258\n",
            "Batch 730: batch_loss=0.024942\n",
            "Batch 740: batch_loss=0.023124\n",
            "Batch 750: batch_loss=0.026833\n",
            "Batch 760: batch_loss=0.026541\n",
            "Batch 770: batch_loss=0.029749\n",
            "Batch 780: batch_loss=0.026263\n",
            "Batch 790: batch_loss=0.027979\n",
            "Batch 800: batch_loss=0.025676\n",
            "Batch 810: batch_loss=0.031729\n",
            "Batch 820: batch_loss=0.028141\n",
            "Batch 830: batch_loss=0.026968\n",
            "Batch 840: batch_loss=0.027294\n",
            "Batch 850: batch_loss=0.022121\n",
            "Batch 860: batch_loss=0.024036\n",
            "Batch 870: batch_loss=0.026980\n",
            "Batch 880: batch_loss=0.025592\n",
            "Batch 890: batch_loss=0.030048\n",
            "Batch 900: batch_loss=0.023717\n",
            "Batch 910: batch_loss=0.023344\n",
            "Batch 920: batch_loss=0.020988\n",
            "Batch 930: batch_loss=0.023189\n",
            "Batch 940: batch_loss=0.023274\n",
            "Batch 950: batch_loss=0.026285\n",
            "Batch 960: batch_loss=0.021219\n",
            "Batch 970: batch_loss=0.028885\n",
            "Batch 980: batch_loss=0.023786\n",
            "Batch 990: batch_loss=0.019277\n",
            "Batch 1000: batch_loss=0.022753\n",
            "Batch 1010: batch_loss=0.029226\n",
            "Batch 1020: batch_loss=0.031663\n",
            "Batch 1030: batch_loss=0.030401\n",
            "Batch 1040: batch_loss=0.024113\n",
            "Batch 1050: batch_loss=0.022496\n",
            "Batch 1060: batch_loss=0.022531\n",
            "Batch 1070: batch_loss=0.028987\n",
            "Batch 1080: batch_loss=0.025832\n",
            "Batch 1090: batch_loss=0.024620\n",
            "Batch 1100: batch_loss=0.025614\n",
            "Batch 1110: batch_loss=0.026652\n",
            "Batch 1120: batch_loss=0.022800\n",
            "Batch 1130: batch_loss=0.023732\n",
            "Batch 1140: batch_loss=0.027171\n",
            "Batch 1150: batch_loss=0.028990\n",
            "Batch 1160: batch_loss=0.022856\n",
            "Batch 1170: batch_loss=0.028424\n",
            "Batch 1180: batch_loss=0.026613\n",
            "Batch 1190: batch_loss=0.025574\n",
            "Batch 1200: batch_loss=0.032370\n",
            "Batch 1210: batch_loss=0.021394\n",
            "Batch 1220: batch_loss=0.022905\n",
            "Batch 1230: batch_loss=0.029487\n",
            "Batch 1240: batch_loss=0.024802\n",
            "Batch 1250: batch_loss=0.031188\n",
            "Batch 1260: batch_loss=0.030315\n",
            "Batch 1270: batch_loss=0.026731\n",
            "Batch 1280: batch_loss=0.032154\n",
            "Batch 1290: batch_loss=0.024257\n",
            "Batch 1300: batch_loss=0.022842\n",
            "Batch 1310: batch_loss=0.023570\n",
            "Batch 1320: batch_loss=0.025373\n",
            "Batch 1330: batch_loss=0.031513\n",
            "Batch 1340: batch_loss=0.023247\n",
            "Batch 1350: batch_loss=0.025251\n",
            "Batch 1360: batch_loss=0.029158\n",
            "Batch 1370: batch_loss=0.028524\n",
            "Batch 1380: batch_loss=0.025672\n",
            "Batch 1390: batch_loss=0.023564\n",
            "Batch 1400: batch_loss=0.029144\n",
            "Batch 1410: batch_loss=0.028200\n",
            "Batch 1420: batch_loss=0.032359\n",
            "Batch 1430: batch_loss=0.023597\n",
            "Batch 1440: batch_loss=0.028427\n",
            "Batch 1450: batch_loss=0.026388\n",
            "Batch 1460: batch_loss=0.024695\n",
            "Batch 1470: batch_loss=0.027358\n",
            "Batch 1480: batch_loss=0.025754\n",
            "Batch 1490: batch_loss=0.025552\n",
            "Batch 1500: batch_loss=0.027235\n",
            "Batch 1510: batch_loss=0.029795\n",
            "Batch 1520: batch_loss=0.027812\n",
            "Batch 1530: batch_loss=0.021263\n",
            "Batch 1540: batch_loss=0.025251\n",
            "Batch 1550: batch_loss=0.027812\n",
            "Batch 1560: batch_loss=0.025699\n",
            "Batch 1570: batch_loss=0.030704\n",
            "Batch 1580: batch_loss=0.037347\n",
            "Batch 1590: batch_loss=0.030315\n",
            "Batch 1600: batch_loss=0.033471\n",
            "Batch 1610: batch_loss=0.025140\n",
            "Batch 1620: batch_loss=0.029271\n",
            "Batch 1630: batch_loss=0.027314\n",
            "Batch 1640: batch_loss=0.034752\n",
            "Batch 1650: batch_loss=0.026949\n",
            "Batch 1660: batch_loss=0.027202\n",
            "Batch 1670: batch_loss=0.022054\n",
            "Batch 1680: batch_loss=0.028342\n",
            "Batch 1690: batch_loss=0.026696\n",
            "Batch 1700: batch_loss=0.025341\n",
            "Batch 1710: batch_loss=0.030145\n",
            "Batch 1720: batch_loss=0.026610\n",
            "Batch 1730: batch_loss=0.026931\n",
            "Batch 1740: batch_loss=0.022297\n",
            "Batch 1750: batch_loss=0.032802\n",
            "Batch 1760: batch_loss=0.026151\n",
            "Batch 1770: batch_loss=0.026649\n",
            "Batch 1780: batch_loss=0.033334\n",
            "Batch 1790: batch_loss=0.029784\n",
            "Batch 1800: batch_loss=0.027529\n",
            "Batch 1810: batch_loss=0.024506\n",
            "Batch 1820: batch_loss=0.025410\n",
            "Batch 1830: batch_loss=0.028212\n",
            "Batch 1840: batch_loss=0.035136\n",
            "Batch 1850: batch_loss=0.024703\n",
            "Batch 1860: batch_loss=0.030838\n",
            "Batch 1870: batch_loss=0.022967\n",
            "Batch 1880: batch_loss=0.021534\n",
            "Batch 1890: batch_loss=0.025630\n",
            "Batch 1900: batch_loss=0.024536\n",
            "Batch 1910: batch_loss=0.032504\n",
            "Batch 1920: batch_loss=0.026655\n",
            "Batch 1930: batch_loss=0.027155\n",
            "Batch 1940: batch_loss=0.028575\n",
            "Batch 1950: batch_loss=0.029984\n",
            "Batch 1960: batch_loss=0.026889\n",
            "Batch 1970: batch_loss=0.024059\n",
            "Batch 1980: batch_loss=0.024040\n",
            "Batch 1990: batch_loss=0.028122\n",
            "Batch 2000: batch_loss=0.034071\n",
            "Batch 2010: batch_loss=0.030601\n",
            "Batch 2020: batch_loss=0.021060\n",
            "Batch 2030: batch_loss=0.020477\n",
            "Batch 2040: batch_loss=0.029887\n",
            "Batch 2050: batch_loss=0.024723\n",
            "Batch 2060: batch_loss=0.022501\n",
            "Batch 2070: batch_loss=0.020635\n",
            "Batch 2080: batch_loss=0.025102\n",
            "Batch 2090: batch_loss=0.018803\n",
            "Batch 2100: batch_loss=0.026546\n",
            "Batch 2110: batch_loss=0.029572\n",
            "Batch 2120: batch_loss=0.025424\n",
            "Batch 2130: batch_loss=0.030541\n",
            "Batch 2140: batch_loss=0.023370\n",
            "Batch 2150: batch_loss=0.030359\n",
            "Batch 2160: batch_loss=0.025225\n",
            "Batch 2170: batch_loss=0.024956\n",
            "Batch 2180: batch_loss=0.025207\n",
            "Batch 2190: batch_loss=0.027266\n",
            "Batch 2200: batch_loss=0.033838\n",
            "Batch 2210: batch_loss=0.023109\n",
            "Batch 2220: batch_loss=0.026414\n",
            "Batch 2230: batch_loss=0.027232\n",
            "Batch 2240: batch_loss=0.034197\n",
            "Batch 2250: batch_loss=0.032840\n",
            "Batch 2260: batch_loss=0.028960\n",
            "Batch 2270: batch_loss=0.028273\n",
            "Batch 2280: batch_loss=0.024971\n",
            "Batch 2290: batch_loss=0.029260\n",
            "Batch 2300: batch_loss=0.021795\n",
            "Batch 2310: batch_loss=0.025719\n",
            "Batch 2320: batch_loss=0.024958\n",
            "Batch 2330: batch_loss=0.024267\n",
            "Batch 2340: batch_loss=0.034161\n",
            "Batch 2350: batch_loss=0.025188\n",
            "Batch 2360: batch_loss=0.027862\n",
            "Batch 2370: batch_loss=0.026781\n",
            "Batch 2380: batch_loss=0.034470\n",
            "Batch 2390: batch_loss=0.024396\n",
            "Batch 2400: batch_loss=0.022586\n",
            "Batch 2410: batch_loss=0.023120\n",
            "Batch 2420: batch_loss=0.021418\n",
            "Batch 2430: batch_loss=0.024319\n",
            "Batch 2440: batch_loss=0.027183\n",
            "Batch 2450: batch_loss=0.020477\n",
            "Batch 2460: batch_loss=0.021700\n",
            "Batch 2470: batch_loss=0.028826\n",
            "Batch 2480: batch_loss=0.028475\n",
            "Batch 2490: batch_loss=0.025673\n",
            "Batch 2500: batch_loss=0.024663\n",
            "Batch 2510: batch_loss=0.023156\n",
            "Batch 2520: batch_loss=0.026129\n",
            "Batch 2530: batch_loss=0.022185\n",
            "Batch 2540: batch_loss=0.021580\n",
            "Batch 2550: batch_loss=0.027790\n",
            "Batch 2560: batch_loss=0.023462\n",
            "Batch 2570: batch_loss=0.023031\n",
            "Batch 2580: batch_loss=0.024287\n",
            "Batch 2590: batch_loss=0.026056\n",
            "Batch 2600: batch_loss=0.023163\n",
            "Batch 2610: batch_loss=0.034448\n",
            "Batch 2620: batch_loss=0.027336\n",
            "Batch 2630: batch_loss=0.024012\n",
            "Batch 2640: batch_loss=0.023821\n",
            "Batch 2650: batch_loss=0.026190\n",
            "Batch 2660: batch_loss=0.024082\n",
            "Batch 2670: batch_loss=0.026774\n",
            "Batch 2680: batch_loss=0.037886\n",
            "Batch 2690: batch_loss=0.025831\n",
            "Batch 2700: batch_loss=0.024691\n",
            "Batch 2710: batch_loss=0.021667\n",
            "Batch 2720: batch_loss=0.027333\n",
            "Batch 2730: batch_loss=0.026702\n",
            "Batch 2740: batch_loss=0.033852\n",
            "Batch 2750: batch_loss=0.024578\n",
            "Batch 2760: batch_loss=0.028782\n",
            "Batch 2770: batch_loss=0.022727\n",
            "Batch 2780: batch_loss=0.024959\n",
            "Batch 2790: batch_loss=0.027460\n",
            "Batch 2800: batch_loss=0.025235\n",
            "Batch 2810: batch_loss=0.025264\n",
            "Batch 2820: batch_loss=0.027694\n",
            "Batch 2830: batch_loss=0.026819\n",
            "Batch 2840: batch_loss=0.023261\n",
            "Batch 2850: batch_loss=0.026875\n",
            "Batch 2860: batch_loss=0.029520\n",
            "Batch 2870: batch_loss=0.022451\n",
            "Batch 2880: batch_loss=0.029908\n",
            "Batch 2890: batch_loss=0.024628\n",
            "Batch 2900: batch_loss=0.024690\n",
            "Batch 2910: batch_loss=0.021056\n",
            "Batch 2920: batch_loss=0.020662\n",
            "Batch 2930: batch_loss=0.026118\n",
            "Batch 2940: batch_loss=0.021593\n",
            "Batch 2950: batch_loss=0.024654\n",
            "Batch 2960: batch_loss=0.026205\n",
            "Batch 2970: batch_loss=0.030210\n",
            "Batch 2980: batch_loss=0.028745\n",
            "Batch 2990: batch_loss=0.021468\n",
            "Batch 3000: batch_loss=0.027782\n",
            "Batch 3010: batch_loss=0.020844\n",
            "Batch 3020: batch_loss=0.021874\n",
            "Batch 3030: batch_loss=0.029260\n",
            "Batch 3040: batch_loss=0.025056\n",
            "Batch 3050: batch_loss=0.030911\n",
            "Batch 3060: batch_loss=0.030509\n",
            "Batch 3070: batch_loss=0.027579\n",
            "Batch 3080: batch_loss=0.031085\n",
            "Batch 3090: batch_loss=0.026797\n",
            "Batch 3100: batch_loss=0.027759\n",
            "Batch 3110: batch_loss=0.025537\n",
            "Batch 3120: batch_loss=0.030909\n",
            "Batch 3130: batch_loss=0.023798\n",
            "Batch 3140: batch_loss=0.024065\n",
            "Batch 3150: batch_loss=0.030184\n",
            "Batch 3160: batch_loss=0.028916\n",
            "Batch 3170: batch_loss=0.025305\n",
            "Batch 3180: batch_loss=0.025145\n",
            "Batch 3190: batch_loss=0.023339\n",
            "Batch 3200: batch_loss=0.022896\n",
            "Batch 3210: batch_loss=0.026617\n",
            "Batch 3220: batch_loss=0.025139\n",
            "Batch 3230: batch_loss=0.024492\n",
            "Batch 3240: batch_loss=0.026157\n",
            "Batch 3250: batch_loss=0.028625\n",
            "Batch 3260: batch_loss=0.025506\n",
            "Batch 3270: batch_loss=0.031430\n",
            "Batch 3280: batch_loss=0.024780\n",
            "Batch 3290: batch_loss=0.026504\n",
            "Batch 3300: batch_loss=0.022839\n",
            "Batch 3310: batch_loss=0.025253\n",
            "Batch 3320: batch_loss=0.021829\n",
            "Batch 3330: batch_loss=0.024762\n",
            "Batch 3340: batch_loss=0.029788\n",
            "Batch 3350: batch_loss=0.031864\n",
            "Batch 3360: batch_loss=0.023935\n",
            "Batch 3370: batch_loss=0.022811\n",
            "Batch 3380: batch_loss=0.025494\n",
            "Batch 3390: batch_loss=0.024261\n",
            "Batch 3400: batch_loss=0.021826\n",
            "Batch 3410: batch_loss=0.025983\n",
            "Batch 3420: batch_loss=0.029849\n",
            "Batch 3430: batch_loss=0.024459\n",
            "Batch 3440: batch_loss=0.024739\n",
            "Batch 3450: batch_loss=0.019944\n",
            "Batch 3460: batch_loss=0.020828\n",
            "Batch 3470: batch_loss=0.030405\n",
            "Batch 3480: batch_loss=0.025862\n",
            "Batch 3490: batch_loss=0.025452\n",
            "Batch 3500: batch_loss=0.029911\n",
            "Batch 3510: batch_loss=0.022780\n",
            "Batch 3520: batch_loss=0.024103\n",
            "Batch 3530: batch_loss=0.022095\n",
            "Batch 3540: batch_loss=0.028051\n",
            "Batch 3550: batch_loss=0.028948\n",
            "Batch 3560: batch_loss=0.023216\n",
            "Batch 3570: batch_loss=0.026227\n",
            "Batch 3580: batch_loss=0.020830\n",
            "Batch 3590: batch_loss=0.024455\n",
            "Batch 3600: batch_loss=0.024365\n",
            "Batch 3610: batch_loss=0.022108\n",
            "Batch 3620: batch_loss=0.023327\n",
            "Batch 3630: batch_loss=0.026618\n",
            "Batch 3640: batch_loss=0.029210\n",
            "Batch 3650: batch_loss=0.027407\n",
            "Batch 3660: batch_loss=0.027651\n",
            "Batch 3670: batch_loss=0.019853\n",
            "Batch 3680: batch_loss=0.025896\n",
            "Batch 3690: batch_loss=0.032470\n",
            "Batch 3700: batch_loss=0.027176\n",
            "Batch 3710: batch_loss=0.028799\n",
            "Batch 3720: batch_loss=0.023178\n",
            "Epoch 10/10, Train Loss: 0.026647, Val Loss: 0.016630\n"
          ]
        }
      ],
      "source": [
        "model = TranslationalEquivariantModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "print(\"Translational Equivariant Model\")\n",
        "for epoch in range(num_epochs):\n",
        "    p_teacher = p_teacher_schedule(epoch, num_epochs)\n",
        "\n",
        "    # ----- TRAIN -----\n",
        "    train_loss = push_forward_train_epoch(\n",
        "        model=model,\n",
        "        dataloader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        box=box,\n",
        "        radius=radius,\n",
        "        rollout_steps=3,\n",
        "        #p_teacher_fn=lambda: p_teacher,  # schedule\n",
        "        grad_clip=1.0,\n",
        "    )\n",
        "\n",
        "    # ----- VALIDATION -----\n",
        "    val_loss = 0.0\n",
        "    n_val_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "          init_data = batch[\"init\"].to(device)\n",
        "          gt_sequence = [gt.to(device) for gt in batch[\"gt\"]]\n",
        "\n",
        "          preds, targets = rollout_push_forward(\n",
        "              model=model,\n",
        "              init_data=init_data,\n",
        "              gt_sequence=gt_sequence,\n",
        "              rollout_steps=5,\n",
        "              radius=radius,\n",
        "              box=box,\n",
        "              device=device,\n",
        "              p_teacher=0.0,  # no teacher forcing in validation\n",
        "          )\n",
        "          val_loss += rollout_loss(preds, targets).item()\n",
        "          n_val_batches += 1\n",
        "\n",
        "    val_loss /= max(1, n_val_batches)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cinn7f8KrmKS"
      },
      "source": [
        "## Evaluating scientific AI models\n",
        "\n",
        "The Boids simulations are very sensitive to changes in the initial state. Slight changes in the initial state can lead to drastically different final states. Similarly, emulations (the neural network predictions) can accumulate errors very quickly.\n",
        "\n",
        "Using MSE to compare models to the ground truth or to each other here does not account for this error accumulation. As a result, a likely generated/predicted trajectory can have high MSE.\n",
        "\n",
        "Luckily for us, there are usually better ways to evaluate models! When working in an interdisciplinary group, the physics wizards will propose a metric that should hold true even when trajectories diverge, or our predictions suffer from accumulating errors.\n",
        "\n",
        "In the Boids setting, we can investigate the distribution of velocities, since these should (hopefully) remain invariant even under diverging trajectories / error accumulation.\n",
        "\n",
        "If we plot them visually, we want to investigate how different the predicted velocity distributions are from the ground truth velocity distributions. However, since we have to investigate the distributions for each timestep, let's use the Kullback-Leibler Divergence ($D_\\text{KL}$) metric to measure the difference. For two distributions $P$ and $Q$, it is defined as follows:\n",
        "\n",
        "\n",
        "$D_\\text{KL}(P||Q) = \\int p(x) \\ln \\frac{p(x)}{q(x)} \\text{d} x $\n",
        "\n",
        "\n",
        "![KL Divergence](https://hugocisneros.com/ox-hugo/forwardvsreversedKL.jpg)\n",
        "\n",
        "\n",
        "The $D_\\text{KL}$ between two distributions $P$ and $Q$ is asymmetric, meaning $D_\\text{KL}(P||Q) \\neq D_\\text{KL}(Q||P)$, as illustrated above.\n",
        "\n",
        "Since we care more whether the predicted distribution $Q$ fits under the ground truth distribution $P$, we will use the reverse KL: $D_\\text{KL}(Q||P)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EBhB_NPErmKS"
      },
      "outputs": [],
      "source": [
        "def compare_distributions(dist1, dist2):\n",
        "    \"\"\"\n",
        "    Compare two distributions by computing the KL divergence\n",
        "\n",
        "    Args:\n",
        "        dist1: torch.distributions.Distribution\n",
        "        dist2: torch.distributions.Distribution\n",
        "    \"\"\"\n",
        "    kl = torch.distributions.kl_divergence(dist1, dist2)\n",
        "    return kl\n",
        "\n",
        "def compute_distribution_per_timestep(data, timesteps):\n",
        "    \"\"\"\n",
        "    Compute the distribution of the data per timestep\n",
        "\n",
        "    Args:\n",
        "        data: torch.Tensor of shape (T, N, 4)\n",
        "        timesteps: int, number of timesteps to compute the distribution for\n",
        "\n",
        "    Returns:\n",
        "        list of torch.distributions.Normal\n",
        "    \"\"\"\n",
        "    distributions = []\n",
        "    for t in range(timesteps):\n",
        "        # Compute the mean and std of the data\n",
        "        mean = data[:, t, :, :].mean()\n",
        "        std = data[:, t, :, :].std()\n",
        "        dist = torch.distributions.Normal(mean, std)\n",
        "        distributions.append(dist)\n",
        "    return distributions\n",
        "\n",
        "def compute_mean_kl_divergence(data, distributions):\n",
        "    \"\"\"\n",
        "    Compute the mean KL divergence between the data and the distributions\n",
        "\n",
        "    Args:\n",
        "        data: torch.Tensor of shape (T, N, 4)\n",
        "        distributions: list of torch.distributions.Normal\n",
        "\n",
        "    Returns:\n",
        "        float\n",
        "    \"\"\"\n",
        "    kl_divergences = []\n",
        "    for t in range(data.shape[0]):\n",
        "        kl = compare_distributions(distributions[t], data[t, :, :])\n",
        "        kl_divergences.append(kl)\n",
        "    return torch.tensor(kl_divergences).mean()\n",
        "\n",
        "def plot_kl_divergence(distributions1, distributions2, title=\"KL Divergence between <distributions1> and <distributions2>\"):\n",
        "    \"\"\"\n",
        "    Plot the KL divergence between the data and the distributions\n",
        "\n",
        "    Args:\n",
        "        distributions1: list of torch.distributions.Normal\n",
        "        distributions2: list of torch.distributions.Normal\n",
        "    \"\"\"\n",
        "    kl_divergences = []\n",
        "    for t in range(len(distributions1)):\n",
        "        kl = compare_distributions(distributions1[t], distributions2[t]).cpu().numpy()\n",
        "        kl_divergences.append(kl)\n",
        "\n",
        "\n",
        "    plt.plot(kl_divergences)\n",
        "    plt.xlabel(\"Timestep\")\n",
        "    plt.ylabel(\"KL Divergence\")\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GESF7TKrmKS",
        "outputId": "13b1c250-8faa-4ce7-eb28-b23e659ba0b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\liamm\\AppData\\Local\\Temp\\ipykernel_14484\\1671957078.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  validation_trajectories = torch.tensor(validation_trajectories, dtype=torch.float)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "validation_files = [pfn for pfn in os.listdir(\"../../data/boids/raw/\") if (16 <= int(pfn.split(\"_\")[-1][:-4]) < 25)]\n",
        "validation_trajectories = [np.load(\"../../data/boids/raw/\" + f) for f in validation_files]\n",
        "validation_trajectories = torch.tensor(validation_trajectories, dtype=torch.float)\n",
        "\n",
        "dists_GT = compute_distribution_per_timestep(validation_trajectories[:,:,:,2:], 1000)\n",
        "dists_AR_set = compute_distribution_per_timestep(ar_set_model_rollout[:,:,:,2:], 1000)\n",
        "plot_kl_divergence(dists_AR_set, dists_GT, title=\"KL Divergence between AR Set Model velocities and the GT velocities per timestep\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "01T5kS9ArmKT"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dists_equivariant = compute_distribution_per_timestep(translational_equivariant_model_rollout[:,:,:,2:], 1000)\n",
        "plot_kl_divergence(dists_equivariant, dists_GT, title=\"KL Divergence between Translational Equivariant Model velocities and the GT velocities per timestep\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU2quSZFrmKT"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] Minartz, K., Poels, Y., Koop, S., & Menkovski, V. (2023). Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics. https://openreview.net/forum?id=CCVsGbhFdj\n",
        "\n",
        "[2] Reynolds, C. W. (1987) Flocks, Herds, and Schools: A Distributed Behavioral Model, in Computer Graphics, 21(4) (SIGGRAPH '87 Conference Proceedings) pages 25-34.\n",
        "\n",
        "[3] Satorras, V. G., Hoogeboom, E., & Welling, M. (2021, July). E (n) equivariant graph neural networks. In International conference on machine learning (pp. 9323-9332). PMLR."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "clean_cuda_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
